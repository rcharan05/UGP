{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11428668,"sourceType":"datasetVersion","datasetId":7157956}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport json\nimport pandas as pd\n!pip install numpy scikit-learn torch\n\n# Set the directory to the Kaggle dataset path\nDATA_DIR = \"/kaggle/input/cislr-dataset\"\n\n# Define paths for each file/folder\nVIDEO_POSE_DIR = os.path.join(DATA_DIR, \"CISLR_v1.5-a_videos_poses\")\nI3D_PKL        = os.path.join(DATA_DIR, \"I3D_features.pkl\")\nPROTO_CSV      = os.path.join(DATA_DIR, \"prototype.csv\")\nTEST_CSV       = os.path.join(DATA_DIR, \"test.csv\")\n\nprint(\"Data Directory:\", DATA_DIR)\nprint(\"Video Pose Directory:\", VIDEO_POSE_DIR)\nprint(\"I3D Features Pickle:\", I3D_PKL)\nprint(\"Prototype CSV:\", PROTO_CSV)\nprint(\"Test CSV:\", TEST_CSV)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-19T04:03:48.645719Z","iopub.execute_input":"2025-04-19T04:03:48.646369Z","iopub.status.idle":"2025-04-19T04:03:51.998896Z","shell.execute_reply.started":"2025-04-19T04:03:48.646339Z","shell.execute_reply":"2025-04-19T04:03:51.998002Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy) (2024.2.0)\nData Directory: /kaggle/input/cislr-dataset\nVideo Pose Directory: /kaggle/input/cislr-dataset/CISLR_v1.5-a_videos_poses\nI3D Features Pickle: /kaggle/input/cislr-dataset/I3D_features.pkl\nPrototype CSV: /kaggle/input/cislr-dataset/prototype.csv\nTest CSV: /kaggle/input/cislr-dataset/test.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"All dependencies are installed and imported","metadata":{}},{"cell_type":"code","source":"# Import libraries\nimport os\nimport numpy as np\nimport pandas as pd\n!pip install pose_format\nfrom pose_format import Pose\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import normalize\nfrom scipy.special import softmax\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics.pairwise import cosine_distances\nfrom sklearn.metrics.pairwise import cosine_similarity","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T04:03:55.430929Z","iopub.execute_input":"2025-04-19T04:03:55.431839Z","iopub.status.idle":"2025-04-19T04:03:59.854309Z","shell.execute_reply.started":"2025-04-19T04:03:55.431807Z","shell.execute_reply":"2025-04-19T04:03:59.853425Z"}},"outputs":[{"name":"stdout","text":"Collecting pose_format\n  Downloading pose_format-0.9.0-py3-none-any.whl.metadata (741 bytes)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pose_format) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pose_format) (1.15.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from pose_format) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->pose_format) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->pose_format) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->pose_format) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->pose_format) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->pose_format) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->pose_format) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->pose_format) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->pose_format) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->pose_format) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->pose_format) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->pose_format) (2024.2.0)\nDownloading pose_format-0.9.0-py3-none-any.whl (97 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.7/97.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pose_format\nSuccessfully installed pose_format-0.9.0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import normalize\nfrom pose_format import Pose\nfrom joblib import Parallel, delayed\nimport itertools\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T04:04:01.933415Z","iopub.execute_input":"2025-04-19T04:04:01.933868Z","iopub.status.idle":"2025-04-19T04:04:05.316241Z","shell.execute_reply.started":"2025-04-19T04:04:01.933843Z","shell.execute_reply":"2025-04-19T04:04:05.315580Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Load data\nproto_df = pd.read_csv(PROTO_CSV)\nproto_df[\"gloss\"] = proto_df[\"gloss\"].astype(str)\ntest_df = pd.read_csv(TEST_CSV)\ntest_df[\"gloss\"] = test_df[\"gloss\"].astype(str)\ny_tr, y_te = proto_df.gloss.tolist(), test_df.gloss.tolist()\n\n# Load I3D features\ni3d_df = pd.read_pickle(I3D_PKL)\ni3d_dict = {r[\"id\"]: np.array(r[\"I3D_features\"], dtype=np.float32) for _, r in i3d_df.iterrows()}\n\n# Define top-k accuracy function\ndef topk_from_S(S, y_tr, y_te, k):\n    ranks = np.argsort(-S, axis=1)\n    return np.mean([y_te[i] in [y_tr[j] for j in ranks[i, :k]] for i in range(len(y_te))]) * 100","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T04:04:07.126852Z","iopub.execute_input":"2025-04-19T04:04:07.127649Z","iopub.status.idle":"2025-04-19T04:04:11.649007Z","shell.execute_reply.started":"2025-04-19T04:04:07.127622Z","shell.execute_reply":"2025-04-19T04:04:11.648465Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# map gloss labels to integer IDs (needed for GPU eval)\nlabel2idx = {g:i for i,g in enumerate(proto_df.gloss)}\ny_tr_idx  = np.array([label2idx[g] for g in proto_df.gloss], dtype=np.int64)\ny_te_idx  = np.array([label2idx[g] for g in test_df.gloss],  dtype=np.int64)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T04:06:19.362813Z","iopub.execute_input":"2025-04-19T04:06:19.363103Z","iopub.status.idle":"2025-04-19T04:06:19.470012Z","shell.execute_reply.started":"2025-04-19T04:06:19.363082Z","shell.execute_reply":"2025-04-19T04:06:19.469243Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import torch.nn.functional as F\n\n# Pre‐move label arrays to GPU\ny_tr_t = torch.from_numpy(y_tr_idx).to(device)  # shape (N_train,)\ny_te_t = torch.from_numpy(y_te_idx).to(device)  # shape (N_test,)\n\ndef improved_i3d_gem(uid, p):\n    arr = i3d_dict[uid].squeeze((0,3,4))   # (1024, S)\n    A   = np.clip(arr, 1e-6, None)\n    gem = np.mean(A**p, axis=1)**(1/p)     # (1024,)\n    f   = np.sign(gem)*np.sqrt(np.abs(gem)+1e-8)\n    return f / (np.linalg.norm(f)+1e-12)\n\ndef build_i3d_gem(p):\n    Xg    = np.stack([improved_i3d_gem(u, p) for u in proto_df.uid])\n    Xg_te = np.stack([improved_i3d_gem(u, p) for u in test_df.uid])\n    return Xg, Xg_te","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T04:06:21.288074Z","iopub.execute_input":"2025-04-19T04:06:21.288415Z","iopub.status.idle":"2025-04-19T04:06:21.509168Z","shell.execute_reply.started":"2025-04-19T04:06:21.288392Z","shell.execute_reply":"2025-04-19T04:06:21.508551Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"print(\"=== GeM‑Pooling sweep over p (GPU sim) ===\")\nbest_gem = (0, None)\nfor p in [1.0, 2.0, 3.0, 4.0]:\n    # 1) build features on CPU\n    Xg_np, Xg_te_np = build_i3d_gem(p)\n\n    # 2) push to GPU\n    Xg    = torch.from_numpy(Xg_np).float().to(device)\n    Xg_te = torch.from_numpy(Xg_te_np).float().to(device)\n\n    # 3) normalize and compute cosine sim\n    Xg_n    = F.normalize(Xg, dim=1)       # (N_train,1024)\n    Xg_te_n = F.normalize(Xg_te, dim=1)    # (N_test, 1024)\n    S       = Xg_te_n @ Xg_n.T             # (N_test, N_train)\n\n    # 4) compute Top-1/5/10\n    print(f\"\\np={p}:\")\n    for k in (1,5,10):\n        # get top-k train‐indices for each test sample\n        topk_idxs = torch.topk(S, k, dim=1).indices  # (N_test, k)\n        # map to labels\n        pred_labels = y_tr_t[topk_idxs]               # (N_test, k)\n        # compare to each test sample's true label\n        correct = (pred_labels == y_te_t[:,None]).any(dim=1).float().mean().item() * 100\n        print(f\"  Top-{k}: {correct:.2f}%\")\n\n        # track best Top-1\n        if k==1 and correct > best_gem[0]:\n            best_gem = (correct, p)\n\nprint(f\"\\n>>> Best GeM p={best_gem[1]} with Top-1={best_gem[0]:.2f}%\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T13:58:42.127952Z","iopub.execute_input":"2025-04-16T13:58:42.128229Z","iopub.status.idle":"2025-04-16T13:58:46.194030Z","shell.execute_reply.started":"2025-04-16T13:58:42.128195Z","shell.execute_reply":"2025-04-16T13:58:46.193383Z"}},"outputs":[{"name":"stdout","text":"=== GeM‑Pooling sweep over p (GPU sim) ===\n\np=1.0:\n  Top-1: 16.81%\n  Top-5: 20.53%\n  Top-10: 22.67%\n\np=2.0:\n  Top-1: 16.89%\n  Top-5: 20.53%\n  Top-10: 22.76%\n\np=3.0:\n  Top-1: 17.07%\n  Top-5: 20.61%\n  Top-10: 22.71%\n\np=4.0:\n  Top-1: 17.07%\n  Top-5: 20.61%\n  Top-10: 22.71%\n\n>>> Best GeM p=3.0 with Top-1=17.07%\n\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"X_gem_np, X_gem_te_np = build_i3d_gem(best_gem[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T13:58:46.194702Z","iopub.execute_input":"2025-04-16T13:58:46.194922Z","iopub.status.idle":"2025-04-16T13:58:47.198583Z","shell.execute_reply.started":"2025-04-16T13:58:46.194904Z","shell.execute_reply":"2025-04-16T13:58:47.197817Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom sklearn.preprocessing import normalize\nimport concurrent.futures\n\n# Global cache for pose files to avoid repeated disk I/O\npose_cache = {}\n\ndef guided_i3d(uid):\n    # Extract I3D features (shape: (1024, S))\n    arr = i3d_dict[uid].squeeze((0, 3, 4))   # (1024, S)\n    Fm = arr.T                              # (S, 1024)\n\n    # Read and cache the pose file if not already cached\n    pose_path = os.path.join(VIDEO_POSE_DIR, f\"{uid}.pose\")\n    if uid not in pose_cache:\n        buf = open(pose_path, \"rb\").read()\n        pose_cache[uid] = Pose.read(buf)\n    p = pose_cache[uid]\n    \n    # Get pose coordinates (T,576,2)\n    coords = p.body.data.squeeze(1)[...,:2]\n    # Extract face (468), left-hand (21), and right-hand (21) landmarks\n    face = coords[:, 33:33+468]\n    lh   = coords[:, 501:501+21]\n    rh   = coords[:, 522:522+21]\n    pts = np.concatenate([face, lh, rh], axis=1)  # (T, 510, 2)\n    \n    T = pts.shape[0]\n    segs = Fm.shape[0]\n    \n    if T < 2:\n        w = np.ones(segs)\n    else:\n        # Use np.array_split to partition the pose frames into segs parts\n        segs_list = np.array_split(pts, segs)\n        w = np.array([np.linalg.norm(np.diff(seg, axis=0), axis=2).mean() if seg.shape[0] > 1 else 0.0\n                      for seg in segs_list]) + 1e-6\n    \n    # Compute the weighted sum across I3D segments\n    f = (Fm * w[:, None]).sum(axis=0) / w.sum()  # (1024,)\n    f = np.sign(f) * np.sqrt(np.abs(f) + 1e-8)\n    return f / (np.linalg.norm(f) + 1e-12)\n\n# Parallel processing for training and test guided-I3D feature extraction\nprint(\"Building guided‑I3D features…\")\n\nwith concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n    X_guided_np = np.stack(list(executor.map(guided_i3d, proto_df.uid)))\n    \nwith concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n    X_guided_te_np = np.stack(list(executor.map(guided_i3d, test_df.uid)))\n\n# Optionally, normalize the final features if needed:\nX_guided_np = normalize(X_guided_np, axis=1)\nX_guided_te_np = normalize(X_guided_te_np, axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T04:06:42.949959Z","iopub.execute_input":"2025-04-19T04:06:42.950307Z","iopub.status.idle":"2025-04-19T04:07:33.140616Z","shell.execute_reply.started":"2025-04-19T04:06:42.950284Z","shell.execute_reply":"2025-04-19T04:07:33.139757Z"}},"outputs":[{"name":"stdout","text":"Building guided‑I3D features…\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# --------------------------------------------------\n# 2) Attention‑Pooling on face+hand velocity (CPU)\n# --------------------------------------------------\ndef pose_attn(uid):\n    buf    = open(f\"{VIDEO_POSE_DIR}/{uid}.pose\",\"rb\").read()\n    p      = Pose.read(buf)\n    coords = p.body.data.squeeze(1)[...,:2]   # (T,576,2)\n    T = coords.shape[0]\n    if T<2:\n        feat = np.zeros(510)\n    else:\n        face = coords[:,33:33+468]\n        lh   = coords[:,501:501+21]\n        rh   = coords[:,522:522+21]\n        pts  = np.concatenate([face,lh,rh],axis=1)   # (T,510,2)\n        diffs= np.linalg.norm(pts[1:]-pts[:-1],axis=2) # (T-1,510)\n        E    = np.linalg.norm(diffs,axis=1)           # (T-1,)\n        w    = E/(E.sum()+1e-6)\n        feat = (w[:,None]*diffs).sum(axis=0)           # (510,)\n    f = np.sign(feat)*np.sqrt(np.abs(feat)+1e-8)\n    return f/(np.linalg.norm(f)+1e-12)\n\nprint(\"Building attention‑velocity features…\")\nX_att_np    = np.stack(Parallel(n_jobs=-1)(delayed(pose_attn)(u) for u in proto_df.uid))\nX_att_te_np = np.stack(Parallel(n_jobs=-1)(delayed(pose_attn)(u) for u in test_df.uid))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:07:19.115689Z","iopub.execute_input":"2025-04-16T20:07:19.116007Z","iopub.status.idle":"2025-04-16T20:07:32.003943Z","shell.execute_reply.started":"2025-04-16T20:07:19.115962Z","shell.execute_reply":"2025-04-16T20:07:32.003167Z"}},"outputs":[{"name":"stdout","text":"Building attention‑velocity features…\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# --------------------------------------------------\n# 4) PCA‑Whiten scan (dims) on GPU sim — FIXED\n# --------------------------------------------------\nprint(\"\\n=== PCA‑Whiten scan (guided branch) ===\")\nbest_pca = (0.0, 0)\n# pre‑move labels once\ny_tr_t = torch.from_numpy(y_tr_idx).to(device)\ny_te_t = torch.from_numpy(y_te_idx).to(device)\n\nfor d in [128, 256, 512, 768, 1024]:\n    # 1) fit & transform on CPU\n    pca     = PCA(whiten=True, n_components=d).fit(X_guided_np)\n    Xp      = pca.transform(X_guided_np)\n    Xp_te   = pca.transform(X_guided_te_np)\n\n    # 2) push to GPU\n    Xp_t    = torch.from_numpy(Xp).float().to(device)     # (N_train, d)\n    Xp_te_t = torch.from_numpy(Xp_te).float().to(device)  # (N_test,  d)\n\n    # 3) cosine sim\n    S = F.normalize(Xp_te_t, dim=1) @ F.normalize(Xp_t, dim=1).T  # (N_test, N_train)\n\n    # 4) compute Top‑1/5/10\n    print(f\"\\ndim={d}:\")\n    for k in (1, 5, 10):\n        topk_idxs   = torch.topk(S, k, dim=1).indices   # (N_test, k)\n        pred_labels = y_tr_t[topk_idxs]                 # (N_test, k)\n        correct     = (pred_labels == y_te_t[:, None]) \\\n                          .any(dim=1) \\\n                          .float() \\\n                          .mean() \\\n                          .item() * 100\n        print(f\"  Top-{k}: {correct:.2f}%\")\n\n        # track best Top‑1\n        if k == 1 and correct > best_pca[0]:\n            best_pca = (correct, d)\n\nprint(f\"\\n>>> Best PCA dim={best_pca[1]} with Top-1={best_pca[0]:.2f}%\\n\")\n\n# 5) build best PCA once for downstream\npca        = PCA(whiten=True, n_components=best_pca[1]).fit(X_guided_np)\nX_pca_np   = pca.transform(X_guided_np)\nX_pca_te_np= pca.transform(X_guided_te_np)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T04:08:56.730050Z","iopub.execute_input":"2025-04-19T04:08:56.730867Z","iopub.status.idle":"2025-04-19T04:09:05.813015Z","shell.execute_reply.started":"2025-04-19T04:08:56.730840Z","shell.execute_reply":"2025-04-19T04:09:05.812317Z"}},"outputs":[{"name":"stdout","text":"\n=== PCA‑Whiten scan (guided branch) ===\n\ndim=128:\n  Top-1: 17.77%\n  Top-5: 22.32%\n  Top-10: 24.90%\n\ndim=256:\n  Top-1: 18.03%\n  Top-5: 23.15%\n  Top-10: 26.08%\n\ndim=512:\n  Top-1: 18.38%\n  Top-5: 23.81%\n  Top-10: 27.05%\n\ndim=768:\n  Top-1: 18.73%\n  Top-5: 24.64%\n  Top-10: 27.83%\n\ndim=1024:\n  Top-1: 19.56%\n  Top-5: 24.42%\n  Top-10: 26.87%\n\n>>> Best PCA dim=1024 with Top-1=19.56%\n\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# --------------------------------------------------\n# 5) Mahalanobis‑scale on guided\n# --------------------------------------------------\nvar     = X_guided_np.var(0)+1e-6\nW       = 1/np.sqrt(var)\nX_ms_np    = X_guided_np * W[None,:]\nX_ms_te_np = X_guided_te_np * W[None,:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T04:09:39.232981Z","iopub.execute_input":"2025-04-19T04:09:39.233707Z","iopub.status.idle":"2025-04-19T04:09:39.258748Z","shell.execute_reply.started":"2025-04-19T04:09:39.233683Z","shell.execute_reply":"2025-04-19T04:09:39.258222Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# --------------------------------------------------\n# 6) GPU‑accelerated branch eval\n# --------------------------------------------------\nbranches = {\n  \"GeM‑I3D\":     (X_gem_np,    X_gem_te_np),\n  \"Attn‑Vel\":    (X_att_np,    X_att_te_np),\n  \"Guided‑I3D\":  (X_guided_np, X_guided_te_np),\n  \"PCA‑guided\":  (X_pca_np,    X_pca_te_np),\n  \"Mahalanobis\": (X_ms_np,     X_ms_te_np),\n}\nfor name,(Xtr_np,Xte_np) in branches.items():\n    Xtr = torch.from_numpy(Xtr_np).float().to(device)\n    Xte = torch.from_numpy(Xte_np).float().to(device)\n    S = F.normalize(Xte,1) @ F.normalize(Xtr,1).T\n    print(f\"\\n--- {name} Only ---\")\n    for k in (1,5,10):\n        topk = torch.topk(S,k,1).indices  # (N_test,k)\n        labels_tr = torch.from_numpy(y_tr_idx).to(device)\n        labels_te = torch.from_numpy(y_te_idx).to(device)\n        pred = labels_tr[topk]            # (N_test,k)\n        acc = (pred.eq(labels_te[:,None]).any(1).float().mean().item()*100)\n        print(f\"Top-{k}: {acc:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T14:00:07.041972Z","iopub.execute_input":"2025-04-16T14:00:07.042294Z","iopub.status.idle":"2025-04-16T14:00:07.163029Z","shell.execute_reply.started":"2025-04-16T14:00:07.042271Z","shell.execute_reply":"2025-04-16T14:00:07.162301Z"}},"outputs":[{"name":"stdout","text":"\n--- GeM‑I3D Only ---\nTop-1: 11.64%\nTop-5: 17.68%\nTop-10: 20.04%\n\n--- Attn‑Vel Only ---\nTop-1: 0.00%\nTop-5: 0.31%\nTop-10: 0.44%\n\n--- Guided‑I3D Only ---\nTop-1: 13.13%\nTop-5: 17.99%\nTop-10: 21.09%\n\n--- PCA‑guided Only ---\nTop-1: 19.52%\nTop-5: 24.46%\nTop-10: 26.83%\n\n--- Mahalanobis Only ---\nTop-1: 13.57%\nTop-5: 19.34%\nTop-10: 22.19%\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# --------------------------------------------------\n# 7) Late‑fusion grid on GPU — FIXED\n# --------------------------------------------------\nprint(\"\\n=== Fusion grid (GeM, PCA, Mahalanobis) ===\")\n\n# pre‑push labels once\ny_tr_t = torch.from_numpy(y_tr_idx).to(device)  # (N_train,)\ny_te_t = torch.from_numpy(y_te_idx).to(device)  # (N_test,)\n\n# pre‑compute sim matrices\nS_gem = F.normalize(torch.from_numpy(X_gem_te_np).to(device), dim=1) \\\n        @ F.normalize(torch.from_numpy(X_gem_np).to(device), dim=1).T\nS_pca = F.normalize(torch.from_numpy(X_pca_te_np).to(device), dim=1) \\\n        @ F.normalize(torch.from_numpy(X_pca_np).to(device), dim=1).T\nS_ms  = F.normalize(torch.from_numpy(X_ms_te_np).to(device), dim=1) \\\n        @ F.normalize(torch.from_numpy(X_ms_np).to(device), dim=1).T\n\nbest_fuse = (0.0, (0.0, 0.0, 0.0))\nfor α, β in itertools.product(np.linspace(0,1,11), repeat=2):\n    γ = 1.0 - α - β\n    if γ < 0: \n        continue\n\n    # fuse sims\n    S = α * S_gem + β * S_pca + γ * S_ms  # (N_test, N_train)\n\n    # get Top-1 train‐indices per test\n    top1_idxs = torch.topk(S, 1, dim=1).indices.squeeze(1)  # (N_test,)\n\n    # map to predicted labels\n    pred_labels = y_tr_t[top1_idxs]                         # (N_test,)\n\n    # compute Top-1 accuracy\n    correct = (pred_labels == y_te_t).float().mean().item() * 100\n\n    if correct > best_fuse[0]:\n        best_fuse = (correct, (α, β, γ))\n\nprint(f\">>> Best fusion α,β,γ = {best_fuse[1]}, Top-1 = {best_fuse[0]:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T14:00:07.163707Z","iopub.execute_input":"2025-04-16T14:00:07.163878Z","iopub.status.idle":"2025-04-16T14:00:07.488184Z","shell.execute_reply.started":"2025-04-16T14:00:07.163864Z","shell.execute_reply":"2025-04-16T14:00:07.487627Z"}},"outputs":[{"name":"stdout","text":"\n=== Fusion grid (GeM, PCA, Mahalanobis) ===\n>>> Best fusion α,β,γ = (0.0, 1.0, 0.0), Top-1 = 19.56%\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"import itertools\n\nprint(\"\\n=== Late‑Fusion Hyperparam Sweep (Top‑1/5/10) ===\")\n# assume: S_gem, S_pca, S_ms are (N_test, N_train) CUDA tensors\n#         y_tr_t, y_te_t are CUDA tensors of shape (N_train,), (N_test,)\n\nfor α, β in itertools.product(np.linspace(0,1,11), repeat=2):\n    γ = 1.0 - α - β\n    if γ < 0:\n        continue\n\n    # fuse\n    S = α * S_gem + β * S_pca + γ * S_ms  # (N_test, N_train)\n\n    # header\n    print(f\"\\nα={α:.2f}, β={β:.2f}, γ={γ:.2f}\")\n\n    # compute Top‑k for k=1,5,10\n    for k in (1,5,10):\n        # get top‑k train‑indices for each test sample\n        topk_idxs   = torch.topk(S, k, dim=1).indices        # (N_test, k)\n        # map to train labels\n        pred_labels = y_tr_t[topk_idxs]                      # (N_test, k)\n        # compare to each test label\n        correct     = (pred_labels == y_te_t[:, None])       # (N_test, k) bool\n        acc         = correct.any(dim=1).float().mean().item() * 100\n        print(f\"  Top-{k}: {acc:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T14:00:07.488888Z","iopub.execute_input":"2025-04-16T14:00:07.489181Z","iopub.status.idle":"2025-04-16T14:00:07.910246Z","shell.execute_reply.started":"2025-04-16T14:00:07.489156Z","shell.execute_reply":"2025-04-16T14:00:07.909693Z"}},"outputs":[{"name":"stdout","text":"\n=== Late‑Fusion Hyperparam Sweep (Top‑1/5/10) ===\n\nα=0.00, β=0.00, γ=1.00\n  Top-1: 16.76%\n  Top-5: 20.70%\n  Top-10: 22.54%\n\nα=0.00, β=0.10, γ=0.90\n  Top-1: 17.99%\n  Top-5: 22.23%\n  Top-10: 24.64%\n\nα=0.00, β=0.20, γ=0.80\n  Top-1: 18.86%\n  Top-5: 23.11%\n  Top-10: 25.51%\n\nα=0.00, β=0.30, γ=0.70\n  Top-1: 19.08%\n  Top-5: 23.68%\n  Top-10: 26.13%\n\nα=0.00, β=0.40, γ=0.60\n  Top-1: 18.99%\n  Top-5: 24.07%\n  Top-10: 26.21%\n\nα=0.00, β=0.50, γ=0.50\n  Top-1: 19.12%\n  Top-5: 24.07%\n  Top-10: 26.74%\n\nα=0.00, β=0.60, γ=0.40\n  Top-1: 19.26%\n  Top-5: 24.20%\n  Top-10: 26.91%\n\nα=0.00, β=0.70, γ=0.30\n  Top-1: 19.34%\n  Top-5: 24.38%\n  Top-10: 26.96%\n\nα=0.00, β=0.80, γ=0.20\n  Top-1: 19.34%\n  Top-5: 24.33%\n  Top-10: 27.00%\n\nα=0.00, β=0.90, γ=0.10\n  Top-1: 19.43%\n  Top-5: 24.33%\n  Top-10: 26.96%\n\nα=0.00, β=1.00, γ=0.00\n  Top-1: 19.56%\n  Top-5: 24.42%\n  Top-10: 26.87%\n\nα=0.10, β=0.00, γ=0.90\n  Top-1: 16.85%\n  Top-5: 20.74%\n  Top-10: 22.54%\n\nα=0.10, β=0.10, γ=0.80\n  Top-1: 18.03%\n  Top-5: 22.23%\n  Top-10: 24.73%\n\nα=0.10, β=0.20, γ=0.70\n  Top-1: 18.91%\n  Top-5: 23.11%\n  Top-10: 25.65%\n\nα=0.10, β=0.30, γ=0.60\n  Top-1: 19.04%\n  Top-5: 23.72%\n  Top-10: 26.30%\n\nα=0.10, β=0.40, γ=0.50\n  Top-1: 19.04%\n  Top-5: 24.07%\n  Top-10: 26.35%\n\nα=0.10, β=0.50, γ=0.40\n  Top-1: 19.17%\n  Top-5: 24.11%\n  Top-10: 26.83%\n\nα=0.10, β=0.60, γ=0.30\n  Top-1: 19.30%\n  Top-5: 24.29%\n  Top-10: 27.09%\n\nα=0.10, β=0.70, γ=0.20\n  Top-1: 19.34%\n  Top-5: 24.33%\n  Top-10: 26.96%\n\nα=0.10, β=0.80, γ=0.10\n  Top-1: 19.39%\n  Top-5: 24.38%\n  Top-10: 27.05%\n\nα=0.10, β=0.90, γ=0.00\n  Top-1: 19.39%\n  Top-5: 24.42%\n  Top-10: 27.13%\n\nα=0.20, β=0.00, γ=0.80\n  Top-1: 16.85%\n  Top-5: 20.92%\n  Top-10: 22.58%\n\nα=0.20, β=0.10, γ=0.70\n  Top-1: 18.12%\n  Top-5: 22.36%\n  Top-10: 24.60%\n\nα=0.20, β=0.20, γ=0.60\n  Top-1: 18.99%\n  Top-5: 23.15%\n  Top-10: 25.86%\n\nα=0.20, β=0.30, γ=0.50\n  Top-1: 19.04%\n  Top-5: 23.81%\n  Top-10: 26.21%\n\nα=0.20, β=0.40, γ=0.40\n  Top-1: 19.17%\n  Top-5: 24.11%\n  Top-10: 26.56%\n\nα=0.20, β=0.50, γ=0.30\n  Top-1: 19.26%\n  Top-5: 24.20%\n  Top-10: 26.83%\n\nα=0.20, β=0.60, γ=0.20\n  Top-1: 19.34%\n  Top-5: 24.29%\n  Top-10: 27.13%\n\nα=0.20, β=0.70, γ=0.10\n  Top-1: 19.43%\n  Top-5: 24.46%\n  Top-10: 26.96%\n\nα=0.20, β=0.80, γ=0.00\n  Top-1: 19.39%\n  Top-5: 24.46%\n  Top-10: 27.05%\n\nα=0.30, β=0.00, γ=0.70\n  Top-1: 16.89%\n  Top-5: 21.14%\n  Top-10: 22.71%\n\nα=0.30, β=0.10, γ=0.60\n  Top-1: 18.25%\n  Top-5: 22.45%\n  Top-10: 24.55%\n\nα=0.30, β=0.20, γ=0.50\n  Top-1: 18.91%\n  Top-5: 23.33%\n  Top-10: 26.13%\n\nα=0.30, β=0.30, γ=0.40\n  Top-1: 18.99%\n  Top-5: 23.85%\n  Top-10: 26.39%\n\nα=0.30, β=0.40, γ=0.30\n  Top-1: 19.17%\n  Top-5: 24.03%\n  Top-10: 26.70%\n\nα=0.30, β=0.50, γ=0.20\n  Top-1: 19.26%\n  Top-5: 24.25%\n  Top-10: 27.00%\n\nα=0.30, β=0.60, γ=0.10\n  Top-1: 19.30%\n  Top-5: 24.38%\n  Top-10: 27.09%\n\nα=0.40, β=0.00, γ=0.60\n  Top-1: 16.98%\n  Top-5: 21.36%\n  Top-10: 22.76%\n\nα=0.40, β=0.10, γ=0.50\n  Top-1: 18.29%\n  Top-5: 22.58%\n  Top-10: 24.73%\n\nα=0.40, β=0.20, γ=0.40\n  Top-1: 18.86%\n  Top-5: 23.33%\n  Top-10: 26.17%\n\nα=0.40, β=0.30, γ=0.30\n  Top-1: 18.99%\n  Top-5: 23.81%\n  Top-10: 26.56%\n\nα=0.40, β=0.40, γ=0.20\n  Top-1: 19.17%\n  Top-5: 24.11%\n  Top-10: 26.74%\n\nα=0.40, β=0.50, γ=0.10\n  Top-1: 19.17%\n  Top-5: 24.20%\n  Top-10: 27.00%\n\nα=0.50, β=0.00, γ=0.50\n  Top-1: 17.11%\n  Top-5: 21.23%\n  Top-10: 22.93%\n\nα=0.50, β=0.10, γ=0.40\n  Top-1: 18.56%\n  Top-5: 22.63%\n  Top-10: 24.81%\n\nα=0.50, β=0.20, γ=0.30\n  Top-1: 18.99%\n  Top-5: 23.41%\n  Top-10: 26.21%\n\nα=0.50, β=0.30, γ=0.20\n  Top-1: 18.91%\n  Top-5: 23.89%\n  Top-10: 26.56%\n\nα=0.50, β=0.40, γ=0.10\n  Top-1: 19.17%\n  Top-5: 24.16%\n  Top-10: 26.91%\n\nα=0.50, β=0.50, γ=0.00\n  Top-1: 19.21%\n  Top-5: 24.38%\n  Top-10: 27.00%\n\nα=0.60, β=0.00, γ=0.40\n  Top-1: 17.16%\n  Top-5: 21.14%\n  Top-10: 22.89%\n\nα=0.60, β=0.10, γ=0.30\n  Top-1: 18.42%\n  Top-5: 22.63%\n  Top-10: 24.77%\n\nα=0.60, β=0.20, γ=0.20\n  Top-1: 18.86%\n  Top-5: 23.54%\n  Top-10: 25.95%\n\nα=0.60, β=0.30, γ=0.10\n  Top-1: 19.04%\n  Top-5: 23.89%\n  Top-10: 26.56%\n\nα=0.70, β=0.00, γ=0.30\n  Top-1: 17.16%\n  Top-5: 21.14%\n  Top-10: 22.93%\n\nα=0.70, β=0.10, γ=0.20\n  Top-1: 18.51%\n  Top-5: 22.58%\n  Top-10: 24.77%\n\nα=0.70, β=0.20, γ=0.10\n  Top-1: 18.86%\n  Top-5: 23.63%\n  Top-10: 25.86%\n\nα=0.80, β=0.00, γ=0.20\n  Top-1: 17.16%\n  Top-5: 20.83%\n  Top-10: 23.06%\n\nα=0.80, β=0.10, γ=0.10\n  Top-1: 18.47%\n  Top-5: 22.54%\n  Top-10: 24.77%\n\nα=0.90, β=0.00, γ=0.10\n  Top-1: 17.16%\n  Top-5: 20.61%\n  Top-10: 22.93%\n\nα=1.00, β=0.00, γ=0.00\n  Top-1: 17.07%\n  Top-5: 20.61%\n  Top-10: 22.71%\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.cluster import MiniBatchKMeans\nfrom sklearn.preprocessing import normalize\nfrom pose_format import Pose","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T14:00:07.910978Z","iopub.execute_input":"2025-04-16T14:00:07.911260Z","iopub.status.idle":"2025-04-16T14:00:08.089226Z","shell.execute_reply.started":"2025-04-16T14:00:07.911236Z","shell.execute_reply":"2025-04-16T14:00:08.088501Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# -----------------------------------------------------------------------------\n# 1) NetVLAD pooling over I3D segment‑features\n# -----------------------------------------------------------------------------\nprint(\"=== Building NetVLAD I3D features ===\")\n# collect all segment‑vectors from prototypes\nall_segs = []\nuids = []\nfor u in proto_df.uid:\n    arr = i3d_dict[u].squeeze((0,3,4))  # (1024, S)\n    for vec in arr.T:                   # S × (1024,)\n        all_segs.append(vec)\n        uids.append(u)\nall_segs = np.stack(all_segs)          # (N_segs, 1024)\n\n# fit a small KMeans\nK = 8\nkm = MiniBatchKMeans(n_clusters=K, random_state=0, batch_size=4096)\nkm.fit(all_segs)\n\ncenters = km.cluster_centers_          # (K, 1024)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T14:00:08.090045Z","iopub.execute_input":"2025-04-16T14:00:08.090287Z","iopub.status.idle":"2025-04-16T14:00:10.185874Z","shell.execute_reply.started":"2025-04-16T14:00:08.090271Z","shell.execute_reply":"2025-04-16T14:00:10.185308Z"}},"outputs":[{"name":"stdout","text":"=== Building NetVLAD I3D features ===\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"def vlad_feat(uid):\n    arr = i3d_dict[uid].squeeze((0,3,4)).T  # (S,1024)\n    # assign each segment to a cluster\n    labels = km.predict(arr)\n    vlad   = np.zeros((K, 1024), dtype=np.float32)\n    for i,lab in enumerate(labels):\n        vlad[lab] += (arr[i] - centers[lab])\n    v = vlad.reshape(-1)                     # (K*1024,)\n    v = np.sign(v)*np.sqrt(np.abs(v)+1e-8)\n    return v/np.linalg.norm(v)\n\n# build prototype & test VLAD features\nX_vlad    = np.stack([vlad_feat(u) for u in proto_df.uid])\nX_vlad_te = np.stack([vlad_feat(u) for u in test_df.uid])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T14:00:10.186394Z","iopub.execute_input":"2025-04-16T14:00:10.186575Z","iopub.status.idle":"2025-04-16T14:00:13.521103Z","shell.execute_reply.started":"2025-04-16T14:00:10.186559Z","shell.execute_reply":"2025-04-16T14:00:13.520552Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# -----------------------------------------------------------------------------\n# 2) Joint‑angle features from pose (elbows)\n# -----------------------------------------------------------------------------\nprint(\"=== Building joint‑angle features ===\")\n# MediaPipe pose indices: left shoulder=11, left elbow=13, left wrist=15;\n#                         right shoulder=12, right elbow=14, right wrist=16\ndef angle_feat(uid):\n    buf    = open(f\"{VIDEO_POSE_DIR}/{uid}.pose\",\"rb\").read()\n    p      = Pose.read(buf)\n    coords = p.body.data.squeeze(1)[...,:2]  # (T,576,2)\n    T = coords.shape[0]\n    if T<2:\n        return np.zeros(4)\n    def compute_angle(a,b,c):\n        ba = a - b\n        bc = c - b\n        cos = np.sum(ba*bc,axis=1) / (np.linalg.norm(ba,axis=1)*np.linalg.norm(bc,axis=1)+1e-6)\n        return np.arccos(np.clip(cos,-1,1))    # (T,)\n    L = compute_angle(coords[:,11], coords[:,13], coords[:,15])\n    R = compute_angle(coords[:,12], coords[:,14], coords[:,16])\n    feat = np.array([L.mean(), L.std(), R.mean(), R.std()],dtype=np.float32)\n    return feat/np.linalg.norm(feat)\n\nX_ang    = np.stack([angle_feat(u) for u in proto_df.uid])\nX_ang_te = np.stack([angle_feat(u) for u in test_df.uid])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T14:00:13.521987Z","iopub.execute_input":"2025-04-16T14:00:13.522215Z","iopub.status.idle":"2025-04-16T14:00:34.507569Z","shell.execute_reply.started":"2025-04-16T14:00:13.522178Z","shell.execute_reply":"2025-04-16T14:00:34.507036Z"}},"outputs":[{"name":"stdout","text":"=== Building joint‑angle features ===\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# -----------------------------------------------------------------------------\n# 3) Half‑crop I3D features (temporal TTA)\n# -----------------------------------------------------------------------------\nprint(\"=== Building half‑crop I3D features ===\")\ndef improved_i3d_half(uid):\n    arr = i3d_dict[uid].squeeze((0,3,4))  # (1024, S)\n    S   = arr.shape[1]\n    def feat(a):\n        m,M,s = a.mean(axis=1), a.max(axis=1), a.std(axis=1)\n        f = np.concatenate([m,M,s])\n        f = np.sign(f)*np.sqrt(np.abs(f)+1e-8)\n        return f/np.linalg.norm(f)\n    if S<2:\n        return feat(arr)\n    mid = S//2\n    f1 = feat(arr[:,:mid])\n    f2 = feat(arr[:,mid:])\n    f  = (f1 + f2) * 0.5\n    return f/np.linalg.norm(f)\n\nX_half    = np.stack([improved_i3d_half(u) for u in proto_df.uid])\nX_half_te = np.stack([improved_i3d_half(u) for u in test_df.uid])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T14:00:34.508730Z","iopub.execute_input":"2025-04-16T14:00:34.508911Z","iopub.status.idle":"2025-04-16T14:00:39.333852Z","shell.execute_reply.started":"2025-04-16T14:00:34.508896Z","shell.execute_reply":"2025-04-16T14:00:39.333243Z"}},"outputs":[{"name":"stdout","text":"=== Building half‑crop I3D features ===\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# -----------------------------------------------------------------------------\n# Evaluate all new branches via pure cosine one‑shot\n# -----------------------------------------------------------------------------\nbranches_new = {\n  \"NetVLAD‑I3D\": X_vlad,    \"NetVLAD‑I3D (test)\": X_vlad_te,\n  \"Angle‑feat\":  X_ang,     \"Angle‑feat (test)\":  X_ang_te,\n  \"Half‑crop\":   X_half,    \"Half‑crop (test)\":   X_half_te,\n}\n\nprint(\"\\n=== New Branches Evaluation ===\")\nfor name in [\"NetVLAD‑I3D\", \"Angle‑feat\", \"Half‑crop\"]:\n    Xtr = branches_new[name]\n    Xte = branches_new[name+\" (test)\"]\n    S = normalize(Xte,axis=1).dot(normalize(Xtr,axis=1).T)\n    print(f\"\\n--- {name} Only ---\")\n    for k in (1,5,10):\n        acc = topk_from_S(S, y_tr, y_te, k)\n        print(f\"Top-{k}: {acc:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T14:00:39.334738Z","iopub.execute_input":"2025-04-16T14:00:39.335028Z","iopub.status.idle":"2025-04-16T14:00:43.515330Z","shell.execute_reply.started":"2025-04-16T14:00:39.335009Z","shell.execute_reply":"2025-04-16T14:00:43.514705Z"}},"outputs":[{"name":"stdout","text":"\n=== New Branches Evaluation ===\n\n--- NetVLAD‑I3D Only ---\nTop-1: 16.67%\nTop-5: 20.83%\nTop-10: 23.46%\n\n--- Angle‑feat Only ---\nTop-1: 5.56%\nTop-5: 8.49%\nTop-10: 9.93%\n\n--- Half‑crop Only ---\nTop-1: 16.89%\nTop-5: 21.05%\nTop-10: 22.84%\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"from sklearn.decomposition import PCA\nfrom sklearn.preprocessing import normalize\n\n# 1a) stack the best features\n#   X_pca_np    (N_train, D1)\n#   X_vlad      (N_train, D2)\n#   X_half      (N_train, D3)\nX_fuse_tr = np.concatenate([X_pca_np, X_vlad, X_half], axis=1)      # (N_train, D1+D2+D3)\nX_fuse_te = np.concatenate([X_pca_te_np, X_vlad_te, X_half_te], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T14:00:43.516015Z","iopub.execute_input":"2025-04-16T14:00:43.516232Z","iopub.status.idle":"2025-04-16T14:00:43.648490Z","shell.execute_reply.started":"2025-04-16T14:00:43.516215Z","shell.execute_reply":"2025-04-16T14:00:43.647678Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"# 1b) final PCA‑whiten back down to ~1024 dims\nFINAL_DIM = 1024\npca_fuse = PCA(whiten=True, n_components=FINAL_DIM).fit(X_fuse_tr)\nX_fuse_tr_p = pca_fuse.transform(X_fuse_tr)    # (N_train, FINAL_DIM)\nX_fuse_te_p = pca_fuse.transform(X_fuse_te)    # (N_test,  FINAL_DIM)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T14:00:43.649452Z","iopub.execute_input":"2025-04-16T14:00:43.649668Z","iopub.status.idle":"2025-04-16T14:00:54.068299Z","shell.execute_reply.started":"2025-04-16T14:00:43.649651Z","shell.execute_reply":"2025-04-16T14:00:54.067657Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"# 1c) cosine one‑shot eval\nS = normalize(X_fuse_te_p,axis=1).dot(normalize(X_fuse_tr_p,axis=1).T)\nprint(\"\\n--- Feature‑Fusion PCA‑whiten ---\")\nfor k in (1,5,10):\n    acc = topk_from_S(S, y_tr, y_te, k)\n    print(f\"Top-{k}: {acc:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T14:00:54.069144Z","iopub.execute_input":"2025-04-16T14:00:54.069374Z","iopub.status.idle":"2025-04-16T14:00:55.142768Z","shell.execute_reply.started":"2025-04-16T14:00:54.069356Z","shell.execute_reply":"2025-04-16T14:00:55.142162Z"}},"outputs":[{"name":"stdout","text":"\n--- Feature‑Fusion PCA‑whiten ---\nTop-1: 19.56%\nTop-5: 24.42%\nTop-10: 26.91%\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"def aqe(X_tr, X_te, alpha=3.0, k=5):\n    \"\"\"\n    X_tr: (N_train, D), X_te: (N_test, D) — already L2‑normalized\n    returns X_te_exp: (N_test, D) L2‑normalized query‑expanded features\n    \"\"\"\n    # initial sim\n    S0 = X_te.dot(X_tr.T)            # (N_test, N_train)\n    N_test = X_te.shape[0]\n    X_te_exp = np.zeros_like(X_te)\n    for i in range(N_test):\n        topk_idx = np.argsort(-S0[i])[:k]\n        # weighted average: 1×query + alpha×sum(neighbors)\n        v = X_te[i] + alpha * X_tr[topk_idx].sum(axis=0)\n        X_te_exp[i] = v / (np.linalg.norm(v)+1e-12)\n    return X_te_exp","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T04:04:36.651603Z","iopub.execute_input":"2025-04-19T04:04:36.651901Z","iopub.status.idle":"2025-04-19T04:04:36.657204Z","shell.execute_reply.started":"2025-04-19T04:04:36.651878Z","shell.execute_reply":"2025-04-19T04:04:36.656215Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# 2a) prepare normalized PCA‑guided features\nX_pg_n    = normalize(X_pca_np,axis=1)\nX_pg_te_n = normalize(X_pca_te_np,axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T04:10:07.564831Z","iopub.execute_input":"2025-04-19T04:10:07.565426Z","iopub.status.idle":"2025-04-19T04:10:07.591512Z","shell.execute_reply.started":"2025-04-19T04:10:07.565401Z","shell.execute_reply":"2025-04-19T04:10:07.590927Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# 2b) AQE sweep over (alpha, k)\nprint(\"\\n=== AQE sweep ===\")\nfor alpha in [1.0,2.0,3.0,5.0]:\n    for k in [1,3,5,10]:\n        Xq = aqe(X_pg_n, X_pg_te_n, alpha=alpha, k=k)\n        S  = Xq.dot(X_pg_n.T)\n        acc1 = topk_from_S(S, y_tr, y_te, 1)\n        print(f\"α={alpha}, k={k} → Top-1: {acc1:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T14:00:55.183593Z","iopub.execute_input":"2025-04-16T14:00:55.183809Z","iopub.status.idle":"2025-04-16T14:01:09.958145Z","shell.execute_reply.started":"2025-04-16T14:00:55.183795Z","shell.execute_reply":"2025-04-16T14:01:09.957459Z"}},"outputs":[{"name":"stdout","text":"\n=== AQE sweep ===\nα=1.0, k=1 → Top-1: 19.56%\nα=1.0, k=3 → Top-1: 18.42%\nα=1.0, k=5 → Top-1: 17.72%\nα=1.0, k=10 → Top-1: 17.02%\nα=2.0, k=1 → Top-1: 19.56%\nα=2.0, k=3 → Top-1: 17.16%\nα=2.0, k=5 → Top-1: 16.54%\nα=2.0, k=10 → Top-1: 16.41%\nα=3.0, k=1 → Top-1: 19.56%\nα=3.0, k=3 → Top-1: 16.85%\nα=3.0, k=5 → Top-1: 16.28%\nα=3.0, k=10 → Top-1: 16.11%\nα=5.0, k=1 → Top-1: 19.56%\nα=5.0, k=3 → Top-1: 16.63%\nα=5.0, k=5 → Top-1: 15.89%\nα=5.0, k=10 → Top-1: 15.97%\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"# 2b) AQE sweep over (alpha, k)\nprint(\"\\n=== AQE sweep ===\")\nfor alpha in [1.0, 2.0, 3.0, 5.0]:\n    for k in [1, 3, 5, 10]:\n        # apply AQE\n        Xq = aqe(X_pg_n, X_pg_te_n, alpha=alpha, k=k)\n        S  = Xq.dot(X_pg_n.T)\n\n        # compute Top-1, Top-5, Top-10\n        acc1  = topk_from_S(S, y_tr, y_te, 1)\n        acc5  = topk_from_S(S, y_tr, y_te, 5)\n        acc10 = topk_from_S(S, y_tr, y_te, 10)\n\n        print(f\"α={alpha}, k={k} → \"\n              f\"Top‑1:  {acc1:.2f}%, \"\n              f\"Top‑5:  {acc5:.2f}%, \"\n              f\"Top‑10: {acc10:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T04:15:34.594442Z","iopub.execute_input":"2025-04-19T04:15:34.595435Z","iopub.status.idle":"2025-04-19T04:16:00.978206Z","shell.execute_reply.started":"2025-04-19T04:15:34.595400Z","shell.execute_reply":"2025-04-19T04:16:00.977328Z"}},"outputs":[{"name":"stdout","text":"\n=== AQE sweep ===\nα=1.0, k=1 → Top‑1:  19.56%, Top‑5:  23.02%, Top‑10: 25.34%\nα=1.0, k=3 → Top‑1:  18.42%, Top‑5:  23.81%, Top‑10: 25.73%\nα=1.0, k=5 → Top‑1:  17.72%, Top‑5:  24.42%, Top‑10: 26.21%\nα=1.0, k=10 → Top‑1:  17.02%, Top‑5:  23.28%, Top‑10: 26.83%\nα=2.0, k=1 → Top‑1:  19.56%, Top‑5:  22.01%, Top‑10: 24.46%\nα=2.0, k=3 → Top‑1:  17.16%, Top‑5:  23.63%, Top‑10: 25.43%\nα=2.0, k=5 → Top‑1:  16.54%, Top‑5:  24.42%, Top‑10: 26.00%\nα=2.0, k=10 → Top‑1:  16.41%, Top‑5:  22.89%, Top‑10: 26.83%\nα=3.0, k=1 → Top‑1:  19.56%, Top‑5:  21.79%, Top‑10: 23.50%\nα=3.0, k=3 → Top‑1:  16.85%, Top‑5:  23.54%, Top‑10: 25.08%\nα=3.0, k=5 → Top‑1:  16.28%, Top‑5:  24.42%, Top‑10: 26.00%\nα=3.0, k=10 → Top‑1:  16.11%, Top‑5:  22.71%, Top‑10: 26.83%\nα=5.0, k=1 → Top‑1:  19.56%, Top‑5:  21.44%, Top‑10: 22.89%\nα=5.0, k=3 → Top‑1:  16.63%, Top‑5:  23.37%, Top‑10: 25.03%\nα=5.0, k=5 → Top‑1:  15.89%, Top‑5:  24.42%, Top‑10: 25.91%\nα=5.0, k=10 → Top‑1:  15.97%, Top‑5:  22.58%, Top‑10: 26.83%\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"print(\"=== ZCA Whitening on guided‑I3D ===\")\nX = X_guided_np - X_guided_np.mean(0)      # center\n# compute covariance\nC = (X.T @ X) / X.shape[0]                 # (D,D)\n# SVD\nU, S, _ = np.linalg.svd(C, full_matrices=False)\n# ZCA matrix\nZ = U @ np.diag(1.0/np.sqrt(S + 1e-6)) @ U.T\n# apply\nX_zca    = (X_guided_np - X_guided_np.mean(0)) @ Z\nX_zca_te = (X_guided_te_np - X_guided_np.mean(0)) @ Z\n# normalize + sim\nXz_n     = normalize(X_zca,   axis=1)\nXz_te_n  = normalize(X_zca_te,axis=1)\nS_zca    = Xz_te_n.dot(Xz_n.T)\nprint(\"ZCA‑Top‑1/5/10:\",\n      topk_from_S(S_zca,y_tr,y_te,1),\n      topk_from_S(S_zca,y_tr,y_te,5),\n      topk_from_S(S_zca,y_tr,y_te,10))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T14:01:09.961360Z","iopub.execute_input":"2025-04-16T14:01:09.961782Z","iopub.status.idle":"2025-04-16T14:01:11.564423Z","shell.execute_reply.started":"2025-04-16T14:01:09.961763Z","shell.execute_reply":"2025-04-16T14:01:11.563609Z"}},"outputs":[{"name":"stdout","text":"=== ZCA Whitening on guided‑I3D ===\nZCA‑Top‑1/5/10: 19.474835886214443 24.551422319474835 27.39606126914661\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"# 2) Ridge‑regression distillation from guided → NetVLAD\nprint(\"=== Distilling guided → NetVLAD ===\")\nG = X_guided_np        # (N_train, Dg)\nV = X_vlad             # (N_train, Dv)\nλ = 0.1\n# solve (GᵀG + λI) W = GᵀV  =>  W: Dg×Dv\nW = np.linalg.solve(G.T @ G + λ*np.eye(G.shape[1]), G.T @ V)\n# map test\nVq = X_guided_te_np @ W  # (N_test, Dv)\n# normalize + sim\nV_n  = normalize(V,axis=1)\nVq_n = normalize(Vq,axis=1)\nS_ds = Vq_n.dot(V_n.T)\nprint(\"Distill‑Top‑1/5/10:\",\n      topk_from_S(S_ds,y_tr,y_te,1),\n      topk_from_S(S_ds,y_tr,y_te,5),\n      topk_from_S(S_ds,y_tr,y_te,10))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T14:01:11.565271Z","iopub.execute_input":"2025-04-16T14:01:11.565544Z","iopub.status.idle":"2025-04-16T14:01:15.894140Z","shell.execute_reply.started":"2025-04-16T14:01:11.565518Z","shell.execute_reply":"2025-04-16T14:01:15.893366Z"}},"outputs":[{"name":"stdout","text":"=== Distilling guided → NetVLAD ===\nDistill‑Top‑1/5/10: 16.192560175054705 20.787746170678336 23.457330415754925\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"# -----------------------------------------------------------------------------\n# Subspace Matching (safe pairwise version)\n# -----------------------------------------------------------------------------\nprint(\"=== Subspace Matching (fixed + safe pairwise loop) ===\")\nk_sub = 5\n\ndef subspace_basis(uid, k=k_sub):\n    A = i3d_dict[uid].squeeze((0, 3, 4))   # (1024, S)\n    U, _, _ = np.linalg.svd(A, full_matrices=False)\n    S = A.shape[1]\n    B = np.zeros((1024, k), dtype=np.float32)\n    use = min(S, k)\n    B[:, :use] = U[:, :use]               # pad with zeros if S < k\n    return B                              # (1024, k)\n\n# build bases\nprint(\"  → computing bases…\")\nU_tr = [subspace_basis(u) for u in proto_df.uid]\nU_te = [subspace_basis(u) for u in test_df.uid]\n\n# compute similarity: ||Uᵢᵗ Uⱼ||_F^2\nprint(\"  → computing pairwise similarities…\")\nN_te, N_tr = len(U_te), len(U_tr)\nS_sub = np.zeros((N_te, N_tr), dtype=np.float32)\nfor i in range(N_te):\n    Ui = U_te[i]\n    for j in range(N_tr):\n        Uj = U_tr[j]\n        M = Ui.T @ Uj\n        S_sub[i, j] = np.sum(M * M)  # Frobenius norm squared\n\n# evaluate\nprint(\"\\n=== Subspace Matching Results ===\")\nfor k in (1, 5, 10):\n    acc = topk_from_S(S_sub, y_tr, y_te, k)\n    print(f\"Top-{k}: {acc:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T14:01:15.895124Z","iopub.execute_input":"2025-04-16T14:01:15.895657Z","iopub.status.idle":"2025-04-16T14:03:30.897669Z","shell.execute_reply.started":"2025-04-16T14:01:15.895635Z","shell.execute_reply":"2025-04-16T14:03:30.896987Z"}},"outputs":[{"name":"stdout","text":"=== Subspace Matching (fixed + safe pairwise loop) ===\n  → computing bases…\n  → computing pairwise similarities…\n\n=== Subspace Matching Results ===\nTop-1: 17.77%\nTop-5: 22.36%\nTop-10: 25.16%\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"# ----------------------------------------\n# 1) Delta / Delta‑Delta I3D branch\n# ----------------------------------------\nimport numpy as np\nfrom sklearn.preprocessing import normalize\n\ndef delta_i3d_feat(uid):\n    # arr: (1024, S)\n    arr = i3d_dict[uid].squeeze((0,3,4))\n    # first‐order diff → pad back to S\n    d1  = np.diff(arr, axis=1)\n    d1  = np.pad(d1, ((0,0),(0,1)), mode='constant')\n    # second‐order diff\n    d2  = np.diff(d1, axis=1)\n    d2  = np.pad(d2, ((0,0),(0,1)), mode='constant')\n    # SSR pooling on both diffs\n    m1,M1,s1 = d1.mean(1), d1.max(1), d1.std(1)\n    m2,M2,s2 = d2.mean(1), d2.max(1), d2.std(1)\n    feat = np.concatenate([m1,M1,s1, m2,M2,s2])\n    feat = np.sign(feat)*np.sqrt(np.abs(feat)+1e-8)\n    return feat / np.linalg.norm(feat)\n\n# build\nX_d    = np.stack([delta_i3d_feat(u) for u in proto_df.uid])\nX_d_te = np.stack([delta_i3d_feat(u) for u in test_df.uid])\n\n# sim + eval\nS_d = normalize(X_d_te,axis=1) @ normalize(X_d,axis=1).T\nprint(\"\\n--- Delta‑I3D Only ---\")\nfor k in (1,5,10):\n    print(f\"Top-{k}: {topk_from_S(S_d, y_tr, y_te, k):.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T14:03:30.898451Z","iopub.execute_input":"2025-04-16T14:03:30.898668Z","iopub.status.idle":"2025-04-16T14:03:38.677276Z","shell.execute_reply.started":"2025-04-16T14:03:30.898650Z","shell.execute_reply":"2025-04-16T14:03:38.676456Z"}},"outputs":[{"name":"stdout","text":"\n--- Delta‑I3D Only ---\nTop-1: 16.50%\nTop-5: 20.22%\nTop-10: 21.44%\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"# ----------------------------------------\n# NEW ONE‑SHOT BRANCHES: DELTA, HADAMARD, GEOMETRIC FUSION\n# ----------------------------------------\nimport numpy as np\nfrom sklearn.preprocessing import normalize\n\n# re‑define your two existing featurizers:\ndef improved_i3d_feat(uid):\n    arr = i3d_dict[uid].squeeze((0,3,4))  # (1024, S)\n    m,M,s = arr.mean(1), arr.max(1), arr.std(1)\n    f = np.concatenate([m,M,s])\n    f = np.sign(f)*np.sqrt(np.abs(f)+1e-8)\n    return f/np.linalg.norm(f)\n\ndef pose_velocity_feat(uid):\n    buf    = open(f\"{VIDEO_POSE_DIR}/{uid}.pose\",\"rb\").read()\n    p      = Pose.read(buf)\n    coords = p.body.data.squeeze(1)[...,:2]  # (T,576,2)\n    if coords.shape[0]<2:\n        feat = np.zeros(510*2)\n    else:\n        face = coords[:,33:33+468]\n        lh   = coords[:,501:501+21]\n        rh   = coords[:,522:522+21]\n        pts  = np.concatenate([face,lh,rh],axis=1)  # (T,510,2)\n        diffs= np.linalg.norm(pts[1:]-pts[:-1],axis=2)  # (T-1,510)\n        feat = np.concatenate([diffs.mean(0), diffs.max(0)])  # (1020,)\n    feat = np.sign(feat)*np.sqrt(np.abs(feat)+1e-8)\n    return feat/np.linalg.norm(feat)\n\n# ----------------------------------------------------------------\n# 1) Delta / Delta‑Delta I3D\n# ----------------------------------------------------------------\ndef delta_i3d_feat(uid):\n    arr = i3d_dict[uid].squeeze((0,3,4))  # (1024, S)\n    d1  = np.pad(np.diff(arr,axis=1), ((0,0),(0,1)), 'constant')\n    d2  = np.pad(np.diff(d1,axis=1), ((0,0),(0,1)), 'constant')\n    m1,M1,s1 = d1.mean(1), d1.max(1), d1.std(1)\n    m2,M2,s2 = d2.mean(1), d2.max(1), d2.std(1)\n    f = np.concatenate([m1,M1,s1, m2,M2,s2])\n    f = np.sign(f)*np.sqrt(np.abs(f)+1e-8)\n    return f/np.linalg.norm(f)\n\nX_d    = np.stack([delta_i3d_feat(u) for u in proto_df.uid])\nX_d_te = np.stack([delta_i3d_feat(u) for u in test_df.uid])\nS_d    = normalize(X_d_te,axis=1) @ normalize(X_d,axis=1).T\n\nprint(\"\\n--- Delta‑I3D Only ---\")\nfor k in (1,5,10):\n    print(f\"Top-{k}: {topk_from_S(S_d, y_tr, y_te, k):.2f}%\")\n\n# ----------------------------------------------------------------\n# 2) Hadamard (I3D × Velocity)\n# ----------------------------------------------------------------\ndef hadamard_feat(uid):\n    f = improved_i3d_feat(uid)      # 3072‑d\n    v = pose_velocity_feat(uid)     # 1020‑d\n    # pad v → 3072\n    if v.shape[0] < f.shape[0]:\n        v = np.pad(v, (0, f.shape[0]-v.shape[0]), 'constant')\n    z = f * v\n    z = np.sign(z)*np.sqrt(np.abs(z)+1e-8)\n    return z/np.linalg.norm(z)\n\nX_h    = np.stack([hadamard_feat(u) for u in proto_df.uid])\nX_h_te = np.stack([hadamard_feat(u) for u in test_df.uid])\nS_h    = normalize(X_h_te,axis=1) @ normalize(X_h,axis=1).T\n\nprint(\"\\n--- Hadamard I3D×Vel Only ---\")\nfor k in (1,5,10):\n    print(f\"Top-{k}: {topk_from_S(S_h, y_tr, y_te, k):.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T19:14:19.704041Z","iopub.execute_input":"2025-04-16T19:14:19.704374Z","iopub.status.idle":"2025-04-16T19:16:26.847432Z","shell.execute_reply.started":"2025-04-16T19:14:19.704354Z","shell.execute_reply":"2025-04-16T19:16:26.846621Z"}},"outputs":[{"name":"stdout","text":"\n--- Delta‑I3D Only ---\nTop-1: 16.50%\nTop-5: 20.22%\nTop-10: 21.44%\n\n--- Hadamard I3D×Vel Only ---\nTop-1: 13.52%\nTop-5: 17.07%\nTop-10: 18.95%\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# ----------------------------------------\n# 3) Geometric fusion of PCA‑whiten & Mahalanobis sims\n# ----------------------------------------\nimport numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import normalize\n\n# 1) Re‑build your “improved I3D” features\nX_imp    = np.stack([improved_i3d_feat(u)    for u in proto_df.uid])\nX_imp_te = np.stack([improved_i3d_feat(u)    for u in test_df.uid])\n\n# 2) PCA‑whiten with the best dim you found (e.g. 1024)\nBEST_DIM = 1024\npca      = PCA(whiten=True, n_components=BEST_DIM).fit(X_imp)\nX_pw     = pca.transform(X_imp)\nX_pw_te  = pca.transform(X_imp_te)\n# cosine‐sim matrix\nS_pw     = normalize(X_pw_te,axis=1) @ normalize(X_pw,axis=1).T\n\n# 3) Mahalanobis‐scale on the same features\nvar      = X_imp.var(0) + 1e-6\nW        = 1/np.sqrt(var)\nX_ms     = X_imp    * W[None,:]\nX_ms_te  = X_imp_te * W[None,:]\nS_ms     = normalize(X_ms_te,axis=1) @ normalize(X_ms,axis=1).T\n\n# 4) Geometric fusion sweep over α∈{0,0.25,0.5,0.75,1}\nS_pw_c = np.clip(S_pw, 1e-6, None)\nS_ms_c = np.clip(S_ms, 1e-6, None)\n\nprint(\"\\n=== Geometric Fusion (PCA‑pw vs Mahalanobis) ===\")\nfor α in [0.0, 0.25, 0.5, 0.75, 1.0]:\n    S_geo = np.exp( α*np.log(S_pw_c) + (1-α)*np.log(S_ms_c) )\n    print(f\"α={α:.2f} →\", end=\" \")\n    for k in (1,5,10):\n        acc = topk_from_S(S_geo, y_tr, y_te, k)\n        print(f\"Top-{k}:{acc:.2f}%\", end=\"  \")\n    print()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T19:17:25.353453Z","iopub.execute_input":"2025-04-16T19:17:25.354194Z","iopub.status.idle":"2025-04-16T19:17:38.196709Z","shell.execute_reply.started":"2025-04-16T19:17:25.354169Z","shell.execute_reply":"2025-04-16T19:17:38.196035Z"}},"outputs":[{"name":"stdout","text":"\n=== Geometric Fusion (PCA‑pw vs Mahalanobis) ===\nα=0.00 → Top-1:17.37%  Top-5:21.53%  Top-10:23.37%  \nα=0.25 → Top-1:19.47%  Top-5:24.60%  Top-10:28.01%  \nα=0.50 → Top-1:19.21%  Top-5:24.73%  Top-10:27.40%  \nα=0.75 → Top-1:18.95%  Top-5:24.64%  Top-10:27.44%  \nα=1.00 → Top-1:18.95%  Top-5:24.55%  Top-10:27.44%  \n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# ----------------------------------------\n# 3) Geometric fusion of PCA‑whiten & Mahalanobis sims\n# ----------------------------------------\nimport numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import normalize\n\n# 1) Re‑build your “improved I3D” features\nX_imp    = np.stack([improved_i3d_feat(u)    for u in proto_df.uid])\nX_imp_te = np.stack([improved_i3d_feat(u)    for u in test_df.uid])\n\n# 2) PCA‑whiten with the best dim you found (e.g. 1024)\nBEST_DIM = 1024\npca      = PCA(whiten=True, n_components=BEST_DIM).fit(X_imp)\nX_pw     = pca.transform(X_imp)\nX_pw_te  = pca.transform(X_imp_te)\n# cosine‐sim matrix\nS_pw     = normalize(X_pw_te,axis=1) @ normalize(X_pw,axis=1).T\n\n# 3) Mahalanobis‐scale on the same features\nvar      = X_imp.var(0) + 1e-6\nW        = 1/np.sqrt(var)\nX_ms     = X_imp    * W[None,:]\nX_ms_te  = X_imp_te * W[None,:]\nS_ms     = normalize(X_ms_te,axis=1) @ normalize(X_ms,axis=1).T\n\n# 4) Geometric fusion sweep over α∈{0,0.25,0.5,0.75,1}\nS_pw_c = np.clip(S_pw, 1e-6, None)\nS_ms_c = np.clip(S_ms, 1e-6, None)\n\nprint(\"\\n=== Geometric Fusion (PCA‑pw vs Mahalanobis) ===\")\nfor α in [0.0, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30,0.35, 0.40, 0.45, 0.5, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95, 1]:\n    S_geo = np.exp( α*np.log(S_pw_c) + (1-α)*np.log(S_ms_c) )\n    print(f\"α={α:.2f} →\", end=\" \")\n    for k in (1,5,10):\n        acc = topk_from_S(S_geo, y_tr, y_te, k)\n        print(f\"Top-{k}:{acc:.2f}%\", end=\"  \")\n    print()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T19:20:35.120928Z","iopub.execute_input":"2025-04-16T19:20:35.121536Z","iopub.status.idle":"2025-04-16T19:21:04.329961Z","shell.execute_reply.started":"2025-04-16T19:20:35.121510Z","shell.execute_reply":"2025-04-16T19:21:04.329176Z"}},"outputs":[{"name":"stdout","text":"\n=== Geometric Fusion (PCA‑pw vs Mahalanobis) ===\nα=0.00 → Top-1:17.37%  Top-5:21.53%  Top-10:23.37%  \nα=0.05 → Top-1:19.12%  Top-5:23.89%  Top-10:26.91%  \nα=0.10 → Top-1:19.56%  Top-5:24.25%  Top-10:27.35%  \nα=0.15 → Top-1:19.39%  Top-5:24.55%  Top-10:27.48%  \nα=0.20 → Top-1:19.47%  Top-5:24.60%  Top-10:27.26%  \nα=0.25 → Top-1:19.43%  Top-5:24.60%  Top-10:27.26%  \nα=0.30 → Top-1:19.30%  Top-5:24.64%  Top-10:27.35%  \nα=0.35 → Top-1:19.21%  Top-5:24.73%  Top-10:27.35%  \nα=0.40 → Top-1:19.21%  Top-5:24.73%  Top-10:27.35%  \nα=0.45 → Top-1:19.17%  Top-5:24.73%  Top-10:27.31%  \nα=0.50 → Top-1:19.17%  Top-5:24.68%  Top-10:27.44%  \nα=0.55 → Top-1:19.12%  Top-5:24.68%  Top-10:27.48%  \nα=0.60 → Top-1:19.12%  Top-5:24.68%  Top-10:27.48%  \nα=0.65 → Top-1:19.08%  Top-5:24.64%  Top-10:27.48%  \nα=0.70 → Top-1:19.08%  Top-5:24.68%  Top-10:27.35%  \nα=0.75 → Top-1:19.08%  Top-5:24.73%  Top-10:27.35%  \nα=0.80 → Top-1:19.08%  Top-5:24.73%  Top-10:27.35%  \nα=0.85 → Top-1:19.08%  Top-5:24.73%  Top-10:27.35%  \nα=0.90 → Top-1:19.08%  Top-5:24.73%  Top-10:27.35%  \nα=0.95 → Top-1:19.08%  Top-5:24.73%  Top-10:27.31%  \nα=1.00 → Top-1:19.08%  Top-5:24.73%  Top-10:27.31%  \n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom sklearn.preprocessing import normalize\nfrom joblib import Parallel, delayed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T19:23:49.027255Z","iopub.execute_input":"2025-04-16T19:23:49.027862Z","iopub.status.idle":"2025-04-16T19:23:49.031889Z","shell.execute_reply.started":"2025-04-16T19:23:49.027837Z","shell.execute_reply":"2025-04-16T19:23:49.031036Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# ==================================================================\n# Additional Method 1: Test-Time Augmentation (TTA) on improved I3D\n# ==================================================================\ndef tta_improved_i3d_feat(uid, n_crops=3):\n    \"\"\"\n    Splits the I3D feature (after squeeze) temporally into n_crops parts,\n    computes SSR features for each crop and returns their (L2-normalized)\n    average.\n    \"\"\"\n    # Original shape: (1,1024,S,1,1) -> (1024, S)\n    arr = i3d_dict[uid].squeeze((0, 3, 4))\n    S_total = arr.shape[1]\n    crop_len = max(1, S_total // n_crops)\n    feats = []\n    for i in range(n_crops):\n        start = i * crop_len\n        end   = S_total if i == n_crops - 1 else (i + 1) * crop_len\n        crop = arr[:, start:end]\n        m = crop.mean(axis=1)\n        M = crop.max(axis=1)\n        s = crop.std(axis=1)\n        f = np.concatenate([m, M, s])\n        f = np.sign(f) * np.sqrt(np.abs(f) + 1e-8)\n        feats.append(f / (np.linalg.norm(f) + 1e-12))\n    return np.mean(np.stack(feats), axis=0)\n\nprint(\"=== TTA on improved I3D features ===\")\n# Build TTA features for all videos\nX_tta    = np.stack([tta_improved_i3d_feat(u, n_crops=3) for u in proto_df.uid])\nX_tta_te = np.stack([tta_improved_i3d_feat(u, n_crops=3) for u in test_df.uid])\n\nS_tta = normalize(X_tta_te, axis=1) @ normalize(X_tta, axis=1).T\nprint(\"TTA improved I3D Only:\")\nfor k in (1, 5, 10):\n    print(f\"Top-{k}: {topk_from_S(S_tta, y_tr, y_te, k):.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T19:24:10.869413Z","iopub.execute_input":"2025-04-16T19:24:10.869700Z","iopub.status.idle":"2025-04-16T19:24:19.835684Z","shell.execute_reply.started":"2025-04-16T19:24:10.869678Z","shell.execute_reply":"2025-04-16T19:24:19.835012Z"}},"outputs":[{"name":"stdout","text":"=== TTA on improved I3D features ===\nTTA improved I3D Only:\nTop-1: 17.07%\nTop-5: 20.66%\nTop-10: 22.76%\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# ==================================================================\n# Additional Method 2: k‑Reciprocal Re‑Ranking (on the best fusion)\n# ==================================================================\n\ndef k_reciprocal_rerank(S, k1=20, lambda_val=0.3):\n    \"\"\"\n    A simple k-reciprocal re-ranking that modifies S based on \n    reciprocal neighborhood relationships.\n    S: (N_test, N_train) similarity matrix\n    \"\"\"\n    q2g = np.argsort(-S, axis=1)  # for each test, indices sorted by descending similarity\n    g2q = np.argsort(-S, axis=0)  # for each train, indices sorted by descending similarity\n    S_new = np.zeros_like(S)\n    # Process each test row in parallel\n    def rerank(i):\n        row = S[i].copy()\n        forward = q2g[i, :k1+1]\n        reciprocal = [j for j in forward if i in g2q[:k1+1, j]]\n        bonus = lambda_val * (len(reciprocal) / (k1+1))\n        row[reciprocal] *= (1 + bonus)\n        return row\n    S_new = np.vstack(Parallel(n_jobs=-1)(delayed(rerank)(i) for i in range(S.shape[0])))\n    return S_new\n\n# Assume your best fused similarity S_fuse is from your previous fusion grid \n# (e.g. S_fuse computed with best α,β,γ from your grid).\n# For demonstration, here we reuse S_pw from your PCA-guided branch:\nS_fuse = S_pw  # (for example; replace with your best fused S)\n\nprint(\"\\n=== k‑Reciprocal Re‑Ranking on best fusion ===\")\nfor k1 in [10, 20, 30]:\n    for lam in [0.1, 0.3, 0.5]:\n        S_rr = k_reciprocal_rerank(S_fuse, k1=k1, lambda_val=lam)\n        acc1 = topk_from_S(S_rr, y_tr, y_te, 1)\n        acc5 = topk_from_S(S_rr, y_tr, y_te, 5)\n        acc10= topk_from_S(S_rr, y_tr, y_te,10)\n        print(f\"k1={k1}, λ={lam}: Top-1={acc1:.2f}% | Top-5={acc5:.2f}% | Top-10={acc10:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T19:24:36.062488Z","iopub.execute_input":"2025-04-16T19:24:36.062795Z","iopub.status.idle":"2025-04-16T19:24:58.911367Z","shell.execute_reply.started":"2025-04-16T19:24:36.062774Z","shell.execute_reply":"2025-04-16T19:24:58.910553Z"}},"outputs":[{"name":"stdout","text":"\n=== k‑Reciprocal Re‑Ranking on best fusion ===\nk1=10, λ=0.1: Top-1=19.08% | Top-5=24.77% | Top-10=27.26%\nk1=10, λ=0.3: Top-1=19.08% | Top-5=24.77% | Top-10=27.31%\nk1=10, λ=0.5: Top-1=19.08% | Top-5=24.73% | Top-10=27.31%\nk1=20, λ=0.1: Top-1=19.08% | Top-5=24.73% | Top-10=27.31%\nk1=20, λ=0.3: Top-1=19.08% | Top-5=24.73% | Top-10=27.31%\nk1=20, λ=0.5: Top-1=19.08% | Top-5=24.73% | Top-10=27.31%\nk1=30, λ=0.1: Top-1=19.08% | Top-5=24.73% | Top-10=27.31%\nk1=30, λ=0.3: Top-1=19.08% | Top-5=24.73% | Top-10=27.31%\nk1=30, λ=0.5: Top-1=19.08% | Top-5=24.73% | Top-10=27.31%\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\n\ndef gem_pooling(x, p=3, eps=1e-6):\n    return F.avg_pool1d(x.clamp(min=eps).pow(p), kernel_size=x.size(-1)).pow(1./p)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:00:55.045045Z","iopub.execute_input":"2025-04-16T20:00:55.045797Z","iopub.status.idle":"2025-04-16T20:00:55.050443Z","shell.execute_reply.started":"2025-04-16T20:00:55.045769Z","shell.execute_reply":"2025-04-16T20:00:55.049725Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\ndef pca_whitening(X_train, X_test, n_components=768):\n    X_train = np.asarray(X_train).reshape(len(X_train), -1)  # Ensure 2D\n    X_test  = np.asarray(X_test).reshape(len(X_test), -1)\n\n    scaler = StandardScaler().fit(X_train)\n    X_train_scaled = scaler.transform(X_train)\n    X_test_scaled  = scaler.transform(X_test)\n\n    pca = PCA(n_components=n_components, whiten=True)\n    X_train_pca = pca.fit_transform(X_train_scaled)\n    X_test_pca  = pca.transform(X_test_scaled)\n    return X_train_pca, X_test_pca","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:07:58.919595Z","iopub.execute_input":"2025-04-16T20:07:58.919898Z","iopub.status.idle":"2025-04-16T20:07:58.925697Z","shell.execute_reply.started":"2025-04-16T20:07:58.919876Z","shell.execute_reply":"2025-04-16T20:07:58.924815Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"def weighted_fusion(similarity_scores, weights):\n    fused_score = sum(w * s for w, s in zip(weights, similarity_scores))\n    return fused_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:01:19.006880Z","iopub.execute_input":"2025-04-16T20:01:19.007512Z","iopub.status.idle":"2025-04-16T20:01:19.011380Z","shell.execute_reply.started":"2025-04-16T20:01:19.007484Z","shell.execute_reply":"2025-04-16T20:01:19.010507Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"import numpy as np\n\ndef k_reciprocal_reranking(original_dist, k1=20, lambda_value=0.3):\n    # Implementation of k-reciprocal re-ranking algorithm\n    # Refer to the original paper for detailed steps\n    # This is a placeholder for the actual implementation\n    reranked_dist = original_dist  # Replace with actual re-ranking logic\n    return reranked_dist","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:01:28.877176Z","iopub.execute_input":"2025-04-16T20:01:28.877718Z","iopub.status.idle":"2025-04-16T20:01:28.881500Z","shell.execute_reply.started":"2025-04-16T20:01:28.877695Z","shell.execute_reply":"2025-04-16T20:01:28.880675Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def extract_pose_features(frames, pose_model):\n    pose_features = []\n    for frame in frames:\n        keypoints = pose_model.detect(frame)\n        pose_features.append(keypoints)\n    return pose_features\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:01:38.127797Z","iopub.execute_input":"2025-04-16T20:01:38.128311Z","iopub.status.idle":"2025-04-16T20:01:38.132638Z","shell.execute_reply.started":"2025-04-16T20:01:38.128280Z","shell.execute_reply":"2025-04-16T20:01:38.131753Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"def compute_joint_velocities(pose_features):\n    velocities = []\n    for i in range(1, len(pose_features)):\n        velocity = pose_features[i] - pose_features[i - 1]\n        velocities.append(velocity)\n    return velocities\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:01:45.947410Z","iopub.execute_input":"2025-04-16T20:01:45.947686Z","iopub.status.idle":"2025-04-16T20:01:45.952183Z","shell.execute_reply.started":"2025-04-16T20:01:45.947665Z","shell.execute_reply":"2025-04-16T20:01:45.951380Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"import torch.nn as nn\n\nclass AttentionPooling(nn.Module):\n    def __init__(self, input_dim):\n        super(AttentionPooling, self).__init__()\n        self.attention = nn.Sequential(\n            nn.Linear(input_dim, 128),\n            nn.ReLU(),\n            nn.Linear(128, 1),\n            nn.Softmax(dim=1)\n        )\n\n    def forward(self, x):\n        weights = self.attention(x)\n        pooled = (x * weights).sum(dim=1)\n        return pooled\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:01:52.626515Z","iopub.execute_input":"2025-04-16T20:01:52.627058Z","iopub.status.idle":"2025-04-16T20:01:52.631932Z","shell.execute_reply.started":"2025-04-16T20:01:52.627027Z","shell.execute_reply":"2025-04-16T20:01:52.631300Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"def fuse_features(visual_features, pose_features, alpha=0.6, beta=0.4):\n    return alpha * visual_features + beta * pose_features\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:01:57.700734Z","iopub.execute_input":"2025-04-16T20:01:57.701021Z","iopub.status.idle":"2025-04-16T20:01:57.705072Z","shell.execute_reply.started":"2025-04-16T20:01:57.701000Z","shell.execute_reply":"2025-04-16T20:01:57.704253Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"from sklearn.svm import SVC\n\ndef train_classifier(features, labels):\n    classifier = SVC(kernel='linear', probability=True)\n    classifier.fit(features, labels)\n    return classifier\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:02:03.197375Z","iopub.execute_input":"2025-04-16T20:02:03.198061Z","iopub.status.idle":"2025-04-16T20:02:03.202088Z","shell.execute_reply.started":"2025-04-16T20:02:03.198026Z","shell.execute_reply":"2025-04-16T20:02:03.201184Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"print(\"\\n--- Evaluating Option 2: GeM + PCA ---\")\nX_gem = np.stack([gem_pooling(torch.tensor(i3d_dict[uid].squeeze((0,3,4))).float(), p=3).cpu().numpy()\n                  for uid in proto_df.uid])\nX_gem_te = np.stack([gem_pooling(torch.tensor(i3d_dict[uid].squeeze((0,3,4))).float(), p=3).cpu().numpy()\n                     for uid in test_df.uid])\n\nX_gem_pca, X_gem_te_pca = pca_whitening(X_gem, X_gem_te, n_components=768)\nS_gem = normalize(X_gem_te_pca) @ normalize(X_gem_pca).T\n\nfor k in (1, 5, 10):\n    print(f\"Top-{k}: {topk_from_S(S_gem, y_tr, y_te, k):.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:08:33.014841Z","iopub.execute_input":"2025-04-16T20:08:33.015139Z","iopub.status.idle":"2025-04-16T20:08:37.012087Z","shell.execute_reply.started":"2025-04-16T20:08:33.015119Z","shell.execute_reply":"2025-04-16T20:08:37.011391Z"}},"outputs":[{"name":"stdout","text":"\n--- Evaluating Option 2: GeM + PCA ---\nTop-1: 19.43%\nTop-5: 24.03%\nTop-10: 27.40%\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"# Match both branches to 510D before fusion\npca_gem = PCA(n_components=510).fit(X_gem_pca)\nX_gem_pca_510 = pca_gem.transform(X_gem_pca)\nX_gem_te_pca_510 = pca_gem.transform(X_gem_te_pca)\n\n# Pose already has 510 features, just scale\npose_scaler = StandardScaler().fit(X_pose)\nX_pose_scaled    = pose_scaler.transform(X_pose)\nX_pose_te_scaled = pose_scaler.transform(X_pose_te)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:14:06.959873Z","iopub.execute_input":"2025-04-16T20:14:06.960200Z","iopub.status.idle":"2025-04-16T20:14:08.204333Z","shell.execute_reply.started":"2025-04-16T20:14:06.960178Z","shell.execute_reply":"2025-04-16T20:14:08.203420Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"# === Evaluate Option 3 (Pose Attention + Fusion with I3D) ===\n\n# 1. Pose Attention Features\nX_pose = np.stack([pose_attn(uid) for uid in proto_df.uid])\nX_pose_te = np.stack([pose_attn(uid) for uid in test_df.uid])\n\nalpha, beta = 0.6, 0.4\nX_fused = normalize(alpha * X_gem_pca_510 + beta * X_pose_scaled)\nX_fused_te = normalize(alpha * X_gem_te_pca_510 + beta * X_pose_te_scaled)\n\nS_fuse = X_fused_te @ X_fused.T\nfor k in (1, 5, 10):\n    print(f\"Top-{k}: {topk_from_S(S_fuse, y_tr, y_te, k):.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:15:58.255219Z","iopub.execute_input":"2025-04-16T20:15:58.256118Z","iopub.status.idle":"2025-04-16T20:16:27.382269Z","shell.execute_reply.started":"2025-04-16T20:15:58.256081Z","shell.execute_reply":"2025-04-16T20:16:27.381443Z"}},"outputs":[{"name":"stdout","text":"Top-1: 16.46%\nTop-5: 20.04%\nTop-10: 21.93%\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"from sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler, normalize\n\n# 1. Scale pose data\npose_scaler = StandardScaler().fit(X_pose)\nX_pose_scaled    = pose_scaler.transform(X_pose)\nX_pose_te_scaled = pose_scaler.transform(X_pose_te)\n\n# 2. Reduce both to 256D\ncommon_dim = 256\n\npca_gem = PCA(n_components=common_dim).fit(X_gem_pca)\nX_gem_proj    = pca_gem.transform(X_gem_pca)\nX_gem_te_proj = pca_gem.transform(X_gem_te_pca)\n\npca_pose = PCA(n_components=common_dim).fit(X_pose_scaled)\nX_pose_proj    = pca_pose.transform(X_pose_scaled)\nX_pose_te_proj = pca_pose.transform(X_pose_te_scaled)\n\n# 3. Fuse\nα, β = 0.6, 0.4\nX_fused    = normalize(α * X_gem_proj + β * X_pose_proj)\nX_fused_te = normalize(α * X_gem_te_proj + β * X_pose_te_proj)\n\n# 4. Evaluate\nS_fuse = X_fused_te @ X_fused.T\nfor k in (1, 5, 10):\n    print(f\"Top-{k}: {topk_from_S(S_fuse, y_tr, y_te, k):.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:16:57.939509Z","iopub.execute_input":"2025-04-16T20:16:57.940081Z","iopub.status.idle":"2025-04-16T20:17:00.221351Z","shell.execute_reply.started":"2025-04-16T20:16:57.940059Z","shell.execute_reply":"2025-04-16T20:17:00.220363Z"}},"outputs":[{"name":"stdout","text":"Top-1: 14.92%\nTop-5: 17.59%\nTop-10: 18.56%\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# ----- Process I3D features -----\ndef process_i3d_feature(feat):\n    \"\"\"\n    Process the I3D feature (expected shape: (1, 1024, T, 1, 1)).\n    This averages over the temporal and singleton dimensions to yield a shape of (1, 1024).\n    \"\"\"\n    tfeat = torch.tensor(feat, dtype=torch.float32)\n    if tfeat.dim() == 5:\n        # Average over dimensions 2, 3, 4 (i.e. temporal and singleton spatial dims)\n        tfeat = tfeat.mean(dim=(2, 3, 4))\n    else:\n        dims = list(range(1, tfeat.dim()))\n        tfeat = tfeat.mean(dim=tuple(dims))\n    return tfeat  # shape: (1, 1024)\n\n# ----- Process Pose features -----\ndef process_pose_feature(feat):\n    \"\"\"\n    Process the pose feature.\n    For example, if 'feat' has shape (T, 1, D, 3) where T is the number of frames (e.g., 125),\n    then this function will average over T to get shape (1, D, 3) and then flatten it\n    to produce a fixed vector of size D*3.\n    For the provided sample, if D is 576 then the output will be of size 576*3=1728.\n    \"\"\"\n    tfeat = torch.tensor(feat, dtype=torch.float32)\n    if tfeat.dim() >= 3:\n        # Average over the temporal dimension (assumed dim 0)\n        tfeat = tfeat.mean(dim=0)  # now shape: (1, D, 3) if input was (T, 1, D, 3)\n        tfeat = tfeat.flatten().unsqueeze(0)  # shape: (1, D*3)\n    else:\n        tfeat = tfeat.flatten().unsqueeze(0)\n    return tfeat\n\n# ----- Dummy Pose Data Loading (Replace with your actual loading) -----\n# For illustration, we are constructing a dummy pose_dict.\n# Replace this dictionary so that each uid in i3d_dict has its corresponding pose feature\n# loaded from your .pose file (which should be a numpy array).\n# For example, if your actual pose file per video yields an array with shape (125, 1, 576, 3),\n# then process_pose_feature will output a (1, 1728) tensor.\npose_dict = {uid: np.random.rand(125, 1, 576, 3).astype(np.float32) for uid in i3d_dict.keys()}\n\n# ----- Define the Dynamic Gated Fusion Model -----\nclass DynamicGatedFusion(nn.Module):\n    def __init__(self, i3d_dim, pose_dim, fusion_dim):\n        super(DynamicGatedFusion, self).__init__()\n        # Project I3D and pose features into a common space\n        self.fc_i3d = nn.Linear(i3d_dim, fusion_dim)\n        self.fc_pose = nn.Linear(pose_dim, fusion_dim)\n        # Gating network: learns a weight for I3D (and 1-gate for pose)\n        self.gate_fc = nn.Sequential(\n            nn.Linear(i3d_dim + pose_dim, fusion_dim),\n            nn.ReLU(),\n            nn.Linear(fusion_dim, 1),\n            nn.Sigmoid()\n        )\n    \n    def forward(self, i3d_feat, pose_feat):\n        # Concatenate features and compute gating weight\n        gate_input = torch.cat([i3d_feat, pose_feat], dim=1)  # shape: [batch_size, i3d_dim+pose_dim]\n        gate_weight = self.gate_fc(gate_input)  # shape: [batch_size, 1]\n        # Project features into the fusion space\n        i3d_proj = self.fc_i3d(i3d_feat)  # shape: [batch_size, fusion_dim]\n        pose_proj = self.fc_pose(pose_feat)  # shape: [batch_size, fusion_dim]\n        # Compute fused feature as weighted sum\n        fused_feat = gate_weight * i3d_proj + (1 - gate_weight) * pose_proj\n        return fused_feat\n\n# ----- Instantiate the fusion model -----\n# I3D features (after pooling) are 1024-dimensional.\n# After processing, pose features become 1728-dimensional (576*3, based on the sample).\ni3d_dim = 1024\npose_dim = 1728  # Updated for the processed pose feature vector length.\nfusion_dim = 512  # Desired final fusion dimension.\n\nfusion_model = DynamicGatedFusion(i3d_dim, pose_dim, fusion_dim)\nfusion_model.eval()  # Set to evaluation mode\n\n# ----- Utility function for L2 normalization -----\ndef l2_normalize(x):\n    return x / (torch.norm(x, dim=1, keepdim=True) + 1e-8)\n\n# ----- Build Prototype Embeddings using the Fusion Model -----\nproto_embeddings = []\nfor _, row in proto_df.iterrows():\n    uid = row[\"uid\"]  # Use 'uid' column from your CSV.\n    if uid in i3d_dict and uid in pose_dict:\n        # Process the I3D feature; expected output shape: (1, 1024)\n        i3d_feat = process_i3d_feature(i3d_dict[uid])\n        # Process the pose feature; expected output shape: (1, 1728)\n        pose_feat = process_pose_feature(pose_dict[uid])\n        with torch.no_grad():\n            fused_feat = fusion_model(i3d_feat, pose_feat)\n        proto_embeddings.append(fused_feat.squeeze(0).numpy())\n    else:\n        proto_embeddings.append(np.zeros(fusion_dim, dtype=np.float32))\nproto_embeddings = np.stack(proto_embeddings)\n\n# ----- Build Test Embeddings using the Fusion Model -----\ntest_embeddings = []\nfor _, row in test_df.iterrows():\n    uid = row[\"uid\"]\n    if uid in i3d_dict and uid in pose_dict:\n        i3d_feat = process_i3d_feature(i3d_dict[uid])\n        pose_feat = process_pose_feature(pose_dict[uid])\n        with torch.no_grad():\n            fused_feat = fusion_model(i3d_feat, pose_feat)\n        test_embeddings.append(fused_feat.squeeze(0).numpy())\n    else:\n        test_embeddings.append(np.zeros(fusion_dim, dtype=np.float32))\ntest_embeddings = np.stack(test_embeddings)\n\n# ----- Normalize the embeddings -----\nproto_embeddings = l2_normalize(torch.tensor(proto_embeddings)).numpy()\ntest_embeddings = l2_normalize(torch.tensor(test_embeddings)).numpy()\n\n# ----- Compute Cosine Similarity and Evaluate -----\nS = np.dot(test_embeddings, proto_embeddings.T)\nprint(\"Top-1 Accuracy: {:.2f}%\".format(topk_from_S(S, y_tr, y_te, 1)))\nprint(\"Top-5 Accuracy: {:.2f}%\".format(topk_from_S(S, y_tr, y_te, 5)))\nprint(\"Top-10 Accuracy: {:.2f}%\".format(topk_from_S(S, y_tr, y_te, 10)))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:54:49.599371Z","iopub.execute_input":"2025-04-16T20:54:49.600082Z","iopub.status.idle":"2025-04-16T20:55:14.423898Z","shell.execute_reply.started":"2025-04-16T20:54:49.600054Z","shell.execute_reply":"2025-04-16T20:55:14.423177Z"}},"outputs":[{"name":"stdout","text":"Top-1 Accuracy: 16.72%\nTop-5 Accuracy: 20.00%\nTop-10 Accuracy: 21.88%\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"pip install scikit-learn scipy\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:56:59.090644Z","iopub.execute_input":"2025-04-16T20:56:59.091438Z","iopub.status.idle":"2025-04-16T20:57:02.431037Z","shell.execute_reply.started":"2025-04-16T20:56:59.091412Z","shell.execute_reply":"2025-04-16T20:57:02.430052Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.2)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":60},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nfrom sklearn.decomposition import PCA\nfrom sklearn.covariance import EmpiricalCovariance\nfrom scipy.spatial.distance import cdist\n\n# ========== Feature Loading ==========\ndef load_features(uid_list, feature_dict, process_fn, fallback_dim):\n    out = []\n    for uid in uid_list:\n        if uid in feature_dict:\n            feat = process_fn(feature_dict[uid])\n        else:\n            feat = np.zeros((fallback_dim,), dtype=np.float32)\n        out.append(feat)\n    return np.stack(out)\n\n# ========== Pose Velocity Extraction ==========\ndef pose_velocity(pose_arr):  # shape: (T, 1, D, 3)\n    vel = np.diff(pose_arr, axis=0)  # shape: (T-1, 1, D, 3)\n    vel = vel.reshape(vel.shape[0], -1)  # (T-1, D*3)\n    return np.mean(vel, axis=0)\n\n# ========== I3D Processing ==========\ndef avg_i3d(i3d_feat):  # shape: (1, 1024, T, 1, 1)\n    t = torch.tensor(i3d_feat, dtype=torch.float32)\n    return t.mean(dim=(2, 3, 4)).squeeze(0).numpy()\n\n# ========== Whitening ==========\ndef mahalanobis_whiten(X):\n    cov = EmpiricalCovariance().fit(X)\n    X_centered = X - cov.location_\n    X_white = np.dot(X_centered, np.linalg.inv(np.linalg.cholesky(cov.covariance_)).T)\n    return X_white\n\n# ========== Cosine Similarity + Fusion ==========\ndef cosine_sim(a, b):\n    a = a / (np.linalg.norm(a, axis=1, keepdims=True) + 1e-8)\n    b = b / (np.linalg.norm(b, axis=1, keepdims=True) + 1e-8)\n    return np.dot(a, b.T)\n\n# ========== Load Features ==========\nproto_uids = proto_df[\"uid\"].tolist()\ntest_uids = test_df[\"uid\"].tolist()\n\n# Load I3D features\nX_proto_i3d = load_features(proto_uids, i3d_dict, avg_i3d, 1024)\nX_test_i3d  = load_features(test_uids, i3d_dict, avg_i3d, 1024)\n\n# Load pose velocity features\nX_proto_pose = load_features(proto_uids, pose_dict, pose_velocity, 1728)\nX_test_pose  = load_features(test_uids, pose_dict, pose_velocity, 1728)\n\n# Mahalanobis normalize\nX_proto_i3d_white = mahalanobis_whiten(X_proto_i3d)\nX_test_i3d_white  = mahalanobis_whiten(X_test_i3d)\nX_proto_pose_white = mahalanobis_whiten(X_proto_pose)\nX_test_pose_white  = mahalanobis_whiten(X_test_pose)\n\n# Compute cosine similarities\nS_i3d  = cosine_sim(X_test_i3d_white, X_proto_i3d_white)\nS_pose = cosine_sim(X_test_pose_white, X_proto_pose_white)\n\n# Fuse scores (adjust α, β)\nα, β = 0.6, 0.4\nS = α * S_i3d + β * S_pose\n\n# Evaluate\nprint(\"Top-1 Accuracy: {:.2f}%\".format(topk_from_S(S, y_tr, y_te, 1)))\nprint(\"Top-5 Accuracy: {:.2f}%\".format(topk_from_S(S, y_tr, y_te, 5)))\nprint(\"Top-10 Accuracy: {:.2f}%\".format(topk_from_S(S, y_tr, y_te, 10)))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:57:19.735514Z","iopub.execute_input":"2025-04-16T20:57:19.735808Z","iopub.status.idle":"2025-04-16T20:57:41.808673Z","shell.execute_reply.started":"2025-04-16T20:57:19.735783Z","shell.execute_reply":"2025-04-16T20:57:41.807685Z"}},"outputs":[{"name":"stdout","text":"Top-1 Accuracy: 19.04%\nTop-5 Accuracy: 23.54%\nTop-10 Accuracy: 26.04%\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"def gem_pooling(i3d_feat, p=3.0):  # Generalized Mean Pooling\n    x = torch.tensor(i3d_feat, dtype=torch.float32)  # [1, 1024, T, 1, 1]\n    x = x.clamp(min=1e-6).pow(p)\n    x = x.mean(dim=(2, 3, 4)).pow(1.0/p).squeeze(0)\n    return x.numpy()\n\ndef pca_whiten(X, dim=1024):\n    pca = PCA(n_components=dim, whiten=True)\n    return pca.fit_transform(X)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:57:41.810146Z","iopub.execute_input":"2025-04-16T20:57:41.810701Z","iopub.status.idle":"2025-04-16T20:57:41.815697Z","shell.execute_reply.started":"2025-04-16T20:57:41.810681Z","shell.execute_reply":"2025-04-16T20:57:41.814911Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"# Load GeM pooled I3D features\nX_proto_i3d = load_features(proto_uids, i3d_dict, gem_pooling, 1024)\nX_test_i3d  = load_features(test_uids, i3d_dict, gem_pooling, 1024)\n\n# Load pose velocity features\nX_proto_pose = load_features(proto_uids, pose_dict, pose_velocity, 1728)\nX_test_pose  = load_features(test_uids, pose_dict, pose_velocity, 1728)\n\n# PCA whiten both\nX_proto_i3d_white = pca_whiten(X_proto_i3d, dim=512)\nX_test_i3d_white  = pca_whiten(X_test_i3d, dim=512)\nX_proto_pose_white = pca_whiten(X_proto_pose, dim=512)\nX_test_pose_white  = pca_whiten(X_test_pose, dim=512)\n\n# Cosine similarity\nS_i3d  = cosine_sim(X_test_i3d_white, X_proto_i3d_white)\nS_pose = cosine_sim(X_test_pose_white, X_proto_pose_white)\n\n# Fuse\nα, β = 0.6, 0.4\nS = α * S_i3d + β * S_pose\n\n# Evaluate\nprint(\"Top-1 Accuracy: {:.2f}%\".format(topk_from_S(S, y_tr, y_te, 1)))\nprint(\"Top-5 Accuracy: {:.2f}%\".format(topk_from_S(S, y_tr, y_te, 5)))\nprint(\"Top-10 Accuracy: {:.2f}%\".format(topk_from_S(S, y_tr, y_te, 10)))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:57:51.150790Z","iopub.execute_input":"2025-04-16T20:57:51.151386Z","iopub.status.idle":"2025-04-16T20:58:00.264166Z","shell.execute_reply.started":"2025-04-16T20:57:51.151361Z","shell.execute_reply":"2025-04-16T20:58:00.263327Z"}},"outputs":[{"name":"stdout","text":"Top-1 Accuracy: 0.00%\nTop-5 Accuracy: 0.22%\nTop-10 Accuracy: 0.35%\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.decomposition import PCA\nimport numpy as np\nimport pandas as pd\nimport os, pickle\n!pip install pose-format\nfrom pose_format.pose import Pose                 # Python reader for .pose :contentReference[oaicite:0]{index=0}  \nfrom pose_format.numpy import NumPyPoseBody       # NumPy backend :contentReference[oaicite:1]{index=1}  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T13:06:14.486342Z","iopub.execute_input":"2025-04-17T13:06:14.486811Z","iopub.status.idle":"2025-04-17T13:06:19.827110Z","shell.execute_reply.started":"2025-04-17T13:06:14.486789Z","shell.execute_reply":"2025-04-17T13:06:19.826407Z"}},"outputs":[{"name":"stdout","text":"Collecting pose-format\n  Downloading pose_format-0.9.0-py3-none-any.whl.metadata (741 bytes)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pose-format) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pose-format) (1.15.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from pose-format) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->pose-format) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->pose-format) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->pose-format) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->pose-format) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->pose-format) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->pose-format) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->pose-format) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->pose-format) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->pose-format) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->pose-format) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->pose-format) (2024.2.0)\nDownloading pose_format-0.9.0-py3-none-any.whl (97 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.7/97.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pose-format\nSuccessfully installed pose-format-0.9.0\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# Paths (adjust as needed)\nI3D_PKL   = \"/kaggle/input/cislr-dataset/I3D_features.pkl\"\nPROTO_CSV = \"/kaggle/input/cislr-dataset/prototype.csv\"\nTEST_CSV  = \"/kaggle/input/cislr-dataset/test.csv\"\nVIDEO_POSE_DIR = \"/kaggle/input/cislr-dataset/CISLR_v1.5-a_videos_poses\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T13:03:52.693070Z","iopub.execute_input":"2025-04-17T13:03:52.693326Z","iopub.status.idle":"2025-04-17T13:03:52.697200Z","shell.execute_reply.started":"2025-04-17T13:03:52.693307Z","shell.execute_reply":"2025-04-17T13:03:52.696454Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Load CSVs\nproto_df = pd.read_csv(PROTO_CSV); proto_df[\"gloss\"] = proto_df[\"gloss\"].astype(str)\ntest_df  = pd.read_csv(TEST_CSV);  test_df[\"gloss\"]  = test_df[\"gloss\"].astype(str)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T13:04:02.762827Z","iopub.execute_input":"2025-04-17T13:04:02.763498Z","iopub.status.idle":"2025-04-17T13:04:02.802729Z","shell.execute_reply.started":"2025-04-17T13:04:02.763466Z","shell.execute_reply":"2025-04-17T13:04:02.802120Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Map gloss to index\nall_gloss = sorted(proto_df[\"gloss\"].unique())\ngloss2idx = {g:i for i,g in enumerate(all_gloss)}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T13:04:05.482549Z","iopub.execute_input":"2025-04-17T13:04:05.482901Z","iopub.status.idle":"2025-04-17T13:04:05.491537Z","shell.execute_reply.started":"2025-04-17T13:04:05.482878Z","shell.execute_reply":"2025-04-17T13:04:05.490859Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"import os\n\nVIDEO_POSE_DIR = \"/kaggle/input/cislr-dataset/CISLR_v1.5-a_videos_poses\"\n\ndef load_pose(uid):\n    \"\"\"\n    Reads the MediaPipe .pose file and returns a NumPy array:\n      shape → (frames, keypoints, 3)\n    \"\"\"\n    path = os.path.join(VIDEO_POSE_DIR, f\"{uid}.pose\")\n    buf  = open(path, \"rb\").read()                  # Read raw bytes :contentReference[oaicite:2]{index=2}\n    p   = Pose.read(buf, NumPyPoseBody)             # Parse header+body :contentReference[oaicite:3]{index=3}\n    data = p.body.data                              # Array[T, K, 3] :contentReference[oaicite:4]{index=4}\n    return data.astype(np.float32)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T13:06:56.371684Z","iopub.execute_input":"2025-04-17T13:06:56.372400Z","iopub.status.idle":"2025-04-17T13:06:56.377415Z","shell.execute_reply.started":"2025-04-17T13:06:56.372374Z","shell.execute_reply":"2025-04-17T13:06:56.376668Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"pose_dict = {}\nfor uid in pd.concat([proto_df.uid, test_df.uid]).unique():\n    pose_dict[uid] = load_pose(uid)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T13:07:05.788031Z","iopub.execute_input":"2025-04-17T13:07:05.788282Z","iopub.status.idle":"2025-04-17T13:08:45.317834Z","shell.execute_reply.started":"2025-04-17T13:07:05.788264Z","shell.execute_reply":"2025-04-17T13:08:45.315617Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"i3d_dict  = {row['id']: np.array(row['I3D_features'], dtype=np.float32)\n             for _, row in i3d_df.iterrows()}     # dict comp :contentReference[oaicite:5]{index=5}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T13:09:26.976918Z","iopub.execute_input":"2025-04-17T13:09:26.977196Z","iopub.status.idle":"2025-04-17T13:09:27.595089Z","shell.execute_reply.started":"2025-04-17T13:09:26.977177Z","shell.execute_reply":"2025-04-17T13:09:27.594331Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"import torch\n\ndef process_pose_feature(array):\n    \"\"\"\n    array: NumPy [T, K, 3]\n    → Tensor [1, K*3] by temporal mean + flatten.\n    \"\"\"\n    t = torch.from_numpy(array)            # [T,K,3]\n    t = t.mean(dim=0)                      # [K,3]\n    return t.flatten().unsqueeze(0)        # [1, K*3]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T13:09:30.576277Z","iopub.execute_input":"2025-04-17T13:09:30.576528Z","iopub.status.idle":"2025-04-17T13:09:30.580769Z","shell.execute_reply.started":"2025-04-17T13:09:30.576511Z","shell.execute_reply":"2025-04-17T13:09:30.580121Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"from sklearn.decomposition import PCA\n\ndef avg_i3d(feat):\n    t = torch.from_numpy(feat)            # [1,1024,T,1,1]\n    return t.mean(dim=(2,3,4)).squeeze(0).numpy()\n\n# Fit PCA on all videos\nX_all = np.stack([avg_i3d(v) for v in i3d_dict.values()])  # [N,1024]\npca   = PCA(n_components=512, whiten=True).fit(X_all)      # \n\ndef get_i3d_emb(uid):\n    v = avg_i3d(i3d_dict[uid])[None]     # [1,1024]\n    return torch.from_numpy(pca.transform(v)).float()  # [1,512]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T13:09:44.745331Z","iopub.execute_input":"2025-04-17T13:09:44.745902Z","iopub.status.idle":"2025-04-17T13:09:47.012454Z","shell.execute_reply.started":"2025-04-17T13:09:44.745880Z","shell.execute_reply":"2025-04-17T13:09:47.010676Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# ── 4. MODEL DEFINITION ──────────────────────────────────────────────────────\n\nclass FusionTransformer(nn.Module):\n    def __init__(self, pose_dim, i3d_dim=512, hid_dim=512, num_classes=None):\n        \"\"\"\n        pose_dim: dimensionality of your processed pose vector (e.g. K*3)\n        i3d_dim: dimensionality of PCA‑whitened I3D embeddings (default 512)\n        hid_dim: hidden size for projection & transformer\n        num_classes: number of unique gloss labels\n        \"\"\"\n        super().__init__()\n        # linear projections\n        self.pose_proj = nn.Linear(pose_dim, hid_dim)\n        self.i3d_proj  = nn.Linear(i3d_dim, hid_dim)\n        # cross‑modal transformer\n        self.transformer = nn.Transformer(\n            d_model=hid_dim, nhead=8,\n            num_encoder_layers=2, num_decoder_layers=2\n        )\n        # final classifier\n        self.classifier = nn.Linear(hid_dim, num_classes)\n\n    def forward(self, pose_vec, i3d_emb):\n        \"\"\"\n        pose_vec:   (B, pose_dim)  — your flattened/processed pose\n        i3d_emb:    (B, i3d_dim)   — your PCA‑whitened I3D embedding\n        \"\"\"\n        # Project modalities\n        P = self.pose_proj(pose_vec)      # (B, hid_dim)\n        V = self.i3d_proj(i3d_emb)        # (B, hid_dim)\n\n        # For transformer we need seq_len x batch x hid\n        # We treat pose as 'source sequence' of length 1 and I3D as 'target' length 1.\n        # If you want multi‑frame pose tokens, supply shape (B, T, pose_dim) and adjust accordingly.\n        P_seq = P.unsqueeze(0)            # (1, B, hid_dim)\n        V_seq = V.unsqueeze(0)            # (1, B, hid_dim)\n\n        # Cross‐modal encoding: pose→I3D\n        fused_seq = self.transformer(src=P_seq, tgt=V_seq)  \n                                         # (1, B, hid_dim)\n        fused     = fused_seq.squeeze(0)  # (B, hid_dim)\n\n        # Classify\n        logits    = self.classifier(fused)  # (B, num_classes)\n        return logits, fused\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T13:13:56.957380Z","iopub.execute_input":"2025-04-17T13:13:56.958167Z","iopub.status.idle":"2025-04-17T13:13:56.965106Z","shell.execute_reply.started":"2025-04-17T13:13:56.958139Z","shell.execute_reply":"2025-04-17T13:13:56.964516Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\n\nclass SignDataset(Dataset):\n    def __init__(self, df, pose_dict, i3d_dict, gloss2idx):\n        \"\"\"\n        df:         DataFrame with columns ['uid','gloss']\n        pose_dict:  {uid: numpy_pose_array}\n        i3d_dict:   {uid: numpy_I3D_feature}\n        gloss2idx:  {gloss: index}\n        \"\"\"\n        self.df        = df.reset_index(drop=True)\n        self.pose_dict = pose_dict\n        self.i3d_dict  = i3d_dict\n        self.gloss2idx = gloss2idx\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row     = self.df.loc[idx]\n        uid     = row[\"uid\"]\n        gloss   = row[\"gloss\"]\n        label   = self.gloss2idx[gloss]\n\n        # Process pose and I3D\n        pose_np = self.pose_dict[uid]                    # e.g. shape [T,K,3]\n        pose_vec= process_pose_feature(pose_np).squeeze()# [pose_dim,]\n\n        i3d_feat= get_i3d_emb(uid).squeeze()             # [i3d_dim,]\n\n        return pose_vec, i3d_feat, label\n\n# Instantiate\ntrain_ds = SignDataset(proto_df, pose_dict, i3d_dict, gloss2idx)\ntest_ds  = SignDataset(test_df,  pose_dict, i3d_dict, gloss2idx)\n\ntrain_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\ntest_loader  = DataLoader(test_ds,  batch_size=1,  shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T13:14:20.405907Z","iopub.execute_input":"2025-04-17T13:14:20.406173Z","iopub.status.idle":"2025-04-17T13:14:20.415907Z","shell.execute_reply.started":"2025-04-17T13:14:20.406155Z","shell.execute_reply":"2025-04-17T13:14:20.415240Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"#  instantiate model\nmodel     = FusionTransformer(\n    pose_dim = process_pose_feature(next(iter(pose_dict.values()))).shape[-1],\n    i3d_dim  = get_i3d_emb(next(iter(i3d_dict.keys()))).shape[-1],\n    hid_dim  = 512,\n    num_classes = len(gloss2idx)\n).cuda()\n\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\ntriplet   = nn.TripletMarginLoss(margin=0.2)  # optional\n\ndef train_epoch():\n    model.train()\n    for pose_vec, i3d_emb, lbl in train_loader:\n        pose_vec = pose_vec.cuda()\n        i3d_emb  = i3d_emb.cuda()\n        lbl      = lbl.cuda()\n\n        logits, fused = model(pose_vec, i3d_emb)\n        loss = F.cross_entropy(logits, lbl)\n\n        # If you want metric‐learning, sample pos/neg to compute triplet loss here\n        # loss += 0.1 * triplet(anchor, positive, negative)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T13:14:41.304446Z","iopub.execute_input":"2025-04-17T13:14:41.305210Z","iopub.status.idle":"2025-04-17T13:14:44.612807Z","shell.execute_reply.started":"2025-04-17T13:14:41.305179Z","shell.execute_reply":"2025-04-17T13:14:44.612255Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n  warnings.warn(\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"@torch.no_grad()\ndef evaluate():\n    model.eval()\n    # Build prototype embeddings\n    proto_embs, proto_lbls = [], []\n    for pose_vec, i3d_emb, lbl in train_loader:\n        pose_vec = pose_vec.cuda()\n        i3d_emb  = i3d_emb.cuda()\n        _, f = model(pose_vec, i3d_emb)\n        proto_embs.append(f.cpu())\n        proto_lbls.extend(lbl.tolist())\n    proto_embs = torch.cat(proto_embs, dim=0)  # (N_proto, hid_dim)\n\n    correct = [0,0,0]\n    total   = len(test_ds)\n    for pose_vec, i3d_emb, lbl in test_loader:\n        pose_vec = pose_vec.cuda()\n        i3d_emb  = i3d_emb.cuda()\n        _, ftest = model(pose_vec, i3d_emb)\n        sims     = F.cosine_similarity(ftest.cpu(), proto_embs)  # (N_proto)\n        topk_idx = sims.topk(10).indices.tolist()\n        preds    = [proto_lbls[i] for i in topk_idx]\n        for i,k in enumerate((1,5,10)):\n            if lbl.item() in preds[:k]:\n                correct[i] += 1\n\n    print(f\"Top‑1:  {correct[0]/total*100:.2f}%\")\n    print(f\"Top‑5:  {correct[1]/total*100:.2f}%\")\n    print(f\"Top‑10: {correct[2]/total*100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T13:15:03.482414Z","iopub.execute_input":"2025-04-17T13:15:03.482866Z","iopub.status.idle":"2025-04-17T13:15:03.489472Z","shell.execute_reply.started":"2025-04-17T13:15:03.482843Z","shell.execute_reply":"2025-04-17T13:15:03.488726Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"for epoch in range(5):\n    print(f\"--- Epoch {epoch+1} ---\")\n    train_epoch()\n    evaluate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T13:15:10.588072Z","iopub.execute_input":"2025-04-17T13:15:10.588324Z","iopub.status.idle":"2025-04-17T13:17:40.910394Z","shell.execute_reply.started":"2025-04-17T13:15:10.588304Z","shell.execute_reply":"2025-04-17T13:17:40.909743Z"}},"outputs":[{"name":"stdout","text":"--- Epoch 1 ---\nTop‑1:  17.16%\nTop‑5:  20.13%\nTop‑10: 21.62%\n--- Epoch 2 ---\nTop‑1:  16.63%\nTop‑5:  18.77%\nTop‑10: 20.13%\n--- Epoch 3 ---\nTop‑1:  16.19%\nTop‑5:  18.69%\nTop‑10: 20.04%\n--- Epoch 4 ---\nTop‑1:  16.63%\nTop‑5:  19.21%\nTop‑10: 20.61%\n--- Epoch 5 ---\nTop‑1:  16.54%\nTop‑5:  19.39%\nTop‑10: 20.70%\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"import numpy as np\n\ndef gem_pooling(features, p=3.0, eps=1e-6):\n    \"\"\"\n    Apply Generalized Mean (GeM) pooling to the input features.\n    \n    Parameters:\n    - features: np.ndarray of shape (T, D), where T is the temporal dimension and D is the feature dimension.\n    - p: float, the pooling parameter.\n    - eps: float, small value to avoid numerical issues.\n    \n    Returns:\n    - np.ndarray of shape (D,), the pooled feature vector.\n    \"\"\"\n    return np.power(np.mean(np.power(np.clip(features, eps, None), p), axis=0), 1.0 / p)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T13:21:02.704055Z","iopub.execute_input":"2025-04-17T13:21:02.704357Z","iopub.status.idle":"2025-04-17T13:21:02.708841Z","shell.execute_reply.started":"2025-04-17T13:21:02.704337Z","shell.execute_reply":"2025-04-17T13:21:02.708106Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"from sklearn.decomposition import PCA\n\ndef pca_whitening(features, n_components=128, eps=1e-5):\n    \"\"\"\n    Apply PCA whitening to the input features.\n    \n    Parameters:\n    - features: np.ndarray of shape (N, D), where N is the number of samples and D is the feature dimension.\n    - n_components: int, number of principal components to retain.\n    - eps: float, small value to avoid division by zero.\n    \n    Returns:\n    - np.ndarray of shape (N, n_components), the PCA-whitened features.\n    - PCA object fitted to the data.\n    \"\"\"\n    pca = PCA(n_components=n_components, whiten=True)\n    whitened = pca.fit_transform(features)\n    return whitened, pca\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T13:21:10.951137Z","iopub.execute_input":"2025-04-17T13:21:10.951400Z","iopub.status.idle":"2025-04-17T13:21:10.955812Z","shell.execute_reply.started":"2025-04-17T13:21:10.951381Z","shell.execute_reply":"2025-04-17T13:21:10.955068Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"def zca_whitening(features, eps=1e-5):\n    \"\"\"\n    Apply ZCA whitening to the input features.\n    \n    Parameters:\n    - features: np.ndarray of shape (N, D), where N is the number of samples and D is the feature dimension.\n    - eps: float, small value to avoid division by zero.\n    \n    Returns:\n    - np.ndarray of shape (N, D), the ZCA-whitened features.\n    \"\"\"\n    # Compute the covariance matrix\n    sigma = np.cov(features, rowvar=False)\n    # Singular Value Decomposition\n    U, S, _ = np.linalg.svd(sigma)\n    # Compute the ZCA whitening matrix\n    zca_matrix = U @ np.diag(1.0 / np.sqrt(S + eps)) @ U.T\n    # Apply the ZCA whitening matrix\n    return features @ zca_matrix.T\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T13:21:20.130651Z","iopub.execute_input":"2025-04-17T13:21:20.130913Z","iopub.status.idle":"2025-04-17T13:21:20.135393Z","shell.execute_reply.started":"2025-04-17T13:21:20.130893Z","shell.execute_reply":"2025-04-17T13:21:20.134599Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"def process_i3d_features(i3d_features_list, p=3.0, n_components=128, eps=1e-5):\n    \"\"\"\n    Process a list of I3D features by applying GeM pooling, PCA whitening, and ZCA whitening.\n    \n    Parameters:\n    - i3d_features_list: list of np.ndarray, each of shape (T, D).\n    - p: float, GeM pooling parameter.\n    - n_components: int, number of PCA components.\n    - eps: float, small value to avoid numerical issues.\n    \n    Returns:\n    - np.ndarray of shape (N, D), the processed features.\n    \"\"\"\n    # Apply GeM pooling to each feature set\n    gem_pooled = np.array([gem_pooling(f, p=p, eps=eps) for f in i3d_features_list])\n    # Apply PCA whitening\n    pca_whitened, _ = pca_whitening(gem_pooled, n_components=n_components, eps=eps)\n    # Apply ZCA whitening\n    zca_whitened = zca_whitening(pca_whitened, eps=eps)\n    return zca_whitened\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T13:21:26.622602Z","iopub.execute_input":"2025-04-17T13:21:26.622886Z","iopub.status.idle":"2025-04-17T13:21:26.628054Z","shell.execute_reply.started":"2025-04-17T13:21:26.622865Z","shell.execute_reply":"2025-04-17T13:21:26.627329Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\n# GeM pooling\ndef gem_pooling(i3d_feat, p=3.0, eps=1e-6):\n    x = torch.tensor(i3d_feat)\n    x = x.clamp(min=eps).pow(p)\n    x = x.mean(dim=2).pow(1./p)\n    return x.squeeze().numpy()\n\n# ZCA Whitening\ndef zca_whitening(X, eps=1e-5):\n    scaler = StandardScaler()\n    X_norm = scaler.fit_transform(X)\n    cov = np.cov(X_norm, rowvar=False)\n    U, S, V = np.linalg.svd(cov)\n    W = np.dot(U, np.dot(np.diag(1.0 / np.sqrt(S + eps)), U.T))\n    return np.dot(X_norm, W)\n\n# Prepare pooled + PCA + ZCA features\ndef prepare_features(df, i3d_dict, pca=None, fit_pca=False):\n    features = []\n    ids = []\n    for uid in df[\"uid\"]:\n        if uid in i3d_dict:\n            feat = gem_pooling(i3d_dict[uid])  # shape [1024]\n            features.append(feat)\n            ids.append(uid)\n    features = np.stack(features)\n    if fit_pca:\n        pca = PCA(n_components=768, whiten=True).fit(features)\n    features = pca.transform(features)\n    features = zca_whitening(features)\n    return features, ids, pca\n\n# Cosine similarity\ndef cosine_similarity(A, B):\n    A_norm = A / np.linalg.norm(A, axis=1, keepdims=True)\n    B_norm = B / np.linalg.norm(B, axis=1, keepdims=True)\n    return np.dot(A_norm, B_norm.T)\n\n# Top-k accuracy\ndef topk_from_similarity(S, y_tr, y_te, k):\n    ranks = np.argsort(-S, axis=1)\n    return np.mean([y_te[i] in [y_tr[j] for j in ranks[i, :k]] for i in range(len(y_te))]) * 100\n\np = 2.0\npca_dim = 1024\n\n# --- Main Pipeline ---\n# Prepare prototype features\nproto_features, proto_ids, pca = prepare_features(proto_df, i3d_dict, fit_pca=True)\nproto_labels = [proto_df[proto_df[\"uid\"] == uid][\"gloss\"].values[0] for uid in proto_ids]\n\n# Prepare test features\ntest_features, test_ids, _ = prepare_features(test_df, i3d_dict, pca=pca)\ntest_labels = [test_df[test_df[\"uid\"] == uid][\"gloss\"].values[0] for uid in test_ids]\n\n# Similarity and accuracy\nS = cosine_similarity(test_features, proto_features)\nprint(\"Top‑1 Accuracy:  {:.2f}%\".format(topk_from_similarity(S, proto_labels, test_labels, 1)))\nprint(\"Top‑5 Accuracy:  {:.2f}%\".format(topk_from_similarity(S, proto_labels, test_labels, 5)))\nprint(\"Top‑10 Accuracy: {:.2f}%\".format(topk_from_similarity(S, proto_labels, test_labels, 10)))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T13:29:58.554272Z","iopub.execute_input":"2025-04-17T13:29:58.554534Z","iopub.status.idle":"2025-04-17T13:30:06.738044Z","shell.execute_reply.started":"2025-04-17T13:29:58.554514Z","shell.execute_reply":"2025-04-17T13:30:06.737373Z"}},"outputs":[{"name":"stdout","text":"Top‑1 Accuracy:  19.47%\nTop‑5 Accuracy:  24.16%\nTop‑10 Accuracy: 26.87%\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"def evaluate(prototypes, queries, proto_labels, query_labels, top_k=(1, 5, 10)):\n    from sklearn.metrics.pairwise import cosine_distances\n\n    distances = cosine_distances(queries, prototypes)\n    topk_preds = np.argsort(distances, axis=1)\n\n    results = []\n    for k in top_k:\n        correct = 0\n        for i, true_label in enumerate(query_labels):\n            pred_ids = topk_preds[i][:k]\n            pred_labels = [proto_labels[j] for j in pred_ids]\n            if true_label in pred_labels:\n                correct += 1\n        acc = (correct / len(query_labels)) * 100\n        results.append(acc)\n\n    return results  # [top1, top5, top10]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T13:38:32.724086Z","iopub.execute_input":"2025-04-17T13:38:32.724608Z","iopub.status.idle":"2025-04-17T13:38:32.729916Z","shell.execute_reply.started":"2025-04-17T13:38:32.724584Z","shell.execute_reply":"2025-04-17T13:38:32.729069Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.decomposition import PCA\n\ndef whiten_and_pca(proto_features, test_features, dim=768):\n    \"\"\"\n    Apply PCA + ZCA whitening.\n    \"\"\"\n    # Stack all data to fit PCA\n    all_features = np.vstack([proto_features, test_features])\n    pca = PCA(n_components=dim, whiten=True, random_state=42)\n    pca.fit(all_features)\n\n    # Transform\n    proto_pca = pca.transform(proto_features)\n    test_pca  = pca.transform(test_features)\n    return proto_pca, test_pca\n\n# GeM pooling\ndef gem_pooling(i3d_feat, p=3.0, eps=1e-6):\n    x = torch.tensor(i3d_feat)\n    x = x.clamp(min=eps).pow(p)\n    x = x.mean(dim=2).pow(1./p)\n    return x.squeeze().numpy()\n\n# ZCA Whitening\ndef zca_whitening(X, eps=1e-5):\n    scaler = StandardScaler()\n    X_norm = scaler.fit_transform(X)\n    cov = np.cov(X_norm, rowvar=False)\n    U, S, V = np.linalg.svd(cov)\n    W = np.dot(U, np.dot(np.diag(1.0 / np.sqrt(S + eps)), U.T))\n    return np.dot(X_norm, W)\n\n# Prepare pooled + PCA + ZCA features\ndef prepare_features(df, i3d_dict, p=3.0):\n    features = []\n    ids = []\n    for uid in df[\"uid\"]:\n        if uid in i3d_dict:\n            raw_feat = np.array(i3d_dict[uid], dtype=np.float32)\n            gem_feat = gem_pooling(raw_feat, p=p)\n            features.append(gem_feat)\n            ids.append(uid)\n    return np.array(features), ids\n\n# Cosine similarity\ndef cosine_similarity(A, B):\n    A_norm = A / np.linalg.norm(A, axis=1, keepdims=True)\n    B_norm = B / np.linalg.norm(B, axis=1, keepdims=True)\n    return np.dot(A_norm, B_norm.T)\n\n# Top-k accuracy\ndef topk_from_similarity(S, y_tr, y_te, k):\n    ranks = np.argsort(-S, axis=1)\n    return np.mean([y_te[i] in [y_tr[j] for j in ranks[i, :k]] for i in range(len(y_te))]) * 100\n\n# --- Hyperparameter Sweep ---\np_values = [1.0, 2.0, 3.0, 4.0, 5.0]\npca_dims = [256, 512, 768, 896, 1024]\n\nresults = []\n\nfor p in p_values:\n    for pca_dim in pca_dims:\n        print(f\"\\n🔧 Testing GeM p={p}, PCA dim={pca_dim}...\")\n        \n        # Prepare features\n        proto_features, proto_ids = prepare_features(proto_df, i3d_dict, p=p)\n        test_features,  test_ids  = prepare_features(test_df,  i3d_dict, p=p)\n\n        # Apply PCA whitening\n        proto_features_whitened, test_features_whitened = whiten_and_pca(proto_features, test_features, dim=pca_dim)\n\n        # Get gloss labels\n        proto_labels = [proto_df[proto_df[\"uid\"] == uid][\"gloss\"].values[0] for uid in proto_ids]\n        test_labels  = [test_df[test_df[\"uid\"] == uid][\"gloss\"].values[0]  for uid in test_ids]\n\n        # Evaluate\n        acc1, acc5, acc10 = evaluate(\n            prototypes=proto_features_whitened,\n            proto_labels=proto_labels,\n            queries=test_features_whitened,\n            query_labels=test_labels\n        )\n\n        results.append((p, pca_dim, acc1, acc5, acc10))\n\n        print(f\"✅ Top-1: {float(acc1):.2f}% | Top-5: {float(acc5):.2f}% | Top-10: {float(acc10):.2f}%\")\n\n\n# --- Summary Table ---\nprint(\"\\n📊 All Results:\")\nprint(f\"{'p':>4} {'PCA_dim':>8} {'Top-1':>10} {'Top-5':>10} {'Top-10':>10}\")\nfor p, dim, a1, a5, a10 in results:\n    print(f\"{p:>4} {dim:>8} {a1:>9.2f}% {a5:>9.2f}% {a10:>9.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T13:38:37.765592Z","iopub.execute_input":"2025-04-17T13:38:37.765863Z","iopub.status.idle":"2025-04-17T13:41:23.111473Z","shell.execute_reply.started":"2025-04-17T13:38:37.765846Z","shell.execute_reply":"2025-04-17T13:41:23.110716Z"}},"outputs":[{"name":"stdout","text":"\n🔧 Testing GeM p=1.0, PCA dim=256...\n✅ Top-1: 18.60% | Top-5: 22.98% | Top-10: 26.00%\n\n🔧 Testing GeM p=1.0, PCA dim=512...\n✅ Top-1: 18.95% | Top-5: 23.63% | Top-10: 26.56%\n\n🔧 Testing GeM p=1.0, PCA dim=768...\n✅ Top-1: 19.21% | Top-5: 23.94% | Top-10: 27.09%\n\n🔧 Testing GeM p=1.0, PCA dim=896...\n✅ Top-1: 19.34% | Top-5: 24.11% | Top-10: 27.26%\n\n🔧 Testing GeM p=1.0, PCA dim=1024...\n✅ Top-1: 19.34% | Top-5: 24.16% | Top-10: 27.22%\n\n🔧 Testing GeM p=2.0, PCA dim=256...\n✅ Top-1: 18.77% | Top-5: 22.89% | Top-10: 26.39%\n\n🔧 Testing GeM p=2.0, PCA dim=512...\n✅ Top-1: 18.82% | Top-5: 23.76% | Top-10: 26.65%\n\n🔧 Testing GeM p=2.0, PCA dim=768...\n✅ Top-1: 19.39% | Top-5: 24.29% | Top-10: 27.61%\n\n🔧 Testing GeM p=2.0, PCA dim=896...\n✅ Top-1: 19.26% | Top-5: 24.20% | Top-10: 27.05%\n\n🔧 Testing GeM p=2.0, PCA dim=1024...\n✅ Top-1: 19.61% | Top-5: 24.07% | Top-10: 27.53%\n\n🔧 Testing GeM p=3.0, PCA dim=256...\n✅ Top-1: 18.69% | Top-5: 23.24% | Top-10: 26.13%\n\n🔧 Testing GeM p=3.0, PCA dim=512...\n✅ Top-1: 19.04% | Top-5: 23.94% | Top-10: 26.83%\n\n🔧 Testing GeM p=3.0, PCA dim=768...\n✅ Top-1: 19.34% | Top-5: 24.33% | Top-10: 27.40%\n\n🔧 Testing GeM p=3.0, PCA dim=896...\n✅ Top-1: 19.56% | Top-5: 24.29% | Top-10: 27.48%\n\n🔧 Testing GeM p=3.0, PCA dim=1024...\n✅ Top-1: 19.65% | Top-5: 24.46% | Top-10: 27.57%\n\n🔧 Testing GeM p=4.0, PCA dim=256...\n✅ Top-1: 18.34% | Top-5: 23.28% | Top-10: 26.52%\n\n🔧 Testing GeM p=4.0, PCA dim=512...\n✅ Top-1: 18.99% | Top-5: 23.89% | Top-10: 26.91%\n\n🔧 Testing GeM p=4.0, PCA dim=768...\n✅ Top-1: 19.34% | Top-5: 24.33% | Top-10: 27.40%\n\n🔧 Testing GeM p=4.0, PCA dim=896...\n✅ Top-1: 19.52% | Top-5: 24.29% | Top-10: 27.40%\n\n🔧 Testing GeM p=4.0, PCA dim=1024...\n✅ Top-1: 19.52% | Top-5: 24.55% | Top-10: 27.57%\n\n🔧 Testing GeM p=5.0, PCA dim=256...\n✅ Top-1: 18.29% | Top-5: 23.41% | Top-10: 26.70%\n\n🔧 Testing GeM p=5.0, PCA dim=512...\n✅ Top-1: 18.86% | Top-5: 23.85% | Top-10: 27.22%\n\n🔧 Testing GeM p=5.0, PCA dim=768...\n✅ Top-1: 19.21% | Top-5: 24.38% | Top-10: 27.48%\n\n🔧 Testing GeM p=5.0, PCA dim=896...\n✅ Top-1: 19.61% | Top-5: 24.33% | Top-10: 27.57%\n\n🔧 Testing GeM p=5.0, PCA dim=1024...\n✅ Top-1: 19.56% | Top-5: 24.51% | Top-10: 27.53%\n\n📊 All Results:\n   p  PCA_dim      Top-1      Top-5     Top-10\n 1.0      256     18.60%     22.98%     26.00%\n 1.0      512     18.95%     23.63%     26.56%\n 1.0      768     19.21%     23.94%     27.09%\n 1.0      896     19.34%     24.11%     27.26%\n 1.0     1024     19.34%     24.16%     27.22%\n 2.0      256     18.77%     22.89%     26.39%\n 2.0      512     18.82%     23.76%     26.65%\n 2.0      768     19.39%     24.29%     27.61%\n 2.0      896     19.26%     24.20%     27.05%\n 2.0     1024     19.61%     24.07%     27.53%\n 3.0      256     18.69%     23.24%     26.13%\n 3.0      512     19.04%     23.94%     26.83%\n 3.0      768     19.34%     24.33%     27.40%\n 3.0      896     19.56%     24.29%     27.48%\n 3.0     1024     19.65%     24.46%     27.57%\n 4.0      256     18.34%     23.28%     26.52%\n 4.0      512     18.99%     23.89%     26.91%\n 4.0      768     19.34%     24.33%     27.40%\n 4.0      896     19.52%     24.29%     27.40%\n 4.0     1024     19.52%     24.55%     27.57%\n 5.0      256     18.29%     23.41%     26.70%\n 5.0      512     18.86%     23.85%     27.22%\n 5.0      768     19.21%     24.38%     27.48%\n 5.0      896     19.61%     24.33%     27.57%\n 5.0     1024     19.56%     24.51%     27.53%\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"!pip install pose_format\nfrom pose_format import Pose\ndef load_pose_poseformat(uid, pose_dir):\n    path = os.path.join(pose_dir, f\"{uid}.pose\")\n    with open(path, \"rb\") as f:\n        pose = Pose.read(f.read())\n    coords = pose.body.data.squeeze(1)  # shape: (frames, keypoints, dims)\n    return coords.reshape(coords.shape[0], -1)  # (frames, keypoints*dims)\n\n# Pooling (average) across time axis\ndef avg_pool(seq):\n    return np.mean(seq, axis=0)\n\n# Prepare full feature (I3D + Pose)\ndef prepare_embeddings(df, i3d_dict, pose_dir):\n    feats, labels = [], []\n    for _, row in df.iterrows():\n        uid, gloss = row[\"uid\"], row[\"gloss\"]\n        try:\n            i3d_feat = i3d_dict[uid].squeeze().T  # (T, C)\n            i3d_avg = avg_pool(i3d_feat)          # (C,)\n            pose_seq = load_pose_poseformat(uid, pose_dir)\n            pose_avg = avg_pool(pose_seq)         # (keypoints*dims,)\n            final_feat = np.concatenate([i3d_avg, pose_avg], axis=0)\n            feats.append(final_feat)\n            labels.append(gloss)\n        except Exception as e:\n            print(f\"Skipping {uid}: {e}\")\n    return np.stack(feats), labels\n\n# Prepare embeddings\nproto_X, proto_y = prepare_embeddings(proto_df, i3d_dict, VIDEO_POSE_DIR)\ntest_X, test_y = prepare_embeddings(test_df, i3d_dict, VIDEO_POSE_DIR)\n\n# Output shapes\nprint(proto_X.shape, len(proto_y), test_X.shape, len(test_y))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T11:36:41.443409Z","iopub.execute_input":"2025-04-18T11:36:41.443692Z","iopub.status.idle":"2025-04-18T11:38:46.671256Z","shell.execute_reply.started":"2025-04-18T11:36:41.443665Z","shell.execute_reply":"2025-04-18T11:38:46.670529Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pose_format in /usr/local/lib/python3.11/dist-packages (0.9.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pose_format) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pose_format) (1.15.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from pose_format) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->pose_format) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->pose_format) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->pose_format) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->pose_format) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->pose_format) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->pose_format) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->pose_format) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->pose_format) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->pose_format) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->pose_format) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->pose_format) (2024.2.0)\n(4765, 2752) 4765 (2285, 2752) 2285\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Evaluate Top-K accuracy\nfrom sklearn.metrics.pairwise import cosine_similarity\ndef evaluate(prototypes, proto_labels, queries, query_labels, top_k=(1, 5, 10)):\n    distances = cosine_similarity(queries, prototypes)  # Higher is better\n    topk_preds = np.argsort(distances, axis=1)[:, ::-1]  # descending order\n\n    results = {}\n    for k in top_k:\n        correct = sum([query_labels[i] in [proto_labels[j] for j in topk_preds[i, :k]] for i in range(len(query_labels))])\n        acc = 100.0 * correct / len(query_labels)\n        results[f\"Top-{k}\"] = acc\n    return results\n\n# Run evaluation\nresults = evaluate(proto_X, proto_y, test_X, test_y)\nprint(\"\\n✅ Evaluation Results:\")\nfor k, v in results.items():\n    print(f\"{k} Accuracy: {v:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T11:38:46.672253Z","iopub.execute_input":"2025-04-18T11:38:46.672832Z","iopub.status.idle":"2025-04-18T11:38:47.533783Z","shell.execute_reply.started":"2025-04-18T11:38:46.672808Z","shell.execute_reply":"2025-04-18T11:38:47.532963Z"}},"outputs":[{"name":"stdout","text":"\n✅ Evaluation Results:\nTop-1 Accuracy: 14.14%\nTop-5 Accuracy: 16.50%\nTop-10 Accuracy: 18.16%\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"i3d_dim = 1024\npose_dim = proto_X.shape[1] - i3d_dim\n\n# Split streams\nproto_X_i3d  = proto_X[:, :i3d_dim]\nproto_X_pose = proto_X[:, i3d_dim:]\ntest_X_i3d   = test_X[:,  :i3d_dim]\ntest_X_pose  = test_X[:,  i3d_dim:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T11:39:52.536848Z","iopub.execute_input":"2025-04-18T11:39:52.537649Z","iopub.status.idle":"2025-04-18T11:39:52.541975Z","shell.execute_reply.started":"2025-04-18T11:39:52.537624Z","shell.execute_reply":"2025-04-18T11:39:52.541228Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"sim_i3d  = cosine_similarity(test_X_i3d,  proto_X_i3d)   # Higher = more similar :contentReference[oaicite:6]{index=6}\nsim_pose = cosine_similarity(test_X_pose, proto_X_pose)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T11:40:09.088115Z","iopub.execute_input":"2025-04-18T11:40:09.088580Z","iopub.status.idle":"2025-04-18T11:40:09.691509Z","shell.execute_reply.started":"2025-04-18T11:40:09.088555Z","shell.execute_reply":"2025-04-18T11:40:09.690706Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import numpy as np\n\ndef topk_acc(sim, proto_labels, test_labels, k):\n    # Rankings: sort by descending similarity\n    ranks = np.argsort(-sim, axis=1)\n    correct = 0\n    for i, true in enumerate(test_labels):\n        preds = [proto_labels[j] for j in ranks[i,:k]]\n        if true in preds:\n            correct += 1\n    return 100.0 * correct / len(test_labels)\n\nbest_alpha, best_acc1 = 0.0, 0.0\nfor alpha in np.linspace(0, 1, 11):\n    sim_fused = alpha * sim_i3d + (1 - alpha) * sim_pose\n    acc1 = topk_acc(sim_fused, proto_y, test_y, 1)\n    if acc1 > best_acc1:\n        best_acc1 = acc1\n        best_alpha = alpha\n\nprint(f\"🔧 Best α = {best_alpha:.1f}, Top‑1 = {best_acc1:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T11:40:52.963813Z","iopub.execute_input":"2025-04-18T11:40:52.964173Z","iopub.status.idle":"2025-04-18T11:40:56.847107Z","shell.execute_reply.started":"2025-04-18T11:40:52.964153Z","shell.execute_reply":"2025-04-18T11:40:56.846404Z"}},"outputs":[{"name":"stdout","text":"🔧 Best α = 0.4, Top‑1 = 16.98%\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"sim_fused = best_alpha * sim_i3d + (1 - best_alpha) * sim_pose\nacc1  = topk_acc(sim_fused, proto_y, test_y, 1)\nacc5  = topk_acc(sim_fused, proto_y, test_y, 5)\nacc10 = topk_acc(sim_fused, proto_y, test_y,10)\n\nprint(\"✅ Final Results:\")\nprint(f\"Top‑1 : {acc1:.2f}%\")\nprint(f\"Top‑5 : {acc5:.2f}%\")\nprint(f\"Top‑10: {acc10:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T11:41:19.285511Z","iopub.execute_input":"2025-04-18T11:41:19.286132Z","iopub.status.idle":"2025-04-18T11:41:20.310168Z","shell.execute_reply.started":"2025-04-18T11:41:19.286108Z","shell.execute_reply":"2025-04-18T11:41:20.309507Z"}},"outputs":[{"name":"stdout","text":"✅ Final Results:\nTop‑1 : 16.98%\nTop‑5 : 20.04%\nTop‑10: 22.71%\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Dataset returning fused embeddings\nclass CISLR_Dataset(Dataset):\n    def __init__(self, df):\n        self.uids   = df.uid.values\n        self.labels = df.gloss.values\n    def __len__(self):\n        return len(self.uids)\n    def __getitem__(self, i):\n        uid = self.uids[i]\n        # I3D: (1,C,T,1,1) → (T,C)\n        i3d = i3d_dict[uid].squeeze().transpose(1,0)\n        # Pool to 1024-D\n        i3d = i3d.mean(axis=0)\n        # Pose: (T2, D) → pool to same dim\n        pose = load_pose(uid)\n        pose = pose.mean(axis=0)\n        # Combine\n        feat = np.concatenate([i3d, pose], axis=0)\n        return torch.from_numpy(feat).float(), self.labels[i]\n\n# DataLoaders\nproto_ds = CISLR_Dataset(proto_df)\ntest_ds  = CISLR_Dataset(test_df)\nproto_loader = DataLoader(proto_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\ntest_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T11:48:45.963346Z","iopub.execute_input":"2025-04-18T11:48:45.963643Z","iopub.status.idle":"2025-04-18T11:48:45.971901Z","shell.execute_reply.started":"2025-04-18T11:48:45.963620Z","shell.execute_reply":"2025-04-18T11:48:45.971242Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# ----------------------------\n# 3) MODEL: PART‐WISE TRANSFORMERS\n# ----------------------------\nclass PartEncoder(nn.Module):\n    def __init__(self, in_dim, hid_dim):\n        super().__init__()\n        self.fc   = nn.Linear(in_dim, hid_dim)\n        self.trans = nn.TransformerEncoder(\n            nn.TransformerEncoderLayer(d_model=hid_dim, nhead=4), num_layers=2)\n    def forward(self, x):\n        # x: (batch, time, in_dim)\n        x = self.fc(x)                     # → (B,T,hid)\n        x = x.permute(1,0,2)               # → (T,B,hid)\n        x = self.trans(x)                  # → (T,B,hid)\n        return x.mean(dim=0)               # → (B,hid)\n\nclass WholeBodyEncoder(nn.Module):\n    def __init__(self, part_dim, hid_dim):\n        super().__init__()\n        self.trans = nn.TransformerEncoder(\n            nn.TransformerEncoderLayer(d_model=part_dim, nhead=4), num_layers=2)\n        self.fc    = nn.Linear(part_dim, hid_dim)\n    def forward(self, parts):\n        # parts: list of (B,part_dim) for each part\n        x = torch.stack(parts, dim=0)      # → (num_parts, B, part_dim)\n        x = self.trans(x)                  # → (num_parts, B, part_dim)\n        x = x.mean(dim=0)                  # → (B,part_dim)\n        return self.fc(x)                  # → (B,hid_dim)\n\nclass P3DModel(nn.Module):\n    def __init__(self, i3d_dim, pose_dim, part_splits, hid_dim=512, num_classes=None):\n        \"\"\"\n        part_splits: list of (start_idx,end_idx) slicing the pose vector into parts\n        \"\"\"\n        super().__init__()\n        self.i3d_dim   = i3d_dim\n        self.pose_dim  = pose_dim\n        self.parts     = part_splits\n        # Per-part encoders\n        self.part_encs = nn.ModuleList([\n            PartEncoder(end-start, hid_dim) for (start,end) in part_splits\n        ])\n        # Whole-body\n        self.whole_enc = WholeBodyEncoder(hid_dim, hid_dim)\n        # Final classifier\n        self.fc_out    = nn.Linear(i3d_dim + hid_dim, num_classes)\n    def forward(self, feats):\n        # feats: (B, i3d_dim+pose_dim)\n        i3d  = feats[:, :self.i3d_dim]                  # (B,i3d_dim)\n        pose = feats[:, self.i3d_dim:]                  # (B,pose_dim)\n        # Split pose into time×keypoints? Here assume pooled already!\n        # Instead we simulate per-part 1D sequence = constant across time\n        # For demo, we simply slice the pooled pose vector and treat it as a single‑step sequence\n        part_feats = []\n        for enc,(s,e) in zip(self.part_encs, self.parts):\n            x = pose[:, s:e].unsqueeze(1)  # → (B,1,part_dim)\n            part_feats.append(enc(x))      # → (B,hid_dim)\n        whole = self.whole_enc(part_feats)  # → (B,hid_dim)\n        # Fuse\n        fusion = torch.cat([i3d, whole], dim=1)\n        return self.fc_out(fusion)          # → (B,num_classes)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T11:49:12.477640Z","iopub.execute_input":"2025-04-18T11:49:12.478173Z","iopub.status.idle":"2025-04-18T11:49:12.488199Z","shell.execute_reply.started":"2025-04-18T11:49:12.478148Z","shell.execute_reply":"2025-04-18T11:49:12.487522Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"part_splits = [(0,33),(33,66),(66,99)]\nmodel = P3DModel(\n    i3d_dim   = 1024,\n    pose_dim  = 99,\n    part_splits=part_splits,\n    hid_dim   = 512,\n    num_classes=len(proto_df)\n).to(DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T11:49:22.245585Z","iopub.execute_input":"2025-04-18T11:49:22.245870Z","iopub.status.idle":"2025-04-18T11:49:22.859629Z","shell.execute_reply.started":"2025-04-18T11:49:22.245848Z","shell.execute_reply":"2025-04-18T11:49:22.858903Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n  warnings.warn(\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# PoseFormat loader\nfrom pose_format import Pose\ndef load_pose(uid):\n    buf  = open(os.path.join(VIDEO_POSE_DIR, f\"{uid}.pose\"), \"rb\").read()\n    pose = Pose.read(buf)\n    coords = pose.body.data.squeeze(1)        # (T, K, 2 or 3)\n    return coords.reshape(coords.shape[0], -1)  # (T, K*dim)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T11:50:59.250764Z","iopub.execute_input":"2025-04-18T11:50:59.251669Z","iopub.status.idle":"2025-04-18T11:50:59.256901Z","shell.execute_reply.started":"2025-04-18T11:50:59.251632Z","shell.execute_reply":"2025-04-18T11:50:59.256340Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"proto_feats.append(\n    torch.cat([i3d_avg, emb], dim=1)\n         .detach()          # <- detach here\n         .cpu()\n         .numpy()\n)\nproto_feats = []\nproto_labels= []\nwith torch.no_grad():\n    for feats, labels in proto_loader:\n        feats = feats.to(DEVICE)\n        emb   = model.whole_enc([\n            enc(feats[:, model.i3d_dim + s : model.i3d_dim + e].unsqueeze(1))\n            for enc,(s,e) in zip(model.part_encs, part_splits)\n        ])\n        i3d_avg = feats[:, :model.i3d_dim]\n        # now emb.requires_grad=False, so .numpy() works\n        proto_feats.append(\n            torch.cat([i3d_avg, emb], dim=1)\n                 .cpu()\n                 .numpy()\n        )\n        proto_labels.extend(labels)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T11:53:02.463861Z","iopub.execute_input":"2025-04-18T11:53:02.464747Z","iopub.status.idle":"2025-04-18T11:53:07.590462Z","shell.execute_reply.started":"2025-04-18T11:53:02.464715Z","shell.execute_reply":"2025-04-18T11:53:07.589600Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"model.eval()  # optional, makes sure you’re in inference mode\n\nproto_feats, proto_labels = [], []\nwith torch.no_grad():\n    for feats, labels in proto_loader:\n        feats = feats.to(DEVICE)\n        # part‑wise embedding\n        emb = model.whole_enc([\n            enc(feats[:, model.i3d_dim + s : model.i3d_dim + e].unsqueeze(1))\n            for enc,(s,e) in zip(model.part_encs, part_splits)\n        ])\n        i3d_avg = feats[:, :model.i3d_dim]\n        # Now emb.requires_grad == False\n        arr = torch.cat([i3d_avg, emb], dim=1).cpu().numpy()\n        proto_feats.append(arr)\n        proto_labels.extend(labels)\nproto_X = np.vstack(proto_feats)\n\ntest_feats, test_labels = [], []\nwith torch.no_grad():\n    for feats, labels in test_loader:\n        feats = feats.to(DEVICE)\n        emb = model.whole_enc([\n            enc(feats[:, model.i3d_dim + s : model.i3d_dim + e].unsqueeze(1))\n            for enc,(s,e) in zip(model.part_encs, part_splits)\n        ])\n        i3d_avg = feats[:, :model.i3d_dim]\n        arr = torch.cat([i3d_avg, emb], dim=1).cpu().numpy()\n        test_feats.append(arr)\n        test_labels.extend(labels)\ntest_X = np.vstack(test_feats)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T11:56:12.539562Z","iopub.execute_input":"2025-04-18T11:56:12.539897Z","iopub.status.idle":"2025-04-18T11:56:19.406062Z","shell.execute_reply.started":"2025-04-18T11:56:12.539872Z","shell.execute_reply":"2025-04-18T11:56:19.404966Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"sim = cosine_similarity(test_X, proto_X)\nranks = np.argsort(-sim, axis=1)\n\ndef topk(ranks, y_true, y_ref, k):\n    return 100.0 * np.mean([\n        y_true[i] in [y_ref[j] for j in ranks[i, :k]]\n        for i in range(len(y_true))\n    ])\n\nprint(\"✅ P3D + I3D Retrieval Results\")\nprint(f\"Top‑1 : {topk(ranks, test_labels, proto_labels, 1):.2f}%\")\nprint(f\"Top‑5 : {topk(ranks, test_labels, proto_labels, 5):.2f}%\")\nprint(f\"Top‑10: {topk(ranks, test_labels, proto_labels,10):.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T11:56:22.267149Z","iopub.execute_input":"2025-04-18T11:56:22.267452Z","iopub.status.idle":"2025-04-18T11:56:22.845704Z","shell.execute_reply.started":"2025-04-18T11:56:22.267427Z","shell.execute_reply":"2025-04-18T11:56:22.844882Z"}},"outputs":[{"name":"stdout","text":"✅ P3D + I3D Retrieval Results\nTop‑1 : 16.85%\nTop‑5 : 20.00%\nTop‑10: 22.23%\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics.pairwise import cosine_distances\n\n# Paths\nDATA_DIR = \"/kaggle/input/cislr-dataset\"\nI3D_PKL    = os.path.join(DATA_DIR, \"I3D_features.pkl\")\nPROTO_CSV  = os.path.join(DATA_DIR, \"prototype.csv\")\nTEST_CSV   = os.path.join(DATA_DIR, \"test.csv\")\n\n# Load CSVs\nproto_df = pd.read_csv(PROTO_CSV); proto_df[\"uid\"] = proto_df[\"uid\"].astype(str)\ntest_df  = pd.read_csv(TEST_CSV);  test_df[\"uid\"]  = test_df[\"uid\"].astype(str)\n\n# Load I3D features\ni3d_df    = pd.read_pickle(I3D_PKL)\ni3d_dict  = {r[\"id\"]: np.array(r[\"I3D_features\"], dtype=np.float32) \n             for _, r in i3d_df.iterrows()}\n\n# GeM pooling\ndef gem_pool(features, p=3.0, eps=1e-6):\n    # features: (T, C)\n    f = np.maximum(features, eps)\n    return np.power(np.mean(np.power(f, p), axis=0), 1.0/p)\n\n# PCA whitening\ndef fit_pca_whiten(X, dim=1024):\n    pca = PCA(n_components=dim, whiten=True, svd_solver='auto')\n    pca.fit(X)\n    return pca\n\ndef apply_pca(pca, X):\n    return pca.transform(X)\n\n# Prepare pooled features\ndef prepare_features(df, i3d_dict, p=3.0):\n    feats, labels = [], []\n    for _, row in df.iterrows():\n        uid, gloss = row[\"uid\"], row[\"gloss\"]\n        raw = i3d_dict.get(uid)\n        if raw is None: continue\n        # raw: (1, C, T, 1, 1)\n        arr = raw.squeeze().transpose(1,0)  # → (T, C)\n        gem = gem_pool(arr, p=p)\n        feats.append(gem)\n        labels.append(gloss)\n    return np.vstack(feats), labels\n\n# Compute prototype and test embeddings\np = 3.0\nproto_X, proto_y = prepare_features(proto_df, i3d_dict, p=p)\ntest_X,  test_y  = prepare_features(test_df,  i3d_dict, p=p)\n\n# Fit PCA-whiten on prototypes\npca_dim = 1024\npca = fit_pca_whiten(proto_X, dim=pca_dim)\n\nproto_Xw = apply_pca(pca, proto_X)\ntest_Xw  = apply_pca(pca, test_X)\n\n# Evaluate via cosine distance (lower better, but we use similarity = -distance)\ndist = cosine_distances(test_Xw, proto_Xw)\nranks = np.argsort(dist, axis=1)\n\ndef topk_acc(ranks, true_labels, proto_labels, k):\n    return np.mean([\n        true_labels[i] in [proto_labels[j] for j in ranks[i, :k]]\n        for i in range(len(true_labels))\n    ]) * 100\n\n# Print results\nprint(\"🔧 Best Model: Pure I3D with GeM(p=3) + PCA(dim=1024) Whitening\")\nprint(f\"Top-1 : {topk_acc(ranks, test_y, proto_y, 1):.2f}%\")\nprint(f\"Top-5 : {topk_acc(ranks, test_y, proto_y, 5):.2f}%\")\nprint(f\"Top-10: {topk_acc(ranks, test_y, proto_y,10):.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T11:59:29.944498Z","iopub.execute_input":"2025-04-18T11:59:29.945212Z","iopub.status.idle":"2025-04-18T11:59:54.116293Z","shell.execute_reply.started":"2025-04-18T11:59:29.945184Z","shell.execute_reply":"2025-04-18T11:59:54.115497Z"}},"outputs":[{"name":"stdout","text":"🔧 Best Model: Pure I3D with GeM(p=3) + PCA(dim=1024) Whitening\nTop-1 : 19.47%\nTop-5 : 24.46%\nTop-10: 27.66%\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"import os\nimport math\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics.pairwise import cosine_similarity\n!pip install pose_format\nfrom pose_format import Pose\n\n# ——————————————————————————————————————————————————————\n# 1) CONFIG & PATHS\n# ——————————————————————————————————————————————————————\nDATA_DIR   = \"/kaggle/input/cislr-dataset\"\nI3D_PKL    = os.path.join(DATA_DIR, \"I3D_features.pkl\")\nPOSE_DIR   = os.path.join(DATA_DIR, \"CISLR_v1.5-a_videos_poses\")\nSMPLX_PKL  = os.path.join(DATA_DIR, \"SMPLX_features.pkl\")\nPROTO_CSV  = os.path.join(DATA_DIR, \"prototype.csv\")\nTEST_CSV   = os.path.join(DATA_DIR, \"test.csv\")\n\nDEVICE     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nBATCH_SIZE = 32\nEMB_DIM    = 512\n\n# ——————————————————————————————————————————————————————\n# 2) LOAD DATA\n# ——————————————————————————————————————————————————————\nproto_df = pd.read_csv(PROTO_CSV); proto_df.uid = proto_df.uid.astype(str)\ntest_df  = pd.read_csv(TEST_CSV);  test_df.uid  = test_df.uid.astype(str)\n\ni3d_df   = pd.read_pickle(I3D_PKL)\ni3d_dict = {r[\"id\"]: np.array(r[\"I3D_features\"],dtype=np.float32)\n            for _,r in i3d_df.iterrows()}\n\nif os.path.exists(SMPLX_PKL):\n    smplx_df   = pd.read_pickle(SMPLX_PKL)\n    smplx_dict = {r[\"id\"]: np.array(r[\"smplx\"],dtype=np.float32)\n                  for _,r in smplx_df.iterrows()}\n    SMPLX_DIM  = next(iter(smplx_dict.values())).shape[0]\nelse:\n    smplx_dict = {}\n    SMPLX_DIM  = 104*3\n\ndef load_pose2d_components(uid):\n    buf    = open(os.path.join(POSE_DIR,f\"{uid}.pose\"),\"rb\").read()\n    pose   = Pose.read(buf)\n    coords = pose.body.data.squeeze(1)   # (T, K, 2)\n    T, K, C= coords.shape\n    flat   = coords.reshape(T, -1)       # (T, K*C)\n\n    # landmark splits by index:\n    body_end  = 33\n    face_end  = 33 + 468\n    hand_end  = face_end + 21*2\n\n    b_flat    = flat[:, : body_end*C]\n    f_flat    = flat[:, body_end*C : face_end*C]\n    h_flat    = flat[:, face_end*C : hand_end*C]\n\n    return (\n        b_flat.mean(0).astype(np.float32),\n        f_flat.mean(0).astype(np.float32),\n        h_flat.mean(0).astype(np.float32),\n    )\n\n# infer dims\n_example = proto_df.uid.iloc[0]\nB2D, F2D, H2D = load_pose2d_components(_example)\nBODY_DIM, FACE_DIM, HAND_DIM = B2D.shape[0], F2D.shape[0], H2D.shape[0]\n\nclass PGVT_Dataset(Dataset):\n    def __init__(self, df):\n        self.uids, self.labels = df.uid.values, df.gloss.values\n    def __len__(self):\n        return len(self.uids)\n    def __getitem__(self, i):\n        uid = self.uids[i]\n        # — uniform sampling of exactly S=8 tokens —————————————\n        arr = i3d_dict[uid].squeeze().transpose(1,0)  # (T,1024)\n        T   = arr.shape[0]\n        S   = 8\n        idx = np.round(np.linspace(0, T-1, S)).astype(int)\n        vid = arr[idx].astype(np.float32)             # (8,1024)\n        b2d,f2d,h2d = load_pose2d_components(uid)\n        s3d = smplx_dict.get(uid, np.zeros(SMPLX_DIM, dtype=np.float32))\n        return (\n            torch.from_numpy(vid),\n            torch.from_numpy(b2d),\n            torch.from_numpy(f2d),\n            torch.from_numpy(h2d),\n            torch.from_numpy(s3d),\n            self.labels[i]\n        )\n\nproto_loader = DataLoader(PGVT_Dataset(proto_df), batch_size=BATCH_SIZE, shuffle=False)\ntest_loader  = DataLoader(PGVT_Dataset(test_df),  batch_size=BATCH_SIZE, shuffle=False)\n\n# ——————————————————————————————————————————————————————\n# 3) MODEL\n# ——————————————————————————————————————————————————————\nclass ContentAwareConv(nn.Module):\n    def __init__(self, dim, k=5):\n        super().__init__()\n        self.conv = nn.Conv1d(dim, dim, kernel_size=k, padding=k//2, groups=dim)\n    def forward(self, x):\n        x = x.permute(0,2,1)\n        x = self.conv(x)\n        return x.permute(0,2,1)\n\nclass PGVT(nn.Module):\n    def __init__(self, in_c, p2d_dim, p3d_dim, emb_dim, nhead=8, nlayers=4):\n        super().__init__()\n        self.emb_dim   = emb_dim\n        self.proj_vid  = nn.Linear(in_c, emb_dim)\n        self.proj_p2d  = nn.Linear(p2d_dim, emb_dim)\n        self.proj_p3d  = nn.Linear(p3d_dim, emb_dim)\n        self.cac2d     = ContentAwareConv(emb_dim)\n        self.cac3d     = ContentAwareConv(emb_dim)\n        self.cls_token = nn.Parameter(torch.randn(1,1,emb_dim))\n        layer = nn.TransformerEncoderLayer(d_model=emb_dim,\n                                           nhead=nhead,\n                                           batch_first=True)\n        self.encoder = nn.TransformerEncoder(layer, num_layers=nlayers)\n        self.fc      = nn.Linear(emb_dim, len(proto_df))\n    def forward(self, vid, p2d, p3d):\n        B = vid.size(0)\n        v = self.proj_vid(vid)             # (B,8,emb)\n        d = self.cac2d(self.proj_p2d(p2d).unsqueeze(1))\n        h = self.cac3d(self.proj_p3d(p3d).unsqueeze(1))\n        cls = self.cls_token.expand(B,-1,-1)\n        x  = torch.cat([cls, v, d, h], dim=1)\n\n        # sinusoidal positional encoding\n        B, L, E = x.shape\n        pos = torch.arange(L, device=x.device).unsqueeze(1)  # (L,1)\n        div = torch.exp(torch.arange(0, E, 2, device=x.device)\n                        * -(math.log(10000.0) / E))            # (E/2,)\n        pe = torch.zeros(L, E, device=x.device)             # (L, E)\n        pe[:, 0::2] = torch.sin(pos * div)\n        pe[:, 1::2] = torch.cos(pos * div)\n        pe = pe.unsqueeze(0)                                # (1, L, E)\n        x = x + pe                                         \n\n        y = self.encoder(x)\n        return y[:,0]\n\nmodel = PGVT(1024, BODY_DIM, SMPLX_DIM, EMB_DIM).to(DEVICE).eval()\n\n# ——————————————————————————————————————————————————————\n# 4) EXTRACTION & EVAL\n# ——————————————————————————————————————————————————————\ndef extract_embeddings(loader, fn):\n    X, Y = [], []\n    with torch.no_grad():\n        for vid, b2d, f2d, h2d, s3d, lbl in loader:\n            emb = fn(\n                vid.to(DEVICE),\n                b2d.to(DEVICE),\n                f2d.to(DEVICE),\n                h2d.to(DEVICE),\n                s3d.to(DEVICE)\n            )\n            X.append(emb.cpu().numpy())\n            Y.extend(lbl)\n    return np.vstack(X), Y\n\n# scoring helper\ndef topk(ranks, y_true, y_ref, k):\n    return 100 * np.mean([\n        y_true[i] in [y_ref[j] for j in ranks[i,:k]]\n        for i in range(len(y_true))\n    ])\n\n# full fusion\nfull_fn = lambda v,b2d,f2d,h2d,s3d: model(v, b2d, s3d)\npX, pY = extract_embeddings(proto_loader, full_fn)\ntX, tY = extract_embeddings(test_loader,  full_fn)\nr    = cosine_similarity(tX, pX)\nranks= np.argsort(-r, axis=1)\nprint(\"✅ Full‑fusion\")\nprint(f\"Top‑1 : {topk(ranks,tY,pY,1):.2f}%  Top‑5 : {topk(ranks,tY,pY,5):.2f}%  Top‑10: {topk(ranks,tY,pY,10):.2f}%\")\n\n# pose‑only\nclass PoseOnly(nn.Module):\n    def __init__(self,in_dim,emb_dim):\n        super().__init__()\n        self.fc  = nn.Linear(in_dim, emb_dim)\n        self.cac = ContentAwareConv(emb_dim)\n    def forward(self,x):\n        y = self.fc(x).unsqueeze(1)\n        return self.cac(y).squeeze(1)\n\nencs = {\n    \"body\" : PoseOnly(BODY_DIM, EMB_DIM).to(DEVICE).eval(),\n    \"face\" : PoseOnly(FACE_DIM, EMB_DIM).to(DEVICE).eval(),\n    \"hands\": PoseOnly(HAND_DIM, EMB_DIM).to(DEVICE).eval(),\n}\n\nfor mode, enc in encs.items():\n    pose_fn = lambda v,b2d,f2d,h2d,s3d, m=mode: \\\n        enc({'body': b2d, 'face': f2d, 'hands': h2d}[m])\n    Xp, Yp = extract_embeddings(proto_loader, pose_fn)\n    Xt, Yt = extract_embeddings(test_loader,  pose_fn)\n\n    r     = cosine_similarity(Xt, Xp)\n    ranks = np.argsort(-r, axis=1)\n\n    print(f\"✅ {mode.capitalize()}‑only\")\n    print(f\"   Top‑1 : {topk(ranks,Yt,Yp,1):.2f}%  Top‑5 : {topk(ranks,Yt,Yp,5):.2f}%  Top‑10: {topk(ranks,Yt,Yp,10):.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:24:35.412476Z","iopub.execute_input":"2025-04-18T14:24:35.412746Z","iopub.status.idle":"2025-04-18T14:27:34.197256Z","shell.execute_reply.started":"2025-04-18T14:24:35.412725Z","shell.execute_reply":"2025-04-18T14:27:34.196350Z"}},"outputs":[{"name":"stdout","text":"Collecting pose_format\n  Downloading pose_format-0.9.0-py3-none-any.whl.metadata (741 bytes)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pose_format) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pose_format) (1.15.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from pose_format) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->pose_format) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->pose_format) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->pose_format) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->pose_format) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->pose_format) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->pose_format) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->pose_format) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->pose_format) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->pose_format) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->pose_format) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->pose_format) (2024.2.0)\nDownloading pose_format-0.9.0-py3-none-any.whl (97 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.7/97.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pose_format\nSuccessfully installed pose_format-0.9.0\n✅ Full‑fusion\nTop‑1 : 10.11%  Top‑5 : 11.86%  Top‑10: 12.52%\n✅ Body‑only\n   Top‑1 : 12.56%  Top‑5 : 16.19%  Top‑10: 17.46%\n✅ Face‑only\n   Top‑1 : 8.93%  Top‑5 : 12.21%  Top‑10: 14.09%\n✅ Hands‑only\n   Top‑1 : 12.34%  Top‑5 : 14.49%  Top‑10: 16.24%\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport math\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom pose_format import Pose\n\n# ——————————————————————————————————————————————————————\n# 1) CONFIG & PATHS\n# ——————————————————————————————————————————————————————\nDATA_DIR   = \"/kaggle/input/cislr-dataset\"\nI3D_PKL    = os.path.join(DATA_DIR, \"I3D_features.pkl\")\nPOSE_DIR   = os.path.join(DATA_DIR, \"CISLR_v1.5-a_videos_poses\")\nSMPLX_PKL  = os.path.join(DATA_DIR, \"SMPLX_features.pkl\")\nPROTO_CSV  = os.path.join(DATA_DIR, \"prototype.csv\")\nTEST_CSV   = os.path.join(DATA_DIR, \"test.csv\")\n\nDEVICE     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nBATCH_SIZE = 32\nEMB_DIM    = 512\n\n# ——————————————————————————————————————————————————————\n# 2) LOAD DATA\n# ——————————————————————————————————————————————————————\nproto_df = pd.read_csv(PROTO_CSV); proto_df.uid = proto_df.uid.astype(str)\ntest_df  = pd.read_csv(TEST_CSV);  test_df.uid  = test_df.uid.astype(str)\n\ni3d_df   = pd.read_pickle(I3D_PKL)\ni3d_dict = {r['id']: np.array(r['I3D_features'], dtype=np.float32) for _, r in i3d_df.iterrows()}\n\nif os.path.exists(SMPLX_PKL):\n    smplx_df   = pd.read_pickle(SMPLX_PKL)\n    smplx_dict = {r['id']: np.array(r['smplx'], dtype=np.float32) for _, r in smplx_df.iterrows()}\n    SMPLX_DIM  = next(iter(smplx_dict.values())).shape[0]\nelse:\n    smplx_dict = {}\n    SMPLX_DIM  = 104*3\n\ndef load_pose2d_components(uid):\n    buf    = open(os.path.join(POSE_DIR, f\"{uid}.pose\"), \"rb\").read()\n    pose   = Pose.read(buf)\n    coords = pose.body.data.squeeze(1)\n    T, K, C = coords.shape\n    flat   = coords.reshape(T, -1)\n\n    body_end = 33\n    face_end = 33 + 468\n    hand_end = face_end + 21*2\n\n    b_flat = flat[:, : body_end*C]\n    f_flat = flat[:, body_end*C : face_end*C]\n    h_flat = flat[:, face_end*C : hand_end*C]\n\n    return (\n        b_flat.mean(0).astype(np.float32),\n        f_flat.mean(0).astype(np.float32),\n        h_flat.mean(0).astype(np.float32),\n    )\n\n_example = proto_df.uid.iloc[0]\nB2D, F2D, H2D = load_pose2d_components(_example)\nBODY_DIM, FACE_DIM, HAND_DIM = B2D.shape[0], F2D.shape[0], H2D.shape[0]\n\nclass PGVT_Dataset(Dataset):\n    def __init__(self, df):\n        self.uids, self.labels = df.uid.values, df.gloss.values\n    def __len__(self): return len(self.uids)\n    def __getitem__(self, i):\n        uid = self.uids[i]\n        arr = i3d_dict[uid].squeeze().transpose(1,0)\n        T   = arr.shape[0]; S = 8\n        idx = np.round(np.linspace(0, T-1, S)).astype(int)\n        vid = arr[idx].astype(np.float32)\n        b2d, f2d, h2d = load_pose2d_components(uid)\n        s3d = smplx_dict.get(uid, np.zeros(SMPLX_DIM, dtype=np.float32))\n        return (\n            torch.from_numpy(vid),\n            torch.from_numpy(b2d),\n            torch.from_numpy(f2d),\n            torch.from_numpy(h2d),\n            torch.from_numpy(s3d),\n            self.labels[i]\n        )\n\nproto_loader = DataLoader(PGVT_Dataset(proto_df), batch_size=BATCH_SIZE, shuffle=False)\ntest_loader  = DataLoader(PGVT_Dataset(test_df),  batch_size=BATCH_SIZE, shuffle=False)\n\n# ——————————————————————————————————————————————————————\n# 3) MODEL: I3D + Body-Hands Cross-Attention Fusion\n# ——————————————————————————————————————————————————————\nclass ContentAwareConv(nn.Module):\n    def __init__(self, dim, k=5):\n        super().__init__()\n        self.conv = nn.Conv1d(dim, dim, kernel_size=k, padding=k//2, groups=dim)\n    def forward(self, x): return self.conv(x.permute(0,2,1)).permute(0,2,1)\n\nclass CrossModalFusion(nn.Module):\n    def __init__(self, emb_dim, nhead=4):\n        super().__init__()\n        self.attn = nn.MultiheadAttention(emb_dim, nhead, batch_first=True)\n        self.proj = nn.Linear(emb_dim*2, emb_dim)\n    def forward(self, query, keys):\n        q = query.unsqueeze(1)\n        attn_out, _ = self.attn(q, keys, keys)\n        fused = torch.cat([query, attn_out.squeeze(1)], dim=-1)\n        return self.proj(fused)\n\nclass I3DPoseCrossAttn(nn.Module):\n    def __init__(self, in_c, body_dim, hand_dim, emb_dim, nhead=8, nlayers=4):\n        super().__init__()\n        self.emb_dim  = emb_dim\n        self.proj_vid = nn.Linear(in_c, emb_dim)\n        layer = nn.TransformerEncoderLayer(d_model=emb_dim, nhead=nhead, batch_first=True)\n        self.encoder   = nn.TransformerEncoder(layer, num_layers=nlayers)\n        self.pool_body = nn.Linear(body_dim, emb_dim)\n        self.pool_hands= nn.Linear(hand_dim, emb_dim)\n        self.fusion    = CrossModalFusion(emb_dim, nhead=4)\n        self.fc        = nn.Linear(emb_dim, len(proto_df))\n    def forward(self, vid, b2d, f2d, h2d, s3d):\n        B = vid.size(0)\n        v = self.proj_vid(vid)\n        cls_token = nn.Parameter(torch.randn(1,1,self.emb_dim)).to(vid.device)\n        cls = cls_token.expand(B,-1,-1)\n        x   = torch.cat([cls, v], dim=1)\n        L, E = x.size(1), self.emb_dim\n        pos = torch.arange(L, device=x.device).unsqueeze(1)\n        div = torch.exp(torch.arange(0, E, 2, device=x.device) * -(math.log(10000.0)/E))\n        pe = torch.zeros(L, E, device=x.device)\n        pe[:,0::2] = torch.sin(pos * div)\n        pe[:,1::2] = torch.cos(pos * div)\n        x = x + pe.unsqueeze(0)\n        y = self.encoder(x)\n        vid_cls = y[:,0]\n        b_emb   = self.pool_body(b2d)\n        h_emb   = self.pool_hands(h2d)\n        keys    = torch.stack([b_emb, h_emb], dim=1)\n        fused   = self.fusion(vid_cls, keys)\n        return fused\n\nmodel = I3DPoseCrossAttn(1024, BODY_DIM, HAND_DIM, EMB_DIM).to(DEVICE).eval()\n\n# ——————————————————————————————————————————————————————\n# 4) EXTRACTION & EVAL\n# ——————————————————————————————————————————————————————\n\ndef extract_embeddings(loader, fn):\n    X, Y = [], []\n    with torch.no_grad():\n        for vid, b2d, f2d, h2d, s3d, lbl in loader:\n            emb = fn(\n                vid.to(DEVICE),\n                b2d.to(DEVICE),\n                f2d.to(DEVICE),\n                h2d.to(DEVICE),\n                s3d.to(DEVICE)\n            )\n            X.append(emb.cpu().numpy())\n            Y.extend(lbl)\n    return np.vstack(X), Y\n\ndef topk(ranks, y_true, y_ref, k):\n    return 100 * np.mean([y_true[i] in [y_ref[j] for j in ranks[i,:k]] for i in range(len(y_true))])\n\nfusion_fn = lambda v,b2d,f2d,h2d,s3d: model(v,b2d,f2d,h2d,s3d)\npX, pY = extract_embeddings(proto_loader, fusion_fn)\ntX, tY = extract_embeddings(test_loader,  fusion_fn)\nranks   = np.argsort(-cosine_similarity(tX, pX), axis=1)\nprint(\"✅ I3D+Pose Cross‑Attn Fusion\")\nprint(f\"Top‑1 : {topk(ranks,tY,pY,1):.2f}%  Top‑10: {topk(ranks,tY,pY,10):.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:35:17.149732Z","iopub.execute_input":"2025-04-18T14:35:17.150324Z","iopub.status.idle":"2025-04-18T14:35:45.197991Z","shell.execute_reply.started":"2025-04-18T14:35:17.150300Z","shell.execute_reply":"2025-04-18T14:35:45.197168Z"}},"outputs":[{"name":"stdout","text":"✅ I3D+Pose Cross‑Attn Fusion\nTop‑1 : 3.63%  Top‑10: 5.51%\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# ——————————————————————————————————————————————————————\n# CONFIG & PATHS\n# ——————————————————————————————————————————————————————\nDATA_DIR  = \"/kaggle/input/cislr-dataset\"\nI3D_PKL   = os.path.join(DATA_DIR, \"I3D_features.pkl\")\nPROTO_CSV = os.path.join(DATA_DIR, \"prototype.csv\")\nTEST_CSV  = os.path.join(DATA_DIR, \"test.csv\")\n\n# Ensemble variants configuration: (GeM p, PCA dim)\nVARIANTS = [\n    {\"p\": 3.0, \"pca_dim\": 1024},\n    {\"p\": 4.0, \"pca_dim\": 768},\n    {\"p\": 5.0, \"pca_dim\": 1024},\n]\n\n# DEVICE for torch if needed\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# ——————————————————————————————————————————————————————\n# UTILITIES\n# ——————————————————————————————————————————————————————\ndef load_data():\n    proto_df = pd.read_csv(PROTO_CSV)\n    test_df  = pd.read_csv(TEST_CSV)\n    # ensure uid is string\n    proto_df.uid = proto_df.uid.astype(str)\n    test_df.uid  = test_df.uid.astype(str)\n    # load I3D features pickle\n    i3d_df = pd.read_pickle(I3D_PKL)\n    i3d_dict = {str(r['id']): np.array(r['I3D_features'], dtype=np.float32)\n                for _, r in i3d_df.iterrows()}\n    return proto_df, test_df, i3d_dict\n\n# GeM pooling\n# x shape: (T, C) or (C, H, W) flattened to (C, HW) or features over time\n# we assume input arr: numpy array of shape (T, feature_dim)\ndef gem_pooling(arr, p=3.0, axis=0, eps=1e-6):\n    # arr shape e.g. (T, C)\n    return np.power(np.maximum(arr, eps), p).mean(axis=axis) ** (1.0 / p)\n\n# PCA-whitening extractor\nclass PCAWhitening:\n    def __init__(self, dim):\n        self.dim = dim\n        self.pca = PCA(n_components=dim, whiten=True)\n        self.fitted = False\n\n    def fit(self, X):\n        # X: (N_samples, feat_dim_original)\n        self.pca.fit(X)\n        self.fitted = True\n\n    def transform(self, X):\n        assert self.fitted, \"PCAWhitening must be fit before transform\"\n        return self.pca.transform(X)\n\n# Top-k accuracy\ndef topk_accuracy(ranks, y_true, y_ref, k):\n    return 100 * np.mean([\n        y_true[i] in [y_ref[j] for j in ranks[i, :k]]\n        for i in range(len(y_true))\n    ])\n\n# ——————————————————————————————————————————————————————\n# MAIN ENSEMBLE PIPELINE\n# ——————————————————————————————————————————————————————\ndef main():\n    proto_df, test_df, i3d_dict = load_data()\n\n    # extract raw I3D embeddings by uniformly sampling T frames -> (S=8, feature_dim)\n    def extract_raw(uid, S=8):\n        feats = i3d_dict[uid].squeeze().T  # (T, C)\n        T = feats.shape[0]\n        idx = np.round(np.linspace(0, T - 1, S)).astype(int)\n        return feats[idx]\n\n    # prepare storage for each variant\n    proto_desc = {}  # variant key -> ndarray (n_proto, dim)\n    test_desc  = {}  # variant key -> ndarray (n_test, dim)\n    y_proto    = proto_df.gloss.values\n    y_test     = test_df.gloss.values\n\n    # iterate variants\n    for var in VARIANTS:\n        p, pca_dim = var['p'], var['pca_dim']\n        key = f\"GeM_p{p}_PCA{pca_dim}\"\n        print(f\"Processing variant: {key}\")\n\n        # 1) GeM pool raw features\n        proto_feats = np.stack([gem_pooling(extract_raw(uid), p=p)\n                                 for uid in proto_df.uid.values])  # (n_proto, C)\n        test_feats  = np.stack([gem_pooling(extract_raw(uid), p=p)\n                                 for uid in test_df.uid.values])   # (n_test, C)\n\n        # 2) PCA-whitening\n        pw = PCAWhitening(dim=pca_dim)\n        pw.fit(proto_feats)\n        proto_pw = pw.transform(proto_feats)  # (n_proto, pca_dim)\n        test_pw  = pw.transform(test_feats)   # (n_test,  pca_dim)\n\n        # store\n        proto_desc[key] = proto_pw\n        test_desc[key]  = test_pw\n\n    # 3) compute cosine similarity per variant\n    sims = {}\n    for key in proto_desc:\n        sims[key] = cosine_similarity(test_desc[key], proto_desc[key])\n\n    # 4) fuse similarities (average)\n    # shape: (n_test, n_proto)\n    sim_stack = np.stack([sims[key] for key in sims], axis=2)  # (n_test, n_proto, n_var)\n    sim_fused = sim_stack.mean(axis=2)\n\n    # 5) ranking and evaluation\n    ranks = np.argsort(-sim_fused, axis=1)\n    print(\"Ensemble (avg fusion) Results:\")\n    print(f\"Top-1 : {topk_accuracy(ranks, y_test, y_proto, 1):.2f}%\")\n    print(f\"Top-5 : {topk_accuracy(ranks, y_test, y_proto, 5):.2f}%\")\n    print(f\"Top-10: {topk_accuracy(ranks, y_test, y_proto, 10):.2f}%\")\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:43:14.208808Z","iopub.execute_input":"2025-04-18T14:43:14.209372Z","iopub.status.idle":"2025-04-18T14:43:21.965783Z","shell.execute_reply.started":"2025-04-18T14:43:14.209347Z","shell.execute_reply":"2025-04-18T14:43:21.965117Z"}},"outputs":[{"name":"stdout","text":"Processing variant: GeM_p3.0_PCA1024\nProcessing variant: GeM_p4.0_PCA768\nProcessing variant: GeM_p5.0_PCA1024\nEnsemble (avg fusion) Results:\nTop-1 : 19.04%\nTop-5 : 24.64%\nTop-10: 27.61%\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# ——————————————————————————————————————————————————————\n# CONFIG & PATHS\n# ——————————————————————————————————————————————————————\nDATA_DIR  = \"/kaggle/input/cislr-dataset\"\nI3D_PKL   = os.path.join(DATA_DIR, \"I3D_features.pkl\")\nPROTO_CSV = os.path.join(DATA_DIR, \"prototype.csv\")\nTEST_CSV  = os.path.join(DATA_DIR, \"test.csv\")\n\nVARIANTS = [\n    {\"p\": 3.0, \"pca_dim\": 1024},\n    {\"p\": 4.0, \"pca_dim\": 768},\n    {\"p\": 5.0, \"pca_dim\": 1024},\n]\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# ——————————————————————————————————————————————————————\n# UTILITIES (same as before)\n# ——————————————————————————————————————————————————————\ndef load_data():\n    proto_df = pd.read_csv(PROTO_CSV)\n    test_df  = pd.read_csv(TEST_CSV)\n    proto_df.uid = proto_df.uid.astype(str)\n    test_df.uid  = test_df.uid.astype(str)\n    i3d_df = pd.read_pickle(I3D_PKL)\n    i3d_dict = {str(r['id']): np.array(r['I3D_features'], dtype=np.float32)\n                for _, r in i3d_df.iterrows()}\n    return proto_df, test_df, i3d_dict\n\ndef gem_pooling(arr, p=3.0, axis=0, eps=1e-6):\n    return np.power(np.maximum(arr, eps), p).mean(axis=axis) ** (1.0 / p)\n\nclass PCAWhitening:\n    def __init__(self, dim):\n        self.pca = PCA(n_components=dim, whiten=True)\n        self.fitted = False\n    def fit(self, X):\n        self.pca.fit(X); self.fitted = True\n    def transform(self, X):\n        assert self.fitted, \"fit() first\"\n        return self.pca.transform(X)\n\ndef topk_accuracy(ranks, y_true, y_ref, k):\n    return 100 * np.mean([\n        y_true[i] in [y_ref[j] for j in ranks[i, :k]]\n        for i in range(len(y_true))\n    ])\n\n# ——————————————————————————————————————————————————————\n# MAIN with RRF FUSION\n# ——————————————————————————————————————————————————————\ndef main(rrf_c=60):\n    proto_df, test_df, i3d_dict = load_data()\n    y_proto = proto_df.gloss.values\n    y_test  = test_df.gloss.values\n\n    # helper to get raw (S=8) I3D features\n    def extract_raw(uid, S=8):\n        feats = i3d_dict[uid].squeeze().T\n        T = feats.shape[0]\n        idx = np.round(np.linspace(0, T - 1, S)).astype(int)\n        return feats[idx]\n\n    # 1–3) as before: build proto_desc, test_desc, compute sims\n    proto_desc, test_desc = {}, {}\n    for var in VARIANTS:\n        key = f\"GeM_p{var['p']}_PCA{var['pca_dim']}\"\n        # pool\n        pf = np.stack([gem_pooling(extract_raw(uid), p=var['p'])\n                       for uid in proto_df.uid])\n        tf = np.stack([gem_pooling(extract_raw(uid), p=var['p'])\n                       for uid in test_df.uid])\n        # PCA‑whiten\n        pw = PCAWhitening(dim=var['pca_dim'])\n        pw.fit(pf)\n        proto_desc[key] = pw.transform(pf)\n        test_desc[key]  = pw.transform(tf)\n\n    # compute cosine sims and ranks per variant\n    sims = {k: cosine_similarity(test_desc[k], proto_desc[k])\n            for k in proto_desc}\n    # ranks[k][t,i] = rank of proto i for test t in variant k\n    ranks = {\n        k: np.argsort(-sims[k], axis=1).argsort(axis=1)\n        for k in sims\n    }\n\n    # 4) RRF fusion\n    # shape: (n_test, n_proto)\n    n_test, n_proto = next(iter(sims.values())).shape\n    rrf_scores = np.zeros((n_test, n_proto), dtype=np.float32)\n    for k in ranks:\n        # add contribution of this variant\n        rrf_scores += 1.0 / (ranks[k] + 1 + rrf_c)\n\n    # 5) ranking & evaluation\n    fused_ranks = np.argsort(-rrf_scores, axis=1)\n    print(\"Ensemble (RRF fusion) Results:\")\n    print(f\"Top-1 : {topk_accuracy(fused_ranks, y_test, y_proto, 1):.2f}%\")\n    print(f\"Top-5 : {topk_accuracy(fused_ranks, y_test, y_proto, 5):.2f}%\")\n    print(f\"Top-10: {topk_accuracy(fused_ranks, y_test, y_proto, 10):.2f}%\")\n\nif __name__ == \"__main__\":\n    main(rrf_c=60)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:52:01.745063Z","iopub.execute_input":"2025-04-18T14:52:01.745334Z","iopub.status.idle":"2025-04-18T14:52:11.127257Z","shell.execute_reply.started":"2025-04-18T14:52:01.745316Z","shell.execute_reply":"2025-04-18T14:52:11.126486Z"}},"outputs":[{"name":"stdout","text":"Ensemble (RRF fusion) Results:\nTop-1 : 19.12%\nTop-5 : 24.64%\nTop-10: 27.57%\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# ——————————————————————————————————————————————————————\n# CONFIG & PATHS\n# ——————————————————————————————————————————————————————\nDATA_DIR  = \"/kaggle/input/cislr-dataset\"\nI3D_PKL   = os.path.join(DATA_DIR, \"I3D_features.pkl\")\nPROTO_CSV = os.path.join(DATA_DIR, \"prototype.csv\")\nTEST_CSV  = os.path.join(DATA_DIR, \"test.csv\")\n\n# Ensemble variants: GeM p and PCA output dimension\nVARIANTS = [\n    {\"p\": 3.0, \"pca_dim\": 1024},\n    {\"p\": 4.0, \"pca_dim\": 768},\n    {\"p\": 5.0, \"pca_dim\": 1024},\n]\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# ——————————————————————————————————————————————————————\n# UTILITIES\n# ——————————————————————————————————————————————————————\ndef load_data():\n    proto_df = pd.read_csv(PROTO_CSV)\n    test_df  = pd.read_csv(TEST_CSV)\n    proto_df.uid = proto_df.uid.astype(str)\n    test_df.uid  = test_df.uid.astype(str)\n    i3d_df = pd.read_pickle(I3D_PKL)\n    i3d_dict = {str(r['id']): np.array(r['I3D_features'], dtype=np.float32)\n                for _, r in i3d_df.iterrows()}\n    return proto_df, test_df, i3d_dict\n\ndef gem_pooling(arr, p=3.0, axis=0, eps=1e-6):\n    return np.power(np.maximum(arr, eps), p).mean(axis=axis) ** (1.0 / p)\n\nclass PCAWhitening:\n    def __init__(self, dim):\n        self.pca = PCA(n_components=dim, whiten=True)\n        self.fitted = False\n    def fit(self, X):\n        self.pca.fit(X)\n        self.fitted = True\n    def transform(self, X):\n        assert self.fitted, \"PCAWhitening must be fit before transform\"\n        return self.pca.transform(X)\n\ndef topk_accuracy(ranks, y_true, y_ref, k):\n    return 100 * np.mean([\n        y_true[i] in [y_ref[j] for j in ranks[i, :k]]\n        for i in range(len(y_true))\n    ])\n\n# ——————————————————————————————————————————————————————\n# MAIN: Weighted Z‑Score Fusion Pipeline\n# ——————————————————————————————————————————————————————\ndef main(eps=1e-6):\n    # Load data\n    proto_df, test_df, i3d_dict = load_data()\n    y_proto = proto_df.gloss.values\n    y_test  = test_df.gloss.values\n\n    # Helper: extract S=8 uniformly sampled frames’ features\n    def extract_raw(uid, S=8):\n        feats = i3d_dict[uid].squeeze().T  # (T, C)\n        T = feats.shape[0]\n        idx = np.round(np.linspace(0, T - 1, S)).astype(int)\n        return feats[idx]\n\n    # 1) Build feature descriptors and compute per‑variant sims\n    proto_desc, test_desc = {}, {}\n    for var in VARIANTS:\n        key = f\"GeM_p{var['p']}_PCA{var['pca_dim']}\"\n        # GeM pooling\n        pf = np.stack([gem_pooling(extract_raw(uid), p=var['p'])\n                       for uid in proto_df.uid])\n        tf = np.stack([gem_pooling(extract_raw(uid), p=var['p'])\n                       for uid in test_df.uid])\n        # PCA‑whitening\n        pw = PCAWhitening(dim=var['pca_dim'])\n        pw.fit(pf)\n        proto_desc[key] = pw.transform(pf)\n        test_desc[key]  = pw.transform(tf)\n\n    # Cosine similarities per variant\n    sims = {k: cosine_similarity(test_desc[k], proto_desc[k])\n            for k in proto_desc}\n\n    # 2) Compute standalone Top‑1 to derive weights\n    variant_keys = list(sims.keys())\n    # Option A: uniform weights\n    # weights = np.ones(len(variant_keys), dtype=np.float32) / len(variant_keys)\n    # Option B: performance‑based weights\n    scores = []\n    for k in variant_keys:\n        ranks_k = np.argsort(-sims[k], axis=1)\n        scores.append(topk_accuracy(ranks_k, y_test, y_proto, 1))\n    weights = np.array(scores, dtype=np.float32)\n    weights /= weights.sum()  # normalize to sum=1\n\n    print(\"Fusion weights:\", dict(zip(variant_keys, weights)))\n\n    # 3) Z‑score normalization + weighted fusion\n    normed = {}\n    for w, k in zip(weights, variant_keys):\n        S     = sims[k]                         # (n_test, n_proto)\n        mu    = S.mean(axis=1, keepdims=True)   # per test sample\n        sigma = S.std(axis=1, keepdims=True) + eps\n        normed[k] = w * (S - mu) / sigma\n\n    sim_fused = sum(normed.values())           # weighted sum\n    fused_ranks = np.argsort(-sim_fused, axis=1)\n\n    # 4) Evaluate\n    print(\"Weighted Norm Fusion Results:\")\n    print(f\"Top-1 : {topk_accuracy(fused_ranks, y_test, y_proto, 1):.2f}%\")\n    print(f\"Top-5 : {topk_accuracy(fused_ranks, y_test, y_proto, 5):.2f}%\")\n    print(f\"Top-10: {topk_accuracy(fused_ranks, y_test, y_proto,10):.2f}%\")\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:58:58.496507Z","iopub.execute_input":"2025-04-18T14:58:58.496783Z","iopub.status.idle":"2025-04-18T14:59:07.169476Z","shell.execute_reply.started":"2025-04-18T14:58:58.496764Z","shell.execute_reply":"2025-04-18T14:59:07.168746Z"}},"outputs":[{"name":"stdout","text":"Fusion weights: {'GeM_p3.0_PCA1024': 0.33485198, 'GeM_p4.0_PCA768': 0.33257404, 'GeM_p5.0_PCA1024': 0.33257404}\nWeighted Norm Fusion Results:\nTop-1 : 18.95%\nTop-5 : 24.73%\nTop-10: 27.61%\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import pairwise_distances\n\n# ——————————————————————————————————————————————————————\n# CONFIG & PATHS\n# ——————————————————————————————————————————————————————\nDATA_DIR  = \"/kaggle/input/cislr-dataset\"\nI3D_PKL   = os.path.join(DATA_DIR, \"I3D_features.pkl\")\nPROTO_CSV = os.path.join(DATA_DIR, \"prototype.csv\")\nTEST_CSV  = os.path.join(DATA_DIR, \"test.csv\")\n\nVARIANTS = [\n    {\"p\": 3.0, \"pca_dim\": 1024},\n    {\"p\": 4.0, \"pca_dim\": 768},\n    {\"p\": 5.0, \"pca_dim\": 1024},\n]\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# ——————————————————————————————————————————————————————\n# UTILITIES\n# ——————————————————————————————————————————————————————\ndef load_data():\n    proto_df = pd.read_csv(PROTO_CSV); proto_df.uid = proto_df.uid.astype(str)\n    test_df  = pd.read_csv(TEST_CSV);  test_df.uid  = test_df.uid.astype(str)\n    i3d_df   = pd.read_pickle(I3D_PKL)\n    i3d_dict = {str(r['id']): np.array(r['I3D_features'], dtype=np.float32)\n                for _, r in i3d_df.iterrows()}\n    return proto_df, test_df, i3d_dict\n\ndef gem_pooling(arr, p=3.0, axis=0, eps=1e-6):\n    return np.power(np.maximum(arr, eps), p).mean(axis=axis) ** (1.0/p)\n\nclass PCAWhitening:\n    def __init__(self, dim):\n        self.pca = PCA(n_components=dim, whiten=True); self.fitted=False\n    def fit(self, X):\n        self.pca.fit(X); self.fitted=True\n    def transform(self, X):\n        assert self.fitted, \"fit() first\"\n        return self.pca.transform(X)\n\ndef topk_accuracy(ranks, y_true, y_ref, k):\n    return 100 * np.mean([\n        y_true[i] in [y_ref[j] for j in ranks[i,:k]]\n        for i in range(len(y_true))\n    ])\n\ndef extract_raw(i3d_arr, S=8):\n    \"\"\"\n    Given i3d_arr.squeeze().T of shape (T,C), uniformly sample S frames.\n    \"\"\"\n    feats = i3d_arr.squeeze().T            # (T, C), T varies per sample :contentReference[oaicite:5]{index=5}\n    T = feats.shape[0]\n    idx = np.round(np.linspace(0, T-1, S)).astype(int)\n    return feats[idx]                      # (S, C)\n\ndef re_ranking(dist_orig, k1=20, k2=6, lambda_value=0.3):\n    \"\"\"\n    k-reciprocal re-ranking (Zhong et al. CVPR 2017) :contentReference[oaicite:6]{index=6}.\n    dist_orig: shape (N, N), N = n_test + n_proto\n    \"\"\"\n    N = dist_orig.shape[0]\n    # 1) initial rankings\n    initial_rank = np.argsort(dist_orig, axis=1)\n    V = np.zeros_like(dist_orig, dtype=np.float32)\n\n    # 2) build k-reciprocal sets\n    for i in range(N):\n        forward_k  = initial_rank[i, :k1+1]\n        backward_k = initial_rank[forward_k, :k1+1]\n        reciprocal = forward_k[np.isin(forward_k,\n                                        np.where(backward_k == i)[0])]\n        if k2 > 1:\n            for j in reciprocal:\n                cand = initial_rank[j, :k2+1]\n                reciprocal = np.unique(np.concatenate((reciprocal, cand)))\n        weight = np.exp(-dist_orig[i, reciprocal])\n        V[i, reciprocal] = weight / np.sum(weight)\n\n    # 3) compute Jaccard distance\n    invIndex = [np.where(V[:, j] > 0)[0] for j in range(N)]\n    jaccard_dist = np.zeros_like(dist_orig, dtype=np.float32)\n    for i in range(N):\n        min_sum = np.zeros(N, dtype=np.float32)\n        nz = np.where(V[i, :] > 0)[0]\n        for j in nz:\n            min_sum[invIndex[j]] += np.minimum(V[i,j], V[invIndex[j], j])\n        jaccard_dist[i] = 1 - min_sum / (2 - min_sum)\n\n    # 4) fuse distances\n    return (1 - lambda_value) * dist_orig + lambda_value * jaccard_dist\n\n# ——————————————————————————————————————————————————————\n# MAIN: Fusion + Re-Ranking + Grid Search\n# ——————————————————————————————————————————————————————\nif __name__ == \"__main__\":\n    proto_df, test_df, i3d_dict = load_data()\n    y_proto, y_test = proto_df.gloss.values, test_df.gloss.values\n\n    # 1) extract descriptors & compute sims per variant\n    proto_desc, test_desc, sims_pg = {}, {}, {}\n    for var in VARIANTS:\n        key = f\"GeM_p{var['p']}_PCA{var['pca_dim']}\"\n        # GeM pooling + PCA-whitening\n        pf = np.stack([gem_pooling(extract_raw(i3d_dict[uid]), p=var['p'])\n                       for uid in proto_df.uid])\n        tf = np.stack([gem_pooling(extract_raw(i3d_dict[uid]), p=var['p'])\n                       for uid in test_df.uid])\n        pw = PCAWhitening(dim=var['pca_dim'])\n        pw.fit(pf)\n        proto_desc[key], test_desc[key] = pw.transform(pf), pw.transform(tf)\n        sims_pg[key] = cosine_similarity(test_desc[key], proto_desc[key])\n\n    # 2) derive fusion weights (performance-based) :contentReference[oaicite:7]{index=7}\n    keys = list(sims_pg.keys())\n    scores = []\n    for k in keys:\n        r = np.argsort(-sims_pg[k], axis=1)\n        scores.append(topk_accuracy(r, y_test, y_proto, 1))\n    weights = np.array(scores, dtype=np.float32)\n    weights /= weights.sum()\n    print(\"Fusion weights:\", dict(zip(keys, weights)))\n\n    # 3) fuse probe-gallery sims via weighted z-score :contentReference[oaicite:8]{index=8}\n    def fuse_sims(sims_dict):\n        normed = {}\n        for w,k in zip(weights, keys):\n            S     = sims_dict[k]\n            mu    = S.mean(axis=1, keepdims=True)\n            sigma = S.std(axis=1, keepdims=True) + 1e-6\n            normed[k] = w * (S - mu) / sigma\n        return sum(normed.values())\n\n    sim_pg = fuse_sims(sims_pg)\n    sim_gg = fuse_sims({k: cosine_similarity(proto_desc[k], proto_desc[k])\n                        for k in keys})\n    sim_pp = fuse_sims({k: cosine_similarity(test_desc[k],  test_desc[k])\n                        for k in keys})\n\n    # 4) build full distance matrix for re-ranking :contentReference[oaicite:9]{index=9}\n    n_test, n_proto = sim_pg.shape\n    dist_pg = 1 - sim_pg\n    dist_gg = 1 - sim_gg\n    dist_pp = 1 - sim_pp\n    N = n_test + n_proto\n    all_dist = np.zeros((N, N), dtype=np.float32)\n    all_dist[:n_test, :n_test]   = dist_pp\n    all_dist[:n_test, n_test:]   = dist_pg\n    all_dist[n_test:, :n_test]   = dist_pg.T\n    all_dist[n_test:, n_test:]   = dist_gg\n\n    # 5) grid-search k1, k2, λ for best Top‑1 :contentReference[oaicite:10]{index=10}\n    best_acc, best_params = 0.0, (None,None,None)\n    for k1 in [5, 10, 20, 30]:\n        for k2 in [1, 5, 10]:\n            for lam in [0.2, 0.3, 0.4]:\n                dr = re_ranking(all_dist, k1=k1, k2=k2,\n                                lambda_value=lam)\n                final = dr[:n_test, n_test:]\n                ranks = np.argsort(final, axis=1)\n                acc1  = topk_accuracy(ranks, y_test, y_proto, 1)\n                if acc1 > best_acc:\n                    best_acc, best_params = acc1, (k1, k2, lam)\n\n    print(f\"Best re-ranking Top-1: {best_acc:.2f}% \"\n          f\"with k1={best_params[0]}, k2={best_params[1]}, λ={best_params[2]}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:02:37.966088Z","iopub.execute_input":"2025-04-18T15:02:37.966572Z","iopub.status.idle":"2025-04-18T15:04:21.624267Z","shell.execute_reply.started":"2025-04-18T15:02:37.966550Z","shell.execute_reply":"2025-04-18T15:04:21.623642Z"}},"outputs":[{"name":"stdout","text":"Fusion weights: {'GeM_p3.0_PCA1024': 0.33383802, 'GeM_p4.0_PCA768': 0.334595, 'GeM_p5.0_PCA1024': 0.331567}\nBest re-ranking Top-1: 19.08% with k1=5, k2=1, λ=0.2\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom scipy.linalg import subspace_angles, sqrtm\n\n# Paths\nDATA_DIR = \"/kaggle/input/cislr-dataset\"\nI3D_PKL = os.path.join(DATA_DIR, \"I3D_features.pkl\")\nPROTO_CSV = os.path.join(DATA_DIR, \"prototype.csv\")\nTEST_CSV = os.path.join(DATA_DIR, \"test.csv\")\n\n# Load data\ndef load_data():\n    proto_df = pd.read_csv(PROTO_CSV)\n    test_df = pd.read_csv(TEST_CSV)\n    proto_df.uid = proto_df.uid.astype(str)\n    test_df.uid = test_df.uid.astype(str)\n    i3d_df = pd.read_pickle(I3D_PKL)\n    i3d_dict = {str(r['id']): np.array(r['I3D_features'], dtype=np.float32) for _, r in i3d_df.iterrows()}\n    return proto_df, test_df, i3d_dict\n\n# Sample fixed number of segments (each of shape (d,))\ndef extract_segments(uid, i3d_dict, S=8):\n    arr = i3d_dict[uid].squeeze().T  # (T, C)\n    T = arr.shape[0]\n    idx = np.round(np.linspace(0, T - 1, S)).astype(int)\n    return arr[idx]\n\n# GeM pooling\ndef gem_pooling(arr, p=3.0, axis=0, eps=1e-6):\n    return np.power(np.maximum(arr, eps), p).mean(axis=axis) ** (1.0 / p)\n\n# PCA whitening\nclass PCAWhitening:\n    def __init__(self, dim):\n        self.pca = PCA(n_components=dim, whiten=True)\n        self.fitted = False\n    def fit(self, X): self.pca.fit(X); self.fitted = True\n    def transform(self, X): assert self.fitted; return self.pca.transform(X)\n\n# Mahalanobis matrix\ndef compute_mahalanobis_matrix(X):\n    cov = np.cov(X.T)\n    cov_inv = np.linalg.pinv(cov)\n    return sqrtm(cov_inv)\n\n# Subspace similarity (angle-based)\ndef compute_subspace_sim(A, B, k=5):\n    sims = []\n    for a in A:\n        row = []\n        Ua = np.linalg.svd(a - a.mean(0), full_matrices=False)[0][:, :k]\n        for b in B:\n            Ub = np.linalg.svd(b - b.mean(0), full_matrices=False)[0][:, :k]\n            angles = subspace_angles(Ua, Ub)\n            row.append(-np.sum(np.cos(angles)))\n        sims.append(row)\n    return np.array(sims)\n\n# Evaluation\ndef topk_accuracy(ranks, y_true, y_ref, k):\n    return 100 * np.mean([\n        y_true[i] in [y_ref[j] for j in ranks[i, :k]]\n        for i in range(len(y_true))\n    ])\n\n# Main fusion logic\ndef main():\n    proto_df, test_df, i3d_dict = load_data()\n    y_proto = proto_df.gloss.values\n    y_test = test_df.gloss.values\n\n    # Extract segment-level\n    proto_segs = [extract_segments(uid, i3d_dict) for uid in proto_df.uid]\n    test_segs = [extract_segments(uid, i3d_dict) for uid in test_df.uid]\n\n    # GeM pooled\n    proto_gem = np.stack([gem_pooling(s, p=4.0) for s in proto_segs])\n    test_gem = np.stack([gem_pooling(s, p=4.0) for s in test_segs])\n\n    # PCA + Mahalanobis\n    pca = PCAWhitening(dim=768)\n    pca.fit(proto_gem)\n    proto_pca = pca.transform(proto_gem)\n    test_pca = pca.transform(test_gem)\n\n    maha = compute_mahalanobis_matrix(proto_pca)\n    proto_maha = proto_pca @ maha\n    test_maha = test_pca @ maha\n    sim_maha = cosine_similarity(test_maha, proto_maha)\n\n    # Subspace similarity (segments)\n    sim_subspace = compute_subspace_sim(test_segs, proto_segs)\n\n    # Fusion\n    alpha, beta = 0.6, 0.4\n    sim_fused = alpha * sim_maha + beta * sim_subspace\n\n    # Ranking\n    ranks = np.argsort(-sim_fused, axis=1)\n    print(\"Hybrid Fusion Results:\")\n    print(f\"Top-1 : {topk_accuracy(ranks, y_test, y_proto, 1):.2f}%\")\n    print(f\"Top-5 : {topk_accuracy(ranks, y_test, y_proto, 5):.2f}%\")\n    print(f\"Top-10: {topk_accuracy(ranks, y_test, y_proto, 10):.2f}%\")\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:18:27.854484Z","iopub.execute_input":"2025-04-18T15:18:27.854764Z","iopub.status.idle":"2025-04-18T17:29:45.828201Z","shell.execute_reply.started":"2025-04-18T15:18:27.854744Z","shell.execute_reply":"2025-04-18T17:29:45.827514Z"}},"outputs":[{"name":"stdout","text":"Hybrid Fusion Results:\nTop-1 : 2.76%\nTop-5 : 5.16%\nTop-10: 7.00%\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom itertools import product\n\n# ——————————————————————————————————————————————————————\n# 1) Configuration & Paths\n# ——————————————————————————————————————————————————————\nDATA_DIR = \"/kaggle/input/cislr-dataset\"\nI3D_PKL    = os.path.join(DATA_DIR, \"I3D_features.pkl\")\nPROTO_CSV  = os.path.join(DATA_DIR, \"prototype.csv\")\nTEST_CSV   = os.path.join(DATA_DIR, \"test.csv\")\n\n# instead of loading EMB_PKLs, we’ll build them:\nGEM_PCA_CONFIG = [\n    (3.0, 1024),\n    (4.0,  768),\n    (5.0, 1024),\n]\n\n# re‐ranking / fusion hyperparams\nRRF_K      = 60\nRR_K1      = 20\nRR_K2      = 6\nRR_LAMBDA  = 0.3\n\n# ——————————————————————————————————————————————————————\n# 2) GeM‐pooling + PCA embedding builder\n# ——————————————————————————————————————————————————————\ndef gem_pool(x, p=3.0, eps=1e-6):\n    # x: (T, C)\n    return np.power(np.maximum(x, eps)**p, 1.0/p).mean(axis=0)\n\ndef build_gem_pca_embeddings(i3d_dict, ids, ps, dim):\n    \"\"\"\n    For a given p, dim:\n     - compute GeM pool on each id → vectors of length C\n     - fit PCA(dim) on the proto set, transform both proto & test\n     - L2 normalize\n    Returns: proto_mat (N_proto×dim), test_mat (N_test×dim)\n    \"\"\"\n    # 1) compute raw GeM for all\n    raw = {uid: gem_pool(i3d_dict[uid], p=ps) for uid in ids[\"all\"]}\n    # 2) split into proto/test lists\n    proto_raw = np.vstack([raw[uid] for uid in ids[\"proto\"]])\n    test_raw  = np.vstack([raw[uid] for uid in ids[\"test\"]])\n    # 3) fit PCA on proto only\n    pca = PCA(n_components=dim, whiten=True)\n    proto_pca = pca.fit_transform(proto_raw)\n    test_pca  = pca.transform(test_raw)\n    # 4) L2 normalize\n    proto_n = proto_pca / np.linalg.norm(proto_pca,axis=1,keepdims=True)\n    test_n  = test_pca  / np.linalg.norm(test_pca,axis=1,keepdims=True)\n    return proto_n, test_n\n\n# ——————————————————————————————————————————————————————\n# 3) Utility functions (as before)\n# ——————————————————————————————————————————————————————\ndef reciprocal_rank_fusion(sims, k=RRF_K):\n    n_q, n_p = sims[0].shape\n    ranks = [np.argsort(-s,axis=1) for s in sims]\n    rr = []\n    for m in range(len(sims)):\n        inv = np.empty((n_q,n_p),int)\n        for i in range(n_q):\n            inv[i, ranks[m][i]] = np.arange(n_p)\n        rr.append(inv)\n    score = np.zeros((n_q,n_p),float)\n    for m in range(len(rr)):\n        score += 1.0 / (k + rr[m])\n    return score\n\ndef topk_accuracy(sim, proto_labels, test_labels, ks=(1,5,10)):\n    idx = np.argsort(-sim, axis=1)\n    return {\n        k:100*np.mean([test_labels[i] in [proto_labels[j] for j in idx[i,:k]]\n                       for i in range(len(test_labels))])\n        for k in ks\n    }\n\n# ——————————————————————————————————————————————————————\n# 4) Load CSV & raw I3D\n# ——————————————————————————————————————————————————————\nproto_df = pd.read_csv(PROTO_CSV); proto_df.uid = proto_df.uid.astype(str)\ntest_df  = pd.read_csv(TEST_CSV);  test_df.uid  = test_df.uid.astype(str)\nproto_labels = proto_df.gloss.tolist()\ntest_labels  = test_df.gloss.tolist()\n\ni3d_df = pd.read_pickle(I3D_PKL)\n# build a dict: uid → (T,C) array\ni3d_dict = {\n    r[\"id\"]: np.array(r[\"I3D_features\"],dtype=np.float32).squeeze().transpose(1,0)\n    for _,r in i3d_df.iterrows()\n}\n\n# define id lists\nids = {\n    \"proto\": proto_df.uid.tolist(),\n    \"test\" : test_df.uid.tolist(),\n    \"all\"  : list(proto_df.uid) + list(test_df.uid)\n}\n\n# ——————————————————————————————————————————————————————\n# 5) Build all embedding variants\n# ——————————————————————————————————————————————————————\nsims = {}\nfor p,dim in GEM_PCA_CONFIG:\n    name = f\"p{p}_{dim}\"\n    proto_X, test_X = build_gem_pca_embeddings(i3d_dict, ids, p, dim)\n    sims[name] = cosine_similarity(test_X, proto_X)\n\n# ——————————————————————————————————————————————————————\n# 6) Weighted‐norm fusion\n# ——————————————————————————————————————————————————————\n# you can tune these later—here we just average equally\nweights = {n:1/len(sims) for n in sims}\nsim_weighted = sum(weights[n]*sims[n] for n in sims)\n\n# ——————————————————————————————————————————————————————\n# 7) Reciprocal‑rank fusion\n# ——————————————————————————————————————————————————————\nsim_rrf = reciprocal_rank_fusion(list(sims.values()))\n\n# ——————————————————————————————————————————————————————\n# 8) (Optional) re‑ranking – skipping for now, fall back to sim_weighted\nsim_rerank = sim_weighted.copy()\n\n# ——————————————————————————————————————————————————————\n# 9) Meta‑ensemble weight search on Top‑1\n# ——————————————————————————————————————————————————————\nbest_score, best_w = 0, None\nfor α, β in product(np.linspace(0,1,11), repeat=2):\n    γ = 1 - α - β\n    if γ < 0: continue\n    sim_meta = α*sim_weighted + β*sim_rrf + γ*sim_rerank\n    acc = topk_accuracy(sim_meta, proto_labels, test_labels)[1]\n    if acc > best_score:\n        best_score, best_w = acc, (α,β,γ)\n\nα,β,γ = best_w\nsim_final = α*sim_weighted + β*sim_rrf + γ*sim_rerank\naccs = topk_accuracy(sim_final, proto_labels, test_labels)\n\nprint(\"✅ Meta‑Ensemble Best Weights:\", best_w)\nprint(f\"Meta‑Ensemble Results → Top‑1: {accs[1]:.2f}%  Top‑5: {accs[5]:.2f}%  Top‑10: {accs[10]:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T18:05:01.596533Z","iopub.execute_input":"2025-04-18T18:05:01.596888Z","iopub.status.idle":"2025-04-18T18:05:44.492056Z","shell.execute_reply.started":"2025-04-18T18:05:01.596851Z","shell.execute_reply":"2025-04-18T18:05:44.491252Z"}},"outputs":[{"name":"stdout","text":"✅ Meta‑Ensemble Best Weights: (0.0, 0.9, 0.09999999999999998)\nMeta‑Ensemble Results → Top‑1: 19.26%  Top‑5: 23.98%  Top‑10: 27.22%\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.covariance import LedoitWolf\n\n# 1) Fit shrinkage covariance on prototypes\ncov_est = LedoitWolf().fit(proto_X)      # proto_X: (N_p, D)\nSigma   = cov_est.covariance_           # (D, D)\ninv_S   = np.linalg.inv(Sigma)          # (D, D)\n\n# 2) Precompute prototype‐side terms\n#    inv_S_proto:   (D, N_p)\ninv_S_proto = inv_S.dot(proto_X.T)\n\n#    p_inv_p[j] = mu_j^T S^{-1} mu_j    shape (N_p,)\np_inv_p = np.einsum('ij,ij->j', proto_X.T, inv_S_proto)\n\ndef mahalanobis_sim_efficient(test_X, proto_X, inv_S, inv_S_proto, p_inv_p, batch_size=128):\n    \"\"\"\n    test_X:       (N_q, D)\n    proto_X:      (N_p, D)\n    inv_S:        (D, D)\n    inv_S_proto:  (D, N_p) = inv_S @ proto_X.T\n    p_inv_p:      (N_p,) = diag(proto_X @ inv_S_proto)\n    returns       (N_q, N_p) matrix of -squared‑Mahalanobis distances\n    \"\"\"\n    N_q, D = test_X.shape\n    N_p     = proto_X.shape[0]\n    sims    = np.empty((N_q, N_p), dtype=np.float32)\n\n    for start in range(0, N_q, batch_size):\n        end   = min(N_q, start + batch_size)\n        sub   = test_X[start:end]           # (B, D)\n        # inv_S @ sub^T → (D, B)\n        invS_sub = inv_S.dot(sub.T)\n        # q_inv_q[i] = x_i^T S^{-1} x_i   shape (B,)\n        q_inv_q  = np.einsum('ij,ij->i', sub, invS_sub.T)\n\n        # cross term: sub @ inv_S_proto   → (B, N_p)\n        cross    = sub.dot(inv_S_proto)\n\n        # dist2 = q_inv_q[:,None] - 2*cross + p_inv_p[None,:]\n        dist2    = q_inv_q[:, None] - 2*cross + p_inv_p[None, :]\n\n        sims[start:end] = -dist2  # higher = more similar\n\n    return sims\n\n# 3) Compute the similarity matrix efficiently\nsim_maha = mahalanobis_sim_efficient(\n    test_X, proto_X, inv_S, inv_S_proto, p_inv_p, batch_size=128\n)\n\n# 4) Evaluate Top‑K accuracy\ndef topk_acc(sim, proto_labels, test_labels, ks=(1,5,10)):\n    idx = np.argsort(-sim, axis=1)\n    out = {}\n    for k in ks:\n        out[k] = 100 * np.mean([\n            test_labels[i] in [proto_labels[j] for j in idx[i,:k]]\n            for i in range(len(test_labels))\n        ])\n    return out\n\naccs = topk_acc(sim_maha, proto_labels, test_labels)\nprint(\"🔧 Mahalanobis Retrieval Results\")\nprint(f\"Top‑1 : {accs[1]:.2f}%\")\nprint(f\"Top‑5 : {accs[5]:.2f}%\")\nprint(f\"Top‑10: {accs[10]:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T18:09:46.988640Z","iopub.execute_input":"2025-04-18T18:09:46.989048Z","iopub.status.idle":"2025-04-18T18:09:47.876890Z","shell.execute_reply.started":"2025-04-18T18:09:46.989020Z","shell.execute_reply":"2025-04-18T18:09:47.876186Z"}},"outputs":[{"name":"stdout","text":"🔧 Mahalanobis Retrieval Results\nTop‑1 : 19.21%\nTop‑5 : 23.94%\nTop‑10: 27.09%\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
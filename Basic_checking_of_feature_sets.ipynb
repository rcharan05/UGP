{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rcharan05/UGP/blob/main/Basic_checking_of_feature_sets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Mounting drive, installing dependencies and loading the dataset"
      ],
      "metadata": {
        "id": "pTY747TW5kz4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR8hDsWxKoNG",
        "outputId": "7df45cab-0cff-4111-cd55-d1b83ac5c5ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define local paths (update if needed)\n",
        "DATA_DIR = \"/content/drive/MyDrive/UGP\"\n",
        "VIDEO_POSE_DIR = f\"{DATA_DIR}/CISLR_v1.5-a_videos_poses\"\n",
        "I3D_PKL = f\"{DATA_DIR}/I3D_features.pkl\"\n",
        "PROTO_CSV = f\"{DATA_DIR}/prototype.csv\"\n",
        "TEST_CSV = f\"{DATA_DIR}/test.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dg3RrslBKqXd",
        "outputId": "f3fdb18f-aa8f-4473-eb9c-96c1902d8b24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/97.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m92.2/97.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.7/97.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install required package for pose feature handling\n",
        "!pip install -q pose-format\n",
        "\n",
        "# Standard imports\n",
        "import os, pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import normalize\n",
        "from pose_format import Pose  # Ensure this package is installed via pip\n",
        "import concurrent.futures\n",
        "from joblib import Parallel, delayed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRq6WBqNKt01"
      },
      "outputs": [],
      "source": [
        "# Load CSV files and ensure glosses are strings:\n",
        "proto_df = pd.read_csv(PROTO_CSV)\n",
        "test_df = pd.read_csv(TEST_CSV)\n",
        "proto_df[\"gloss\"] = proto_df[\"gloss\"].astype(str)\n",
        "test_df[\"gloss\"]  = test_df[\"gloss\"].astype(str)\n",
        "# Extract labels as lists for evaluation:\n",
        "y_train = proto_df[\"gloss\"].tolist()\n",
        "y_test  = test_df[\"gloss\"].tolist()\n",
        "\n",
        "# --------------------------\n",
        "# Load I3D features and build a lookup dictionary.\n",
        "# The I3D pickle file should have a DataFrame with a column \"id\" and \"I3D_features\"\n",
        "i3d_df = pd.read_pickle(I3D_PKL)\n",
        "i3d_dict = {}\n",
        "for _, row in i3d_df.iterrows():\n",
        "    vid = row[\"id\"]\n",
        "    # Convert raw I3D features to a float32 NumPy array (assumed shape: (1,1024,11,1,1))\n",
        "    arr = np.array(row[\"I3D_features\"], dtype=np.float32)\n",
        "    # We'll need the raw array later for per-segment processing.\n",
        "    i3d_dict[vid] = arr"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Extraction Functions"
      ],
      "metadata": {
        "id": "uO0p6uH26n_B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaLsYFOIKyTo"
      },
      "outputs": [],
      "source": [
        "# -- Utility: Signed Square-Root (SSR)\n",
        "def apply_ssr(feat):\n",
        "    # Add a small epsilon to avoid taking sqrt of zero.\n",
        "    return np.sign(feat) * np.sqrt(np.abs(feat) + 1e-8)\n",
        "\n",
        "# -- Improved I3D Feature Extraction with Mean + Max Pooling\n",
        "def get_improved_i3d_feature(uid):\n",
        "    \"\"\"\n",
        "    For a given uid, extract its raw I3D feature array (shape: (1,1024,11,1,1)).\n",
        "    Remove singletons, then pool along the segments axis (axis=2 after squeezing).\n",
        "    We take both mean and max pooling to capture average and extreme activations.\n",
        "    Finally, apply SSR and L2-normalize.\n",
        "    \"\"\"\n",
        "    arr = i3d_dict[uid]  # shape: (1,1024,11,1,1)\n",
        "    arr = np.squeeze(arr, axis=(0,3,4))  # Now shape becomes (1024, 11)\n",
        "    mean_pool = np.mean(arr, axis=1)      # (1024,)\n",
        "    max_pool  = np.max(arr, axis=1)        # (1024,)\n",
        "    feat = np.concatenate([mean_pool, max_pool])  # shape: (2048,)\n",
        "    feat = apply_ssr(feat)\n",
        "    # L2 normalize:\n",
        "    norm = np.linalg.norm(feat)\n",
        "    return feat / norm if norm > 0 else feat\n",
        "\n",
        "# -- Improved Pose Feature Extraction with Mean + Max Pooling\n",
        "def get_improved_pose_feature(uid, segments=11):\n",
        "    \"\"\"\n",
        "    For a given uid, load the .pose file.\n",
        "    The original pose data is assumed to be of shape (frames, 1, 576, 3).\n",
        "    After squeezing, we get (frames, 576, 3). We then segment along the temporal axis.\n",
        "    For each segment, compute mean and max pooling, concatenate, apply SSR and normalize.\n",
        "    \"\"\"\n",
        "    pose_filepath = os.path.join(VIDEO_POSE_DIR, f\"{uid}.pose\")\n",
        "    with open(pose_filepath, \"rb\") as f:\n",
        "        buf = f.read()\n",
        "    pose = Pose.read(buf)\n",
        "    coords = pose.body.data  # (frames, 1, 576, 3)\n",
        "    coords = np.squeeze(coords, axis=1)  # now (frames, 576, 3)\n",
        "    T = coords.shape[0]\n",
        "    if T >= segments:\n",
        "        seg_size = T // segments\n",
        "        means, maxes = [], []\n",
        "        for i in range(segments):\n",
        "            start = i * seg_size\n",
        "            end = T if i == segments - 1 else (i + 1) * seg_size\n",
        "            segment = coords[start:end]\n",
        "            means.append(np.mean(segment, axis=0).flatten())\n",
        "            maxes.append(np.max(segment, axis=0).flatten())\n",
        "        mean_pool = np.mean(np.stack(means), axis=0)\n",
        "        max_pool  = np.max(np.stack(maxes), axis=0)\n",
        "    else:\n",
        "        mean_pool = np.mean(coords, axis=0).flatten()\n",
        "        max_pool  = np.max(coords, axis=0).flatten()\n",
        "    feat = np.concatenate([mean_pool, max_pool])\n",
        "    feat = apply_ssr(feat)\n",
        "    norm = np.linalg.norm(feat)\n",
        "    return feat / norm if norm > 0 else feat\n",
        "\n",
        "# -- Build feature arrays concurrently for a given modality\n",
        "def build_improved_features(df, modality=\"i3d\", segments=11):\n",
        "    \"\"\"\n",
        "    Uses concurrent processing to extract improved features.\n",
        "    modality: \"i3d\" or \"pose\"\n",
        "    \"\"\"\n",
        "    uids = df[\"uid\"].tolist()\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        if modality == \"i3d\":\n",
        "            feats = list(executor.map(get_improved_i3d_feature, uids))\n",
        "        elif modality == \"pose\":\n",
        "            feats = list(executor.map(lambda uid: get_improved_pose_feature(uid, segments=segments), uids))\n",
        "        else:\n",
        "            raise ValueError(\"Modality must be either 'i3d' or 'pose'.\")\n",
        "    return np.stack(feats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ezam1P1yLDY0",
        "outputId": "19196614-5eaa-4357-c71a-267a4a80a7e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting improved I3D features...\n",
            "Extracting improved Pose features...\n"
          ]
        }
      ],
      "source": [
        "print(\"Extracting improved I3D features...\")\n",
        "X_i3d_train_improved = build_improved_features(proto_df, modality=\"i3d\")\n",
        "X_i3d_test_improved  = build_improved_features(test_df, modality=\"i3d\")\n",
        "\n",
        "print(\"Extracting improved Pose features...\")\n",
        "X_pose_train_improved = build_improved_features(proto_df, modality=\"pose\", segments=11)\n",
        "X_pose_test_improved  = build_improved_features(test_df, modality=\"pose\", segments=11)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BASELINE COSINE SIMILARITY EVALUATION FUNCTIONS"
      ],
      "metadata": {
        "id": "9Pic9iwo6wL6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGrAHek9LHOr"
      },
      "outputs": [],
      "source": [
        "def compute_cosine_similarity(X_test, X_train):\n",
        "    \"\"\"Compute cosine similarity via dot product (assumes features are L2-normalized).\"\"\"\n",
        "    return X_test.dot(X_train.T)\n",
        "\n",
        "def compute_topk_accuracy(S, y_train, y_test, k_values=[1,5,10]):\n",
        "    ranks = np.argsort(-S, axis=1)\n",
        "    results = {}\n",
        "    for k in k_values:\n",
        "        topk = ranks[:, :k]\n",
        "        acc = np.mean([y_test[i] in [y_train[j] for j in topk[i]] for i in range(len(y_test))]) * 100\n",
        "        results[k] = acc\n",
        "        print(f\"Top-{k} Accuracy: {acc:.2f}%\")\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Checking basic I3D, pose and concatenated feature set accuracies"
      ],
      "metadata": {
        "id": "rq9jmKgS65bO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I3D feature set accuracy"
      ],
      "metadata": {
        "id": "21AU8-dc690z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnH4eFFfLfDT",
        "outputId": "fa21f28d-af0e-4c3b-afe4-107fa301b746"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Evaluation: I3D Only ---\n",
            "I3D Only Cosine Similarity:\n",
            "Top-1 Accuracy: 17.02%\n",
            "Top-5 Accuracy: 20.88%\n",
            "Top-10 Accuracy: 22.93%\n"
          ]
        }
      ],
      "source": [
        "# (A) Using ONLY I3D features:\n",
        "print(\"\\n--- Evaluation: I3D Only ---\")\n",
        "# Ensure features are normalized (they should already be normalized after our extraction)\n",
        "X_i3d_train_norm = normalize(X_i3d_train_improved, axis=1)\n",
        "X_i3d_test_norm  = normalize(X_i3d_test_improved, axis=1)\n",
        "S_i3d = compute_cosine_similarity(X_i3d_test_norm, X_i3d_train_norm)\n",
        "print(\"I3D Only Cosine Similarity:\")\n",
        "acc_i3d = compute_topk_accuracy(S_i3d, y_train, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just pose feature set accuracy"
      ],
      "metadata": {
        "id": "3VTaFCIN6_-0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQ-ajGhFLgFQ",
        "outputId": "01fbad33-a6b0-492b-c63b-a95ed26e9101"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Evaluation: Pose Only ---\n",
            "Pose Only Cosine Similarity:\n",
            "Top-1 Accuracy: 0.31%\n",
            "Top-5 Accuracy: 0.39%\n",
            "Top-10 Accuracy: 0.83%\n"
          ]
        }
      ],
      "source": [
        "# (B) Using ONLY Pose features:\n",
        "print(\"\\n--- Evaluation: Pose Only ---\")\n",
        "X_pose_train_norm = normalize(X_pose_train_improved, axis=1)\n",
        "X_pose_test_norm  = normalize(X_pose_test_improved, axis=1)\n",
        "S_pose = compute_cosine_similarity(X_pose_test_norm, X_pose_train_norm)\n",
        "print(\"Pose Only Cosine Similarity:\")\n",
        "acc_pose = compute_topk_accuracy(S_pose, y_train, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine both with equal weightage (pose brings down accuracy)"
      ],
      "metadata": {
        "id": "edtPIh4T7DlN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNsPz7cpLkQU",
        "outputId": "c52cc358-0706-41db-a383-9fe6396334d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Evaluation: Combined (Separate Modality Weighting) ---\n",
            "Top-1 Accuracy: 15.75%\n",
            "Top-5 Accuracy: 19.69%\n",
            "Top-10 Accuracy: 22.23%\n"
          ]
        }
      ],
      "source": [
        "# (C) Using Both modalities with Separate Modality Weighting:\n",
        "print(\"\\n--- Evaluation: Combined (Separate Modality Weighting) ---\")\n",
        "# Here we fuse the cosine similarities from I3D and pose.\n",
        "# You can use adaptive weights; here we use equal weighting.\n",
        "alpha = 0.5\n",
        "S_combined = alpha * S_i3d + (1 - alpha) * S_pose\n",
        "acc_combined = compute_topk_accuracy(S_combined, y_train, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#More advanced methods but with these basic datasets"
      ],
      "metadata": {
        "id": "4A_AJzE27LPA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "k-Reciprocal Re-Ranking (Simple Version)"
      ],
      "metadata": {
        "id": "FDXcD27J7OUt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4p3bJTHLSKe",
        "outputId": "78987979-a694-418d-d94f-a7bc08ac1d5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Evaluation: Combined with k-Reciprocal Re-Ranking (Simple Heuristic) ---\n",
            "Top-1 Accuracy: 16.02%\n",
            "Top-5 Accuracy: 20.26%\n",
            "Top-10 Accuracy: 22.58%\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{1: np.float64(16.01750547045952),\n",
              " 5: np.float64(20.26258205689278),\n",
              " 10: np.float64(22.582056892778994)}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from joblib import Parallel, delayed\n",
        "\n",
        "def k_reciprocal_rerank_simple(S, k1=20, lambda_value=0.3, n_jobs=-1):\n",
        "    \"\"\"\n",
        "    A simple heuristic re-ranking function.\n",
        "    For each query (row i in S), we:\n",
        "      1. Identify the top (k1+1) gallery neighbors.\n",
        "      2. For each candidate gallery index j in that set, check if\n",
        "         query i appears in the top (k1+1) neighbors for gallery sample j.\n",
        "         (This is done using initial_rank_g2q.)\n",
        "      3. Compute a bonus factor proportional to the size of the reciprocal set.\n",
        "      4. Multiply the similarity score for those gallery samples by (1 + bonus).\n",
        "\n",
        "    This function returns a new similarity matrix of shape S (num_test, num_train).\n",
        "    \"\"\"\n",
        "    num_test, num_train = S.shape\n",
        "    # Sort similarities to get neighbor indices.\n",
        "    initial_rank_q2g = np.argsort(-S, axis=1)  # shape: (num_test, num_train)\n",
        "    initial_rank_g2q = np.argsort(-S, axis=0)  # shape: (num_test, num_train)\n",
        "\n",
        "    def rerank_row(i):\n",
        "        row = S[i, :].copy()\n",
        "        # Get top (k1+1) gallery indices for query i.\n",
        "        forward_neighbors = initial_rank_q2g[i, :k1+1]\n",
        "        # For each candidate gallery sample j, check if query i is also in the top (k1+1) for gallery j.\n",
        "        reciprocal = [j for j in forward_neighbors if i in initial_rank_g2q[:, j][:k1+1]]\n",
        "        # Compute a bonus factor that grows with the number of reciprocal neighbors.\n",
        "        bonus = lambda_value * (len(reciprocal) / (k1+1))\n",
        "        # Boost the similarity scores for the reciprocal gallery samples.\n",
        "        for j in reciprocal:\n",
        "            row[j] = row[j] * (1 + bonus)\n",
        "        return row\n",
        "\n",
        "    # Process each query row in parallel.\n",
        "    new_rows = Parallel(n_jobs=n_jobs)(delayed(rerank_row)(i) for i in range(num_test))\n",
        "    S_re_rank = np.vstack(new_rows)\n",
        "    return S_re_rank\n",
        "\n",
        "# Example usage:\n",
        "print(\"\\n--- Evaluation: Combined with k-Reciprocal Re-Ranking (Simple Heuristic) ---\")\n",
        "S_re_rank_simple = k_reciprocal_rerank_simple(S_combined, k1=20, lambda_value=0.3, n_jobs=-1)\n",
        "compute_topk_accuracy(S_re_rank_simple, y_train, y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pose-Guided I3D Feature Extraction"
      ],
      "metadata": {
        "id": "N0gt8xa77RYi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tcn_39YYQS17"
      },
      "outputs": [],
      "source": [
        "# ---------------------------------------\n",
        "# FIXED: Pose‑Guided I3D Pooling\n",
        "# ---------------------------------------\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "def get_pose_guided_i3d_feature(uid):\n",
        "    # 1) Load raw I3D: shape (1,1024,T,1,1)\n",
        "    arr = i3d_dict[uid]                      # (1,1024,T,1,1)\n",
        "    arr = arr.squeeze(axis=(0,3,4))         # → (1024, T_i3d)\n",
        "    D, T_i3d = arr.shape\n",
        "\n",
        "    # 2) Load pose coords\n",
        "    buf  = open(f\"{VIDEO_POSE_DIR}/{uid}.pose\",\"rb\").read()\n",
        "    pose = Pose.read(buf)\n",
        "    coords = pose.body.data.squeeze(1)       # (frames, 576, 3)\n",
        "    F = coords.shape[0]\n",
        "\n",
        "    # 3) Build wrist trajectory (avg of left & right)\n",
        "    wrist = (coords[:, 15] + coords[:, 16]) * 0.5  # (frames,3)\n",
        "\n",
        "    # 4) Compute one weight per I3D segment by summing wrist velocity\n",
        "    seg_len = max(F // T_i3d, 1)\n",
        "    weights = []\n",
        "    for t in range(T_i3d):\n",
        "        start = t * seg_len\n",
        "        end   = F if t == T_i3d - 1 else (t + 1) * seg_len\n",
        "        seg   = wrist[start:end]\n",
        "        if seg.shape[0] > 1:\n",
        "            vt = np.sum(np.linalg.norm(np.diff(seg, axis=0), axis=1))\n",
        "        else:\n",
        "            vt = 0.0\n",
        "        weights.append(vt + 1e-6)\n",
        "    w = np.array(weights)                    # (T_i3d,)\n",
        "\n",
        "    # 5) Weighted pooling of I3D segments\n",
        "    Fi3d = (arr * w).sum(axis=1) / w.sum()    # (1024,)\n",
        "\n",
        "    # 6) SSR + L2‑normalize\n",
        "    Fi3d = np.sign(Fi3d) * np.sqrt(np.abs(Fi3d) + 1e-8)\n",
        "    Fi3d /= np.linalg.norm(Fi3d) + 1e-12\n",
        "\n",
        "    return Fi3d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1V4_iJ-qQUAP",
        "outputId": "a9a39e18-6885-489a-fd01-59789da721f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting pose‑guided I3D features…\n"
          ]
        }
      ],
      "source": [
        "  # Now rebuild your pose‑guided I3D features:\n",
        "  print(\"Extracting pose‑guided I3D features…\")\n",
        "  X_i3d_pg_train = np.vstack([get_pose_guided_i3d_feature(u) for u in proto_df[\"uid\"]])\n",
        "  X_i3d_pg_test  = np.vstack([get_pose_guided_i3d_feature(u) for u in test_df[\"uid\"]])\n",
        "\n",
        "  # L2‑normalize\n",
        "  X_i3d_pg_train_n = normalize(X_i3d_pg_train, axis=1)\n",
        "  X_i3d_pg_test_n  = normalize(X_i3d_pg_test,  axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfbFSb2CQYd_",
        "outputId": "2e7e28a4-9c4f-430c-e0b4-71c238a48b49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Evaluation: Pose‑Guided I3D Only ---\n",
            "Top-1 Accuracy: 16.46%\n",
            "Top-5 Accuracy: 20.13%\n",
            "Top-10 Accuracy: 22.41%\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{1: np.float64(16.455142231947484),\n",
              " 5: np.float64(20.13129102844639),\n",
              " 10: np.float64(22.407002188183807)}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Evaluate\n",
        "print(\"\\n--- Evaluation: Pose‑Guided I3D Only ---\")\n",
        "S_pg = X_i3d_pg_test_n.dot(X_i3d_pg_train_n.T)\n",
        "compute_topk_accuracy(S_pg, y_train, y_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGzLfchSWuwtOeBf/sgT0N",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}